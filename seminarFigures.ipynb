{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.random as rd\n",
    "from scipy import stats\n",
    "import matplotlib as mpl\n",
    "import itertools as itertools\n",
    "import math\n",
    "import matplotlib.mlab as mlab\n",
    "from matplotlib.ticker import LogFormatterSciNotation\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "#from matplotlib import font_manager\n",
    "import matplotlib.mathtext as mathtext\n",
    "from decimal import Decimal\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Aug 29 11:27:54 2018\n",
    "@author: D. Dragomir\n",
    "\"\"\"\n",
    "#%matplotlib notebook\n",
    "import glob\n",
    "import numpy as np\n",
    "#import tkinter\n",
    "import matplotlib\n",
    "#try:\n",
    "#    matplotlib.use('TkAgg')\n",
    "#except ImportError:\n",
    "#    print(\"TkAgg error did occur\")\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from scipy.signal import medfilt\n",
    "import pandas as pd\n",
    "# from tsearchutils import tsearchutils as tsu\n",
    "#from mostutils import Processing\n",
    "import astropy.io.fits as apf\n",
    "import sys\n",
    "import getpass\n",
    "import emcee\n",
    "import corner\n",
    "from multiprocessing import Pool\n",
    "#this is currenlty not working on my OS but might work for you\n",
    "#import gaiarad as gr# this is the old way to get stellar radius, you can edit this out\n",
    "# import updatevet_2min as uv#this is for making advanced DV reports, you can edit this out\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random as rd\n",
    "import time as tm\n",
    "import math\n",
    "\n",
    "# from pyts.image import GASF, GADF, MTF, RecurrencePlots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_known_TOIS = pd.read_csv('/Users/mharris/Downloads/csv-file-toi-catalog_03032022.csv', skiprows = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_known_TOIS = all_known_TOIS.drop_duplicates('TIC').reset_index(drop=True)\n",
    "all_known_TOIS = all_known_TOIS.rename(columns={'TIC': 'TICID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOIs_and_sectors = pd.read_csv('/Users/mharris/Downloads/all_TOIs_sectors_observed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_known_TOIS = all_known_TOIS[['TICID', 'Full TOI ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TICID</th>\n",
       "      <th>Full TOI ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3146</th>\n",
       "      <td>2876</td>\n",
       "      <td>3131.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TICID  Full TOI ID\n",
       "3146   2876      3131.01"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_known_TOIS[all_known_TOIS['TICID'] == 2876]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TICID</th>\n",
       "      <th>Sectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2876</td>\n",
       "      <td>11;38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4711</td>\n",
       "      <td>11;38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17361</td>\n",
       "      <td>11;38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160023</td>\n",
       "      <td>65;11;38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>857186</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5276</th>\n",
       "      <td>1989628303</td>\n",
       "      <td>67;27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>1990842033</td>\n",
       "      <td>1;67;27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>2010186093</td>\n",
       "      <td>16;56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>2016376984</td>\n",
       "      <td>16;17;56;24;57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>2041563029</td>\n",
       "      <td>16;17;57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5281 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           TICID         Sectors\n",
       "0           2876           11;38\n",
       "1           4711           11;38\n",
       "2          17361           11;38\n",
       "3         160023        65;11;38\n",
       "4         857186              42\n",
       "...          ...             ...\n",
       "5276  1989628303           67;27\n",
       "5277  1990842033         1;67;27\n",
       "5278  2010186093           16;56\n",
       "5279  2016376984  16;17;56;24;57\n",
       "5280  2041563029        16;17;57\n",
       "\n",
       "[5281 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOIs_and_sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_TOIs_and_sectors = pd.merge(all_known_TOIS , TOIs_and_sectors, on=\"TICID\", how=\"left\").sort_values('TICID')\n",
    "\n",
    "new_TOIs_and_sectors.to_csv('/Users/mharris/Downloads/all_TOIs_sectors_observed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lnprob_trap(pars,t,flux,unc,tc): #calculates the log liklihood of these parameters\n",
    "    depth  = pars[0] #pars = parameters array\n",
    "    t0 = pars[1]\n",
    "    T = pars[2] #duration\n",
    "    tau = pars[3] #ingress/egress\n",
    "    if depth > 1. or depth < 0.:\n",
    "        #print('bad depth')\n",
    "        return -np.inf\n",
    "    if t0 > max(t)+1. or t0 < min(t)-1. or np.abs(t0-tc) > 1.:\n",
    "        #print('bad t0')\n",
    "        #print(t0,max(t),min(t),tc)\n",
    "        return -np.inf\n",
    "    if T/24. > 3. or T < tau or  T < 0: #SHOULD REVISIT THIS CRITERION DWS\n",
    "        #print('bad T')\n",
    "        return -np.inf\n",
    "    if tau/24. > 1. or tau < 0.: #SHOULD REVISIT THIS CRITERION DWS\n",
    "        #print('bad tau')\n",
    "        return -np.inf\n",
    "\n",
    "    flux_theo = tsu().trapmodel(depth,t,t0,T/24.,tau/24.)\n",
    "\n",
    "    return 0.0-0.5*np.sum(((flux_theo-flux)/unc)**2.) \n",
    "\n",
    "def lnprob_box(pars,t,flux,unc,tc): \n",
    "    depth  = pars[0]\n",
    "    t0 = pars[1]\n",
    "    tau = pars[2]\n",
    "    if depth > 1. or depth < 0.:\n",
    "        #print('bad depth')\n",
    "        return -np.inf\n",
    "    if t0 > max(t)+1. or t0 < min(t)-1. or np.abs(t0-tc) > 1.:\n",
    "        #print('bad t0')\n",
    "        #print(t0,max(t),min(t),tc)\n",
    "        return -np.inf\n",
    "    if tau < 0.:\n",
    "        #print('bad tau')\n",
    "        return -np.inf\n",
    "\n",
    "    flux_theo = tsu().boxmodel2(depth,t,t0,tau/24.)\n",
    "\n",
    "    return 0.0-0.5*np.sum(((flux_theo-flux)/unc)**2.)\n",
    "\n",
    "def get_tic_info(ticid):\n",
    "#    infile = '/Users/svillan/Dropbox (MIT)/tics/sb_ticradec_exo_CTL_07.02xTIC_v7.csv'\n",
    "#    infile = '/Users/svillan/Dropbox (MIT)/tics/si_ticradec_exo_CTL_07.02xTIC_v7.csv'\n",
    "    #if curmag == '10': magbin = 'b'\n",
    "    #if curmag == '11': magbin = 'i'\n",
    "    #if curmag == '12': magbin = 'f'\n",
    "    #infile = '/Users/svillan/Dropbox (MIT)/tics/s'+magbin+'_ticradec_exo_CTL_07.02xTIC_v7.csv'\n",
    "    #infile = '/Users/svillan/Dropbox (MIT)/tics/exo_CTL_08.01xTIC_v8.csv'\n",
    "\n",
    "    infile = '/Volumes/MALH_grad_school/tic8.csv' \n",
    "    dframe = pd.read_csv(infile,header=1,usecols=[0,13,14,30,42,60,64,65,70,71,72,73],names=['tic','RA','DEC','Vmag','Jmag','Tmag','Teff','eTeff','Rad','eRad','Mass','eMass'],dtype={'tic':'str' , 'RA':'float' , 'DEC':'float' , 'Vmag':'float', 'Jmag':'float','Tmag':'float','Teff':'float','eTeff':'float','Rad':'float','eRad':'float','Mass':'float','eMass':'float'},index_col=False)\n",
    "    match  = np.where(str(ticid) == dframe['tic'])\n",
    "    #print(match)\n",
    "    if len(match) != 1:\n",
    "    #if match.size <= 0:\n",
    "        print('error in tic match')\n",
    "    #elif np.isfinite(match[0]) != True:\n",
    "    #elif np.isfinite(match[0]) != True:\n",
    "        #print('error in the tic match')\n",
    "    else:\n",
    "        ra    = float(dframe['RA'][match[0]])\n",
    "        dec   = float(dframe['DEC'][match[0]])\n",
    "        Vmag  = float(dframe['Vmag'][match[0]])\n",
    "        Jmag  = float(dframe['Jmag'][match[0]])\n",
    "        Tmag  = float(dframe['Tmag'][match[0]])\n",
    "        Teff  = float(dframe['Teff'][match[0]])\n",
    "        eTeff = float(dframe['eTeff'][match[0]])\n",
    "        Rad   = float(dframe['Rad'][match[0]])\n",
    "        eRad  = float(dframe['eRad'][match[0]])\n",
    "        Mass  = float(dframe['Mass'][match[0]])\n",
    "        eMass = float(dframe['eMass'][match[0]])\n",
    "\n",
    "    return ra,dec,Vmag,Jmag,Tmag,Teff,eTeff,Rad,eRad,Mass,eMass\n",
    "\n",
    "def get_gaia_rad(ticid,ra,dec,path): #Don't need this function\n",
    "    #search gaia and create the output in a csv file \n",
    "    #get best stellar radius\n",
    "    rad,rad_lo,rad_hi = gr.gaiarad(ticid,ra,dec,path)\n",
    "    return rad,rad_lo,rad_hi\n",
    "\n",
    "def period_search(pars,t,flux,unc): #DWS what does this function do?--Email\n",
    "    depth  = pars[0]\n",
    "    t0 = pars[1]\n",
    "    T = pars[2]\n",
    "    #tau = pars[3]\n",
    "\n",
    "    periodgrid = 1./np.linspace(1./35., 1./0.5, 35000) \n",
    "    lnprobper = np.zeros(len(periodgrid))\n",
    "    print('running period search')\n",
    "    for i in range(len(periodgrid)):\n",
    "        phase = tsu().phasefold(t,periodgrid[i],t0) #This function is in tsearchutils\n",
    "        flux_theo = tsu().boxmodel2(depth,phase,0.5,(T/24.)/periodgrid[i]) \n",
    "        lnprobper[i] = 0.0-0.5*np.sum(((flux_theo-flux)/unc)**2.)\n",
    "\n",
    "    print('done with search')\n",
    "    bestndx = np.where(lnprobper == max(lnprobper))\n",
    "    bestper0 = periodgrid[bestndx]\n",
    "    bestper = bestper0[0]\n",
    "    maxtime = np.max(t)-np.min(t)\n",
    "    good = np.array(np.where(periodgrid > maxtime))[0]\n",
    "    if good.size == 0:\n",
    "        print('period results bad')\n",
    "        periodic = False\n",
    "        bestper = maxtime\n",
    "        probmin = np.max(lnprobper)\n",
    "    else:\n",
    "        probmax = np.max(lnprobper[good])\n",
    "        probmin = np.min(lnprobper[good])\n",
    "        delprob = np.abs(probmax-probmin)\n",
    "\n",
    "        if max(lnprobper) >= probmax+delprob and bestper <= maxtime:\n",
    "            periodic = True\n",
    "        else:\n",
    "            periodic = False\n",
    "\n",
    "    #plt.close()\n",
    "    #plt.scatter(periodgrid,lnprobper)\n",
    "    #plt.axhline(probmin)\n",
    "    #plt.axhline(np.max(lnprobper))\n",
    "    #plt.axvline(bestper)\n",
    "    #plt.axvline(maxtime)\n",
    "    #plt.show()\n",
    "    #plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    phase = tsu().phasefold(t,bestper,t0)\n",
    "    phase_theo = np.linspace(0.,1.,1000)\n",
    "    #flux_theo = tsu().trapmodel(depth,phase_theo,0.5,(T/24.)/bestper,(tau/24.)/bestper)\n",
    "    flux_theo = tsu().boxmodel2(depth,phase_theo,0.5,(T/24.)/bestper)\n",
    "    model_full_time = np.linspace(np.min(t),np.max(t),1000)\n",
    "    model_full_phase = tsu().phasefold(model_full_time,bestper,t0)\n",
    "    #model_full_flux = tsu().trapmodel(depth,model_full_phase,0.5,(T/24.)/bestper,(tau/24.)/bestper)\n",
    "    model_full_flux = tsu().boxmodel2(depth,model_full_phase,0.5,(T/24.)/bestper)\n",
    "    model_single_time = np.linspace(0.,1.,1000)\n",
    "    model_single_flux = tsu().boxmodel2(depth,model_single_time,0.5,(T/24.)/bestper)\n",
    "    return bestper,phase,model_full_time,model_full_flux,model_single_time,model_single_flux,periodic,periodgrid,lnprobper\n",
    "\n",
    "def remove_elements_based_on_indxs_fn(lst_of_lsts, remove_indxs):\n",
    "    #returns arrays, also can take arrays in lst_of_lsts\n",
    "    new_lst_of_lst = []\n",
    "    for lst in lst_of_lsts:\n",
    "        lst = [i for j, i in enumerate(lst) if j not in remove_indxs]\n",
    "        new_lst_of_lst.append(np.array(lst))\n",
    "    return new_lst_of_lst\n",
    "\n",
    "\n",
    "def binning_function_based_on_median(data, pts_per_bin):\n",
    "    binned_data = []\n",
    "    for i in range(0, len(data), pts_per_bin):\n",
    "        if i+pts_per_bin<=len(data):\n",
    "           # print(data[i:i+pts_per_bin])\n",
    "            binned_data.append(np.median(data[i:i+pts_per_bin]))\n",
    "        else:\n",
    "            binned_data.append(np.median(data[i:]))\n",
    "    return binned_data\n",
    "\n",
    "def binning_several_lists_at_once(data_list, pts_per_bin):\n",
    "    return [binning_function_based_on_median(x, pts_per_bin) for x in data_list]\n",
    "\n",
    "\n",
    "def new_binning_function_by_time(time, flux, raw, time_size_of_bins):\n",
    "    time = np.array(time).byteswap().newbyteorder() \n",
    "    flux = np.array(flux).byteswap().newbyteorder() \n",
    "    raw = np.array(raw).byteswap().newbyteorder() \n",
    "\n",
    "    interval = time_size_of_bins/60./24.\n",
    "    df = pd.DataFrame({'time': time, 'flux':flux, 'raw':raw})\n",
    "    df = df.append(df)\n",
    "    #print(df)\n",
    "    numbins = np.array(list(range(int(np.ceil((max(time)-min(time))/interval))+1)))\n",
    "    #print(df)\n",
    "    bins = np.array([min(time)+x*interval for x in numbins])\n",
    "    #print(bins)\n",
    "    df['time_bins'] = pd.cut(df.time, bins)\n",
    "    new_time = [x for x in df.groupby('time_bins').mean()['time'] if not math.isnan(x)]\n",
    "    new_flux = [x for x in df.groupby('time_bins').mean()['flux'] if not math.isnan(x)]\n",
    "    new_raw  = [x for x in df.groupby('time_bins').mean()['raw'] if not math.isnan(x)]\n",
    "    #print(len(new_time), len(new_flux), len(new_raw))\n",
    "    return [np.array(new_time), np.array(new_flux), np.array(new_raw)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getpass' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3ea7842fff51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0musr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetuser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#np.set_printoptions(threshold=np.nan)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#pd.set_option('display.max_rows', 10000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getpass' is not defined"
     ]
    }
   ],
   "source": [
    "usr = str(getpass.getuser())\n",
    "\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "#pd.set_option('display.max_rows', 10000)\n",
    "\n",
    "\n",
    "matplotlib.rcParams['font.family'] = \"serif\"\n",
    "matplotlib.rcParams['xtick.minor.visible'] = \"True\"\n",
    "matplotlib.rcParams['ytick.minor.visible'] = \"True\"\n",
    "matplotlib.rcParams['xtick.direction'] = \"in\"\n",
    "matplotlib.rcParams['ytick.direction'] = \"in\"\n",
    "matplotlib.rcParams['xtick.top'] = 'True'\n",
    "matplotlib.rcParams['ytick.right'] = 'True'\n",
    "matplotlib.rcParams['axes.axisbelow'] = 'True'\n",
    "\n",
    "\n",
    "#~sector starts, Julian date - TESS launch date (2457000)\n",
    "#01 1324\n",
    "#02 1353.5\n",
    "#03 1383\n",
    "#04 1409\n",
    "#05 1437 #1436.9 from DD\n",
    "#06 1466\n",
    "#07 1491\n",
    "#08 1517\n",
    "#09 1543.5\n",
    "#10 1569.5\n",
    "#11 1590\n",
    "#12 1625\n",
    "#13 1653\n",
    "#14 1683\n",
    "#15 1711\n",
    "#16 1738.4\n",
    "#17 1764.6\n",
    "#18 1790.6\n",
    "#19 1816.0\n",
    "\n",
    "secstart = 1436.9\n",
    "secend = secstart+28.\n",
    "cursec = '5'\n",
    "#curmag = '10'\n",
    "\n",
    "#Directories\n",
    "#indir = '/Users/'+usr+'/Dropbox (MIT)/TESS/qlp_lcs/'\n",
    "#outdir = '/Users/svilmasteroutdir = '/home/bobby/mallory/Pipeline/Output_files_2min/'\n",
    "\n",
    "    \n",
    "indir = masterindir+'sector_'+cursec+'/' #'/pdo/ramp/tev/qlp-delivery/sector-1/sector-1_first_delivery/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #for Missed singles\n",
    "# missed_singles_masteroutdir = '/home/bobby/mallory/Pipeline/Output_files/SAMPLE_out/'\n",
    "# if os.path.exists('/home/bobby/mallory/Pipeline/Output_files/SAMPLE_out/sector_'+cursec)==False:\n",
    "#     sec_outdir = os.path.join(missed_singles_masteroutdir, 'sector_'+cursec)\n",
    "#     os.mkdir(sec_outdir)\n",
    "# outdir = '/home/bobby/mallory/Pipeline/Output_files/SAMPLE_out/sector_'+cursec+'/'\n",
    "\n",
    "\n",
    "#read in TESS light curves \n",
    "#QLP TCE\n",
    "infiles = []\n",
    "for root, dirs, files in os.walk('.'):\n",
    "    for file in files:\n",
    "        if(file.endswith(\".fits\")):\n",
    "            infiles.append(os.path.join(root,file))\n",
    "infiles = sorted(infiles)\n",
    "tics = len(infiles)\n",
    "#print(\"infiles\", infiles)\n",
    "\n",
    "#SPOC all\n",
    "#infiles = sorted(glob.glob(indir+'light-curve/*fits.gz'))\n",
    "detectsigspec = 5.0 #5.0 #3.0 #with the current setup, a threshold too high could kill long-duration events. #BLS spectrum #something to change later\n",
    "seclength = 27.4\n",
    "#knownsingles = [290165539,139147770,394287035,52368076,214517366,139198430,150098860,152283270,53812109,270341214,309402106,444151146,141428309,177350401,233964642]\n",
    "#172,278,405,584,749\n",
    "\n",
    "#get the pdumps ready\n",
    "#pdir = '/Users/'+usr+'/Dropbox (MIT)/TESS/ts_lcs_pdump/' #Email Steven to get this file\n",
    "pdir = '/../Mdwarf_trends_project/Pipeline/pdumps'\n",
    "\n",
    "pfiles = sorted(glob.glob(pdir+'pdump_sector*.csv'))\n",
    "#print(pfiles)                                                                                           \n",
    "pdumps = []\n",
    "for ppp in range(len(pfiles)):\n",
    "    print(\"ppp\", ppp)\n",
    "    print(pfiles[ppp])\n",
    "    df = pd.read_csv(pfiles[ppp])\n",
    "    pdumps = np.append(pdumps,df['Time'])\n",
    "\n",
    "    \n",
    "#ctl = uv.readtic()\n",
    "#get the csv file ready\n",
    "outTIC   = np.array([])\n",
    "outRA    = np.array([])\n",
    "outDEC   = np.array([])\n",
    "outTmag  = np.array([])\n",
    "outVmag  = np.array([])\n",
    "outJmag  = np.array([])\n",
    "outTeff  = np.array([])\n",
    "outRad   = np.array([])\n",
    "outMass  = np.array([])\n",
    "outTc    = np.array([])\n",
    "outDepth = np.array([])\n",
    "outDur   = np.array([])\n",
    "outTau   = np.array([])\n",
    "outRp    = np.array([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_TOIs = [\n",
    "408232559,\n",
    "415339577, 436640602]\n",
    "#print(infiles)\n",
    "tics = len(infiles) #len(candprops.star_tic) #runs through all the files\n",
    "#    print('Nfiles = '+str(loopies))\n",
    "new_infiles = []\n",
    "new_tic = []\n",
    "\n",
    "rd.seed(42)\n",
    "#for i in np.random.choice(np.array(infiles), 1): \n",
    "for i in infiles:\n",
    "    fileticid = np.int64(i.split(\"-\")[2].lstrip(\"0\")) #[4].lstrip(\"0\"))\n",
    "    if fileticid in possible_TOIs:\n",
    "        new_infiles.append(i)\n",
    "        new_tic.append(fileticid)\n",
    "\n",
    "print(len(new_infiles))\n",
    "print(new_tic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = new_infiles[0]\n",
    "#print('filename', type(filename),filename)\n",
    "fileticid = np.int64(filename.split(\"-\")[2].lstrip(\"0\")) #[4].lstrip(\"0\"))\n",
    "#         if zzz == 0: \n",
    "#             dict_of_ticids[fileticid] = []\n",
    "#print(type(fileticid))\n",
    "print('working on '+str(fileticid))\n",
    "\n",
    "hdulist=apf.open(filename) #fits time series\n",
    "tbdata = hdulist[1].data\n",
    "#print(hdulist[1].header)\n",
    "time = tbdata.field('TIME')\n",
    "#print('got time')\n",
    "raw  = tbdata.field('SAP_FLUX')\n",
    "flux = tbdata.field('PDCSAP_FLUX') #tbdata.field('PDCSAP_FLUX') #tbdata.field('SAP_FLUX') #DSW - Email as if he's using lines 100-120\n",
    "quality = tbdata.field('QUALITY') \n",
    "indxnan = np.logical_not((np.isnan(flux)) | (np.isnan(time))) #looking for where time or flux is nan\n",
    "time = time[(indxnan) & (quality == 0)] #quality: flag 0=good, 1=bad\n",
    "flux = flux[(indxnan) & (quality == 0)]\n",
    "flux = flux/np.median(flux)\n",
    "raw  = raw[(indxnan) & (quality == 0)]\n",
    "#print('got all good quality data')\n",
    "\n",
    "dur = np.max(time)-np.min(time)\n",
    "     \n",
    "\n",
    "cleant = time #[indx]\n",
    "#        print(\"cleant1: \", cleant)\n",
    "cleanf = flux #[indx]\n",
    "cleanr = raw\n",
    "#print(np.min(cleant),np.max(cleant),secstart,secend)\n",
    "if len(cleant > 1):\n",
    "    if (np.min(cleant) < secstart): #DWS\n",
    "#                print(\"min cleant:\", np.min(cleant), \" secstart: \", secstart)\n",
    "        cleanf = cleanf[cleant > secstart]\n",
    "        cleanr = cleanr[cleant > secstart]\n",
    "        cleant = cleant[cleant > secstart]\n",
    "#                print(\"cleant2:\", cleant)\n",
    "if len(cleant > 1):\n",
    "        if (np.max(cleant) > secend):\n",
    "            cleanf = cleanf[cleant < secend]\n",
    "            cleanr = cleanr[cleant < secend]\n",
    "            cleant = cleant[cleant < secend]\n",
    "#                    print(\"cleant3: \", cleant)\n",
    "\n",
    "if len(cleant) <= 1:\n",
    "    print('no good flux for '+str(fileticid))\n",
    "\n",
    "newtime,newflux,newraw = cleant, cleanf, cleanr #RENAME later or rename mask newtime\n",
    "print('median: ', np.median(newflux))\n",
    "#        print(\"newtime: \",newtime)\n",
    "#print('reassigned names')\n",
    "binned_time, binned_flux, binned_raw = new_binning_function_by_time(newtime, newflux, newraw, 10)\n",
    "#print(type(binned_time), type(newtime))\n",
    "#spec,depth,specsh,depthsh = tsu().fitleastsq(binned_time,np.array(binned_flux)) #use this if still need to worry about outliers masquerading as BLS signals\n",
    "spec,depth,specsh,depthsh = tsu().new_fitleastsq(binned_time,np.array(binned_flux)) #use this if still need to worry about outliers masquerading as BLS signals\n",
    "\n",
    "#print('spec: ', len(spec), ' specsh: ', len(specsh))\n",
    "#spec,depth = tsu().fitleastsq(newtime,np.array(newflux))\n",
    "#time = np.array(cleants.BJD)  \n",
    "detecthresh = detectsigspec*np.std(spec) \n",
    "print('standard dev: ', np.std(spec))\n",
    "detecthresh_sh = detectsigspec*np.std(specsh) #use this if still need to worry about outliers masquerading as BLS signals\n",
    "#print(\"spec for maxspec: \", spec)\n",
    "maxspec = abs(np.max(spec)) #[(newtime > (np.min(newtime)+1.)) & (newtime < (np.max(newtime)-1.))])\n",
    "indxmaxspec = np.where(spec > detecthresh)\n",
    "\n",
    "a=0\n",
    "#print(\"maxspec >= detecthresh: \"+str(maxspec)+\" >= \"+str(detecthresh)+str(maxspec>detecthresh))\n",
    "print('maxspec: ', maxspec, ', minspec: ', np.min(spec), ' detechthresh: ', detecthresh, ' detecthresh_sh', detecthresh_sh)\n",
    "if (maxspec >= detecthresh): # & (np.any(rp < 30.)): #if SNR metric is larger than threshold AND rp is reasonable for a planetary object (but condition works only if we trust Rstar!)\n",
    "#            a=1\n",
    "#\"\"\"here is were the issue is occuring. why is maxspec always less than detectthresh?\"\"\"\n",
    "#duration cut (as a way to better deal with single-point outliers without actually cropping a transit); but this could eliminate high-b and grazing transits\n",
    "    goodtimes = np.array([],dtype = np.int16) #rename later for index\n",
    "    for l in range(len(specsh)):\n",
    "        #if zzz == 1:\n",
    "            #print(\"need all True!: \"+str(specsh[l] >= detecthresh_sh)+\", \"+str(l > 1)+\", \"+str(l < (len(specsh)-2)))\n",
    "            #print(str(specsh[l])+\" >= \"+str(detecthresh_sh)+\", and \"+str(l)+\" > 1, and \"+str(l)+\" < \"+str(len(specsh)-2))\n",
    "        if (specsh[l] >= detecthresh_sh) & (l > 1) & (l+3 < (len(specsh)-2)): #REVISIT: because the first and last points are likely to be systematic, we ignore first and last 2 points so they can't be considered as a transit\n",
    "            #print('got to searching for a transit')\n",
    "            if ([specsh[x]>= detecthresh_sh for x in range(l-1, l+2)]):#(specsh[l-1] >= detecthresh_sh) and (specsh[l+1] >= detecthresh_sh): #Revisit: looking for 3 points in a row\n",
    "\n",
    "#                    if (specsh[l-1] >= detecthresh_sh) or (specsh[l+1] >= detecthresh_sh):\n",
    "                a=1\n",
    "                #dict_of_ticids[fileticid].extend([l-1,l,l+1])\n",
    "               # dict_of_ticids[fileticid] = list(set(dict_of_ticids[fileticid]))\n",
    "                goodtimes = np.append(goodtimes,int(l))\n",
    "                print(\"This looks like a transit!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newunc = np.full(len(newflux),np.std(newflux)) #an array the size of newflux of the st.dev of newflux\n",
    "binned_unc = np.full(len(binned_flux), np.std(binned_flux))\n",
    "nwalkers = 40 \n",
    "nchain = 1000\n",
    "bchain = 500 #=0.5*nchain\n",
    "\n",
    "indxbest = min(goodtimes[np.where(spec[goodtimes] == max(spec[goodtimes]))]) #DWS -email\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tc_prior = float(binned_time[indxbest])\n",
    "ini_box = np.array([1.-float(binned_flux[indxbest]),tc_prior,2.5],dtype=float) #10. for 30 minute data\n",
    "ndim_box = len(ini_box)\n",
    "err_box = np.array([0.1,0.1,.01])\n",
    "pos_box = [ini_box+5e-3*err_box*np.random.randn(ndim_box) for rrr in range(nwalkers)]\n",
    "\n",
    "#with Pool() as pool:\n",
    "    #sampler = emcee.EnsembleSampler(nwalkers,ndim_box,lnprob_box,args=(newtime,newflux,newunc,tc_prior),pool=pool)\n",
    "    #sampler.run_mcmc(pos_box,nchain,progress=True)\n",
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers,ndim_box,lnprob_box,args=(binned_time,binned_flux,binned_unc,tc_prior))\n",
    "sampler.run_mcmc(pos_box,nchain,progress=True)\n",
    "\n",
    "samples_box = sampler.chain[:, bchain:, :].reshape((-1,ndim_box))\n",
    "report_box = list(map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]), zip(*np.percentile(samples_box, [16, 50, 84],axis=0))))\n",
    "pars_box_best = [report_box[0][0],report_box[1][0],report_box[2][0]]\n",
    "box_best_depth = report_box[0][0]\n",
    "box_best_depth_lo = report_box[0][1]\n",
    "box_best_depth_hi = report_box[0][2]\n",
    "box_best_t0 = report_box[1][0]\n",
    "box_best_T = report_box[2][0]\n",
    "\n",
    "#try:\n",
    "#get tic ra,dec\n",
    "#                        ra,dec = get_tic_info(str(fileticid),curmag)\n",
    "    #RA,DEC,Vmag,Jmag,Tmag,Teff,eTeff,Rad,eRad,Mass,eMass = get_tic_info(str(fileticid))\n",
    "#get gaia radius\n",
    "#                        g_rad,g_rad_lo,g_rad_hi = get_gaia_rad(str(fileticid),ra,dec,outdir)\n",
    "#                        g_rad_sig_lo = g_rad-g_rad_lo\n",
    "#                        g_rad_sig_hi = g_rad_hi-g_rad\n",
    "#except:\n",
    "#                       g_rad=np.nan\n",
    "    #Rad = np.nan\n",
    "    #RA  = np.nan\n",
    "    #DEC = np.nan\n",
    "    #Vmag = np.nan\n",
    "    #Tmag = np.nan\n",
    "    #Jmag = np.nan\n",
    "    #Teff = np.nan\n",
    "    #Mass = np.nan\n",
    "\n",
    "\n",
    "#rp/rs = sqrt(depth)\n",
    "#rp = rs*sqrt(depth)\n",
    "\n",
    "#p_rad = 109.*Rad*np.sqrt(trap_best_depth)\n",
    "\n",
    "\n",
    "\n",
    "#check for periodicity\n",
    "#bestper, phase, per_full_time, per_full_flux, phased_time, phased_flux, periodic, periodgrid, lnprobper = period_search(pars_trap_best,newtime,newflux,newunc)\n",
    "bestper, phase, per_full_time, per_full_flux, phased_time, phased_flux, periodic, periodgrid, lnprobper = period_search(pars_box_best,binned_time,binned_flux,binned_unc)\n",
    "\n",
    "#model_time = np.arange(np.min(newtime),np.max(newtime),5e-3)\n",
    "model_time = per_full_time\n",
    "\n",
    "if periodic == False:\n",
    "    #model_trap_0 = tsu().trapmodel(pars_trap_best[0],model_time,pars_trap_best[1],pars_trap_best[2]/24.,pars_trap_best[3]/24.)\n",
    "    #model_trap_best = (model_trap_0-1.)*1000.\n",
    "    model_box_0 = tsu().boxmodel2(pars_box_best[0],model_time,pars_box_best[1],pars_box_best[2]/24.)\n",
    "    model_box_best = (model_box_0-1.)*1000.\n",
    "else:\n",
    "    model_box_best = (per_full_flux-1.)*1000.\n",
    "\n",
    "plt.gcf().clear() \n",
    "plt.suptitle(str(fileticid))\n",
    "#plt.figure(1,constrained_layout=True)\n",
    "plt.figure(1)\n",
    "gs = gridspec.GridSpec(3,1,height_ratios = [1,1,3],hspace=0.5)\n",
    "\n",
    "plt.subplot(gs[0])\n",
    "x,y = binned_time, binned_raw\n",
    "delx = max(x)-min(x)\n",
    "dely = max(y)-min(y)\n",
    "plt.axis([min(x)-0.01*delx, max(x)+0.01*delx, min(y)-0.01*dely, max(y)+0.01*dely])\n",
    "plt.scatter(binned_time,binned_raw,s=0.1,color='C2')\n",
    "for ppp in range(len(pdumps)):\n",
    "    plt.axvline(x=pdumps[ppp],ymin=0,ymax=1,color='C3',alpha=0.1,zorder=-1)\n",
    "plt.xlabel('TJD')\n",
    "plt.ylabel('Raw Flux')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(gs[1])\n",
    "x,y = newtime, (newflux-1.)*1000.\n",
    "delx = max(x)-min(x)\n",
    "dely = max(y)-min(y)\n",
    "plt.axis([min(x)-0.01*delx, max(x)+0.01*delx, min(y)-0.01*dely, max(y)+0.01*dely])\n",
    "\n",
    "plt.plot(model_time,model_box_best,color='C1',alpha=0.8)\n",
    "plt.scatter(newtime,(newflux-1.)*1000.,s=0.1,color='C0')\n",
    "for ppp in range(len(pdumps)):\n",
    "    plt.axvline(x=pdumps[ppp],ymin=0,ymax=1,color='C3',alpha=0.1,zorder=-1)\n",
    "plt.xlabel('TJD')\n",
    "plt.ylabel('Relative Flux [ppt]')\n",
    "plt.subplot(gs[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,12))\n",
    "transit_times = []\n",
    "transit_flux = []\n",
    "def animate_pipeline(l, transit_times):\n",
    "    ax.clear()\n",
    "    \n",
    "    ax.scatter(newtime,(newflux-1.)*1000.,color='lightgrey',s=4,alpha=0.5,label='SPOC 2-min detrended',rasterized=True)\n",
    "    ax.scatter(binned_time[l], (binned_flux[l]-1)*1000.,color='black',s=4,alpha=0.5,label='SPOC 2-min detrended, binned',rasterized=True)\n",
    "    ax.axhline(-10, 10, detecthresh_sh, color='gray', linestyle='--', linewidth=3)\n",
    "\n",
    "    if (specsh[l] >= detecthresh_sh) & (l > 1) & (l+3 < (len(specsh)-2)): #REVISIT: because the first and last points are likely to be systematic, we ignore first and last 2 points so they can't be considered as a transit\n",
    "            #print('got to searching for a transit')\n",
    "            if ([specsh[x]>= detecthresh_sh for x in range(l-2, l)]):#(specsh[l-1] >= detecthresh_sh) and (specsh[l+1] >= detecthresh_sh): #Revisit: looking for 3 points in a row\n",
    "                transit_times.append(binned_time[l])\n",
    "                transit_flux.append(binned_flux[l])\n",
    "    ax.scatter(transit_times, transit_flux,color='limegreen',s=4,alpha=0.5,rasterized=True)\n",
    "    for ppp in range(len(pdumps)):\n",
    "        plt.axvline(x=pdumps[ppp],ymin=0,ymax=1,color='C1',zorder=-3)\n",
    "    ax.legend(fontsize='small',loc=3)\n",
    "    ax.tick_params(labelsize=8)\n",
    "    ax.xlabel('Time [h]',fontsize='small')\n",
    "    ax.ylabel('Normalized Flux',fontsize='small')\n",
    "    ax.set_xlim([min(newtime), max(new_time)])\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate_pipeline, list(range(len(binned_time))), interval=1000, repeat=False)\n",
    "ani.save('pipeline_vid.mp4', fps=1, extra_args=['-vcodec', 'libx264'], savefig_kwargs={'facecolor':'black'})\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
