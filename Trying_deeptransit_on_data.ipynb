{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39689e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random as rd\n",
    "import astropy.io.fits as apf\n",
    "import batman\n",
    "import eleanor\n",
    "import emcee\n",
    "import getpass\n",
    "import glob\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import Process\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import time as tm \n",
    "from astroquery.mast import Catalogs\n",
    "import astropy.units as units\n",
    "from astropy.wcs import WCS\n",
    "import math\n",
    "import astropy.io.fits as apf\n",
    "from astropy.stats import sigma_clip\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from wotan import flatten\n",
    "import lightkurve as lk\n",
    "import corner\n",
    "import numpy as np\n",
    "import juliet\n",
    "import matplotlib.gridspec as gridspec\n",
    "import mpl_axes_aligner\n",
    "\n",
    "from astropy.timeseries import BoxLeastSquares\n",
    "from ldtk import LDPSetCreator, BoxcarFilter, TabulatedFilter, SVOFilter\n",
    "from ldtk.filters import tess, sdss_z\n",
    "from astroquery import svo_fps\n",
    "\n",
    "import mr_forecast as mr\n",
    "import numba\n",
    "from math import floor\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "from transitleastsquares import (\n",
    "    transitleastsquares,\n",
    "    cleaned_array,\n",
    "    catalog_info,\n",
    "    transit_mask\n",
    "    )\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "\n",
    "\n",
    "import deep_transit as dt\n",
    "import copy\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc26e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TICIDs = [150428135, 259377017, 235678745, 467179528, 284441182, 36724087, 441798995, 219195044]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3de2917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "import ntpath\n",
    "\n",
    "LDC_for_quadratic = pd.read_csv('./LDC_files/table15.dat', \n",
    "                                header = None, \n",
    "                                sep=\"\\s+\", index_col=None,\n",
    "                               names = ['logg', 'Teff', 'z','L/HP', 'aLSM', 'bLSM',\n",
    "                                       'aFCM', 'bFCM', 'SQRT(CHI2)', 'qsr', 'PC'])\n",
    "\n",
    "mdwarf_LDC_for_quadratic = LDC_for_quadratic[LDC_for_quadratic['Teff']<4300]\n",
    "                  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "348f9398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transit_mask(t, period, duration, T0):\n",
    "    \n",
    "    # Works with numba, but is not faster\n",
    "    mask = np.abs((t - T0 + 0.5 * period) % period - 0.5 * period) < 0.5 * duration\n",
    "    return mask\n",
    "\n",
    "\n",
    "def match_logg_and_teff_for_LDC(df):\n",
    "    \n",
    "    # Written by Mallory Harris\n",
    "\n",
    "    # Description: uses logg and effective temp to calculate quadratic limb darkening parameters based on given  csv\n",
    "    \n",
    "    # Arguments : df = panda dataframe of TIC parameters\n",
    "\n",
    "\n",
    "    # Return    : df = panda dataframe with updated quadratic limb darkening parameters\n",
    "\n",
    "    a = []\n",
    "    b = []\n",
    "#     print('a')\n",
    "    bar_format = \"{desc}{percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} targets | {elapsed}<{remaining}\"\n",
    "    pbar = tqdm(total=len(df), smoothing=0.3,  position=1, leave=True, bar_format=bar_format)\n",
    "    for i in range(len(df)):\n",
    "#         print(i)\n",
    "\n",
    "        Teff = np.float128(df['Teff'])[i]\n",
    "        logg =  np.float128(df['logg'])[i]\n",
    "        pbar.update(1)\n",
    "\n",
    "        try:\n",
    "            int(Teff)\n",
    "            mdwarf_Teff =mdwarf_LDC_for_quadratic[mdwarf_LDC_for_quadratic['Teff'] == np.median(mdwarf_LDC_for_quadratic.iloc[(mdwarf_LDC_for_quadratic['Teff'].astype('float128')-Teff+0.01).abs().argsort()[:8]].reset_index(drop=True)['Teff'])]\n",
    "            if i%100 == 0:\n",
    "    #                 print(Teff, set(mdwarf_Teff['Teff']))\n",
    "                if len(set(mdwarf_Teff['Teff']))>1:\n",
    "                       print(mdwarf_Teff)\n",
    "            if not abs(logg)>=0.:\n",
    "                logg = np.median(mdwarf_Teff['logg'])\n",
    "    #         print(mdwarf_Teff.iloc[(mdwarf_Teff['logg'].astype('float128')-logg-0.00000001).abs().argsort()].iloc[0][['aLSM', 'bLSM']])\n",
    "            aLSM, bLSM =  mdwarf_Teff.iloc[(mdwarf_Teff['logg'].astype('float128')-logg-0.00000001).abs().argsort()].iloc[0][['aLSM', 'bLSM']]\n",
    "#             print(aLSM, bLSM)\n",
    "            a.append(aLSM)\n",
    "            b.append(bLSM)  \n",
    "\n",
    "                    \n",
    "        except:\n",
    "            a.append(np.nan)\n",
    "            b.append(np.nan)\n",
    "    pbar.close()\n",
    "\n",
    "    df['aLSM'] = a\n",
    "    df['bLSM'] = b\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c40f97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TICIDs = [261257684, 150428135, 259377017, 235678745, 467179528, 284441182, 36724087, 441798995, 219195044]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c3ac89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctlfile = './Total_Mdwarf_files/final_mdwarf_params_new.csv'\n",
    "mdwarfs = pd.read_csv(ctlfile, iterator =True, chunksize = 100000, index_col=None)\n",
    "\n",
    "mdwarfs_known = pd.concat(\n",
    "    [chunk[chunk['TICID'].astype(int).isin(TICIDs)] \n",
    "    for chunk in mdwarfs]\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1736d730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d04473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_if_doesnt_exist(outdir, str_new_dir_name):\n",
    "    # Written by Mallory Harris\n",
    "\n",
    "    # Description: creates new directory to save data to if it does not already exist\n",
    "\n",
    "    # Arguments : outdir             = existing directory in which new directory will be located\n",
    "    #             str_new_dir_name   = string of the new subdirectory of outdir's name\n",
    "\n",
    "\n",
    "    if os.path.exists(outdir+str_new_dir_name)==False:\n",
    "        new_outdir = os.path.join(outdir, str_new_dir_name)\n",
    "        os.mkdir(new_outdir)\n",
    "\n",
    "\n",
    "def fetch(ticid, pipeline, exptime, sector_num): \n",
    "    # Written by Mallory Harris\n",
    "\n",
    "    # Description: uses lightkurve to download TESS fits file based on sector number, source pipeline, exposure time and star id\n",
    "\n",
    "    # Arguments : ticid       = TESS Input Catalog identification number of star\n",
    "    #             sector_num  = sector from which to download data\n",
    "\n",
    "    #             pipeline    = source pipeline from which to get data (options are 'QLP', 'SPOC', 'TESS-SPOC')\n",
    "    #             exptime     = exposure length of observations (2 or 30 minutes, depending on pipeline) units of seconds\n",
    "    #                           'QLP', 'TESS-SPOC', 'TGLC' = 30 minute (1800s, PM), 10 minute (600s, EM1), 300s (EM2)\n",
    "    #                           'SPOC'             = 2  minutte (120 s) exptime\n",
    "\n",
    "    Path = './known_Mdwarfs_data'\n",
    "    good_authors = [pipeline]\n",
    "    if pipeline == 'SPOC':\n",
    "        Path =  Path+'/PS_data/tic_'+str(ticid)\n",
    "        small_dir_path_lst = glob.glob(Path+\"/mastDownload/TESS/*\"+str(ticid).zfill(16)+\"*\")\n",
    "    else:\n",
    "        Path =  Path+'/FFI_data/tic_'+str(ticid)\n",
    "#         print(Path)\n",
    "        small_dir_path_lst = glob.glob(Path+\"/HLSP/*\"+str(ticid).zfill(16)+\"*\")\n",
    "\n",
    "        if pipeline == 'QLP':\n",
    "            small_dir_path_lst = [i for i in small_dir_path_lst if 'ffi' in i]\n",
    "        elif pipeline == 'TESS-SPOC':\n",
    "            small_dir_path_lst = [i for i in small_dir_path_lst if 'tess-spoc' in i]\n",
    "        elif pipeline == 'TGLC':\n",
    "            small_dir_path_lst = [i for i in small_dir_path_lst if 'gaiaid' in i]\n",
    "\n",
    "    for i in small_dir_path_lst:\n",
    "        file = glob.glob(i+'/*.fits')\n",
    "        print('there is something already in the folder:', len(file))\n",
    "        if len(file)>0:\n",
    "            os.remove(file[0])\n",
    "        print('it was removed')\n",
    "        \n",
    "    search = lk.search_lightcurve('TIC '+str(ticid), mission='TESS', exptime =exptime)\n",
    "#     print(search)\n",
    "    try:\n",
    "        result = all(elem in list(search.author)  for elem in good_authors)\n",
    "    except:\n",
    "        print(search)\n",
    "        result = False\n",
    "\n",
    "    if result == True:\n",
    "        search = search[search.author == pipeline]\n",
    "        if sector_num!= None:\n",
    "            search.download(quality_bitmask='default', download_dir = Path)\n",
    "        else:\n",
    "            \n",
    "            search.download_all(quality_bitmask='default', download_dir = Path)\n",
    "\n",
    "        print('done downloading')\n",
    "    else:\n",
    "        print('No '+pipeline+' obervations')\n",
    "\n",
    "def get_lcf_files(df, pipeline, last_hung_ticid = 0, sector_num = False):\n",
    "    # Written by Mallory Harris\n",
    "\n",
    "    # Description: takes dataframe of TICIDs observed in a given sector (identified by a column in df, explained below)\n",
    "    #              to download light curves of that sector for each ticid from given pipeline \n",
    "            \n",
    "\n",
    "    # Arguments : df              = panda dataframe. Must include at least one column of \"TICID\" with TESS identification number\n",
    "    #                               and one column denoting whether or not observations were taken in the named sector.\n",
    "    #                               example: if targets are observed in sector 20, their value in the column \"S20\" will be >0\n",
    "    #             sector_num      = sector from which to download data\n",
    "    #             pipeline        = source pipeline from which to get data (options are 'QLP', 'SPOC', 'TESS-SPOC')\n",
    "    #             last_hung_ticid = if, for any reason, this function is stopped, one can enter that last downloaded TICID to avoid re-downloading data\n",
    "\n",
    "    if pipeline == 'SPOC':\n",
    "        exptime = 'short'\n",
    "    else:\n",
    "        exptime = 'long'\n",
    "    if sector_num!=False:\n",
    "        new_df = df[df['S'+str(sector_num)]>0.].reset_index(drop = True)\n",
    "        print('sector '+str(sector_num), 'num targets', len(new_df))\n",
    "\n",
    "    else:\n",
    "        new_df = df.copy()\n",
    "        sector_num = None\n",
    "    indx = 0\n",
    "\n",
    "    if last_hung_ticid != 0:\n",
    "        indx = new_df[new_df['TICID'] == last_hung_ticid].index[0]\n",
    "    print('starting index: ', indx)\n",
    "    r = indx\n",
    "    sector_PS_targets = new_df[indx:]\n",
    "    #start_time = time.time()\n",
    "    masteroutdir = './known_Mdwarfs_data/'\n",
    "    \n",
    "    if pipeline == 'SPOC':\n",
    "        mkdir_if_doesnt_exist(masteroutdir, 'PS_data/')\n",
    "        masteroutdir = masteroutdir + 'PS_data/'\n",
    "    else:\n",
    "        mkdir_if_doesnt_exist(masteroutdir, 'FFI_data/')\n",
    "        masteroutdir = masteroutdir + 'FFI_data/'\n",
    "\n",
    "    \n",
    "    for i in sector_PS_targets['TICID']:\n",
    "        print(r)\n",
    "        r +=1\n",
    "\n",
    "        ticid = int(i)\n",
    "        \n",
    "        print('TIC '+str(ticid))\n",
    "        #print(time.localtime())\n",
    "        while 1<2:\n",
    "            proc = Process(target=fetch, args=(ticid, sector_num, pipeline, exptime))\n",
    "            proc.start()\n",
    "            proc.join(timeout = 45)\n",
    "            proc.terminate()\n",
    "            if proc.exitcode is None:\n",
    "                print('timeout')\n",
    "                continue\n",
    "            else:\n",
    "                print('success!')\n",
    "                break\n",
    "    print('All done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "177fda5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TICID</th>\n",
       "      <th>RA</th>\n",
       "      <th>DEC</th>\n",
       "      <th>Vmag</th>\n",
       "      <th>Jmag</th>\n",
       "      <th>Tmag</th>\n",
       "      <th>Teff</th>\n",
       "      <th>eTeff_x</th>\n",
       "      <th>Rad</th>\n",
       "      <th>eRad</th>\n",
       "      <th>...</th>\n",
       "      <th>S54</th>\n",
       "      <th>S55</th>\n",
       "      <th>eTeff_y</th>\n",
       "      <th>logg</th>\n",
       "      <th>elogg</th>\n",
       "      <th>M/H</th>\n",
       "      <th>eM/H</th>\n",
       "      <th>GAIA</th>\n",
       "      <th>aLSM</th>\n",
       "      <th>bLSM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>261257684.0</td>\n",
       "      <td>89.372315</td>\n",
       "      <td>-83.130204</td>\n",
       "      <td>12.588</td>\n",
       "      <td>9.607</td>\n",
       "      <td>10.8460</td>\n",
       "      <td>3751.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.532439</td>\n",
       "      <td>0.015794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.70914</td>\n",
       "      <td>0.009127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.620844e+18</td>\n",
       "      <td>0.2581</td>\n",
       "      <td>0.3609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150428135.0</td>\n",
       "      <td>97.096787</td>\n",
       "      <td>-65.579312</td>\n",
       "      <td>13.151</td>\n",
       "      <td>9.469</td>\n",
       "      <td>10.9102</td>\n",
       "      <td>3494.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.419457</td>\n",
       "      <td>0.012573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.80892</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.284518e+18</td>\n",
       "      <td>0.1604</td>\n",
       "      <td>0.4325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>219195044.0</td>\n",
       "      <td>92.391740</td>\n",
       "      <td>-53.823484</td>\n",
       "      <td>13.311</td>\n",
       "      <td>10.241</td>\n",
       "      <td>11.5436</td>\n",
       "      <td>3731.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.473141</td>\n",
       "      <td>0.014147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.76101</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.500474e+18</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.4118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>259377017.0</td>\n",
       "      <td>68.415501</td>\n",
       "      <td>-51.956232</td>\n",
       "      <td>12.603</td>\n",
       "      <td>9.099</td>\n",
       "      <td>10.4981</td>\n",
       "      <td>3532.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.374358</td>\n",
       "      <td>0.011496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.85053</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.781196e+18</td>\n",
       "      <td>0.1604</td>\n",
       "      <td>0.4325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36724087.0</td>\n",
       "      <td>154.646405</td>\n",
       "      <td>-11.716734</td>\n",
       "      <td>13.140</td>\n",
       "      <td>9.007</td>\n",
       "      <td>10.5848</td>\n",
       "      <td>3331.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.374139</td>\n",
       "      <td>0.011184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.85074</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.767282e+18</td>\n",
       "      <td>0.1529</td>\n",
       "      <td>0.4604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>235678745.0</td>\n",
       "      <td>285.633044</td>\n",
       "      <td>75.418605</td>\n",
       "      <td>13.190</td>\n",
       "      <td>9.797</td>\n",
       "      <td>11.0788</td>\n",
       "      <td>3746.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.463205</td>\n",
       "      <td>0.013592</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.76979</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.268372e+18</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.4118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>441798995.0</td>\n",
       "      <td>264.147791</td>\n",
       "      <td>77.126122</td>\n",
       "      <td>13.476</td>\n",
       "      <td>10.765</td>\n",
       "      <td>11.9521</td>\n",
       "      <td>3872.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.548484</td>\n",
       "      <td>0.016161</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.69525</td>\n",
       "      <td>0.009462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.657159e+18</td>\n",
       "      <td>0.2946</td>\n",
       "      <td>0.3316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>284441182.0</td>\n",
       "      <td>10.088709</td>\n",
       "      <td>61.213626</td>\n",
       "      <td>13.459</td>\n",
       "      <td>10.154</td>\n",
       "      <td>11.4752</td>\n",
       "      <td>3624.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.490120</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.74607</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.272241e+17</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.3984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>467179528.0</td>\n",
       "      <td>197.998168</td>\n",
       "      <td>65.833807</td>\n",
       "      <td>12.941</td>\n",
       "      <td>9.706</td>\n",
       "      <td>11.0402</td>\n",
       "      <td>3618.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.435666</td>\n",
       "      <td>0.012939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.79432</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.678074e+18</td>\n",
       "      <td>0.1671</td>\n",
       "      <td>0.4201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TICID          RA        DEC    Vmag    Jmag     Tmag    Teff  \\\n",
       "0  261257684.0   89.372315 -83.130204  12.588   9.607  10.8460  3751.0   \n",
       "1  150428135.0   97.096787 -65.579312  13.151   9.469  10.9102  3494.0   \n",
       "2  219195044.0   92.391740 -53.823484  13.311  10.241  11.5436  3731.0   \n",
       "3  259377017.0   68.415501 -51.956232  12.603   9.099  10.4981  3532.0   \n",
       "4   36724087.0  154.646405 -11.716734  13.140   9.007  10.5848  3331.0   \n",
       "5  235678745.0  285.633044  75.418605  13.190   9.797  11.0788  3746.0   \n",
       "6  441798995.0  264.147791  77.126122  13.476  10.765  11.9521  3872.0   \n",
       "7  284441182.0   10.088709  61.213626  13.459  10.154  11.4752  3624.0   \n",
       "8  467179528.0  197.998168  65.833807  12.941   9.706  11.0402  3618.0   \n",
       "\n",
       "   eTeff_x       Rad      eRad  ...   S54   S55  eTeff_y     logg     elogg  \\\n",
       "0    157.0  0.532439  0.015794  ...   0.0   0.0    157.0  4.70914  0.009127   \n",
       "1    157.0  0.419457  0.012573  ...   0.0   0.0    157.0  4.80892  0.004651   \n",
       "2    157.0  0.473141  0.014147  ...   0.0   0.0    157.0  4.76101  0.007200   \n",
       "3    157.0  0.374358  0.011496  ...   0.0   0.0    157.0  4.85053  0.002090   \n",
       "4    157.0  0.374139  0.011184  ...   0.0   0.0    157.0  4.85074  0.001634   \n",
       "5    157.0  0.463205  0.013592  ...  10.0  10.0    157.0  4.76979  0.006479   \n",
       "6    157.0  0.548484  0.016161  ...  10.0  10.0    157.0  4.69525  0.009462   \n",
       "7    157.0  0.490120  0.014531  ...   0.0   0.0    157.0  4.74607  0.007723   \n",
       "8    157.0  0.435666  0.012939  ...   0.0   0.0    157.0  4.79432  0.005376   \n",
       "\n",
       "   M/H eM/H          GAIA    aLSM    bLSM  \n",
       "0  NaN  NaN  4.620844e+18  0.2581  0.3609  \n",
       "1  NaN  NaN  5.284518e+18  0.1604  0.4325  \n",
       "2  NaN  NaN  5.500474e+18  0.1737  0.4118  \n",
       "3  NaN  NaN  4.781196e+18  0.1604  0.4325  \n",
       "4  NaN  NaN  3.767282e+18  0.1529  0.4604  \n",
       "5  NaN  NaN  2.268372e+18  0.1737  0.4118  \n",
       "6  NaN  NaN  1.657159e+18  0.2946  0.3316  \n",
       "7  NaN  NaN  4.272241e+17  0.2125  0.3984  \n",
       "8  NaN  NaN  1.678074e+18  0.1671  0.4201  \n",
       "\n",
       "[9 rows x 80 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdwarfs_known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff7e0614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there is something already in the folder: 0\n",
      "it was removed\n",
      "there is something already in the folder: 0\n",
      "it was removed\n",
      "there is something already in the folder: 0\n",
      "it was removed\n",
      "there is something already in the folder: 0\n",
      "it was removed\n",
      "done downloading\n"
     ]
    }
   ],
   "source": [
    "fetch(261257684, 'SPOC', 'short', None)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7dae5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_breaks(time, val = 27.):\n",
    "    time = time[np.argsort(time)] \n",
    "    t   = np.diff(time)\n",
    "    inds = np.where( t>val)[0]\n",
    "    return inds + 1\n",
    "\n",
    "# def sort_data_by_times(time, flux):\n",
    "#     return time[np.argsort(time)], flux[np.argsort(time)]\n",
    "\n",
    "\n",
    "def breaking_up_data(time, break_val = 27.):\n",
    "    brk = np.append(np.append([0], find_breaks(time, break_val)), [len(time)])\n",
    "    \n",
    "    \n",
    "    indexes = []\n",
    "    for i in range(len(brk)-1):\n",
    "        r = np.arange(brk[i],brk[i+1], 1)\n",
    "\n",
    "        cadence_6hrs = np.nanmin(np.diff(new_time[r]))/24/4\n",
    "    \n",
    "        if len(time[r])>cadence_6hrs:\n",
    "            indexes.append(r)\n",
    "    return indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c5f8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_median(data, kernel=300):\n",
    "    \"\"\"Returns sliding median of width 'kernel' and same length as data \"\"\"\n",
    "    idx = np.arange(kernel) + np.arange(len(data) - kernel + 1)[:, None]\n",
    "    idx = idx.astype(np.int)  # needed if oversampling_factor is not int\n",
    "    med = np.median(data[idx], axis=1)\n",
    "\n",
    "    # Append the first/last value at the beginning/end to match the length of\n",
    "    # data and returned median\n",
    "    first_values = med[0]\n",
    "    last_values = med[-1]\n",
    "    missing_values = len(data) - len(med)\n",
    "    values_front = int(missing_values * 0.5)\n",
    "    values_end = missing_values - values_front\n",
    "    med = np.append(np.full(values_front, first_values), med)\n",
    "    med = np.append(med, np.full(values_end, last_values))\n",
    "    return med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab733cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017361111111111112"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*5/60/60/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72ba3e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.199999999999999"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.005*24*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "319b5fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "\n",
    "# model_colors = ['#FF930F', '#71Fd8FF']\n",
    "def using_BLS_to_find_periodic_signals(time, flux, u, verbose = True, show_progress_info = True, \n",
    "                                       intransit = [], periods = [], T0 = [], Tdur = [], \n",
    "                                       depths = [], first=True):\n",
    "    \n",
    "    max_per = min(max(time)-min(time), 100.)\n",
    "    if first == True:\n",
    "        intransit = np.full(len(time), False)\n",
    "        periods = []\n",
    "        T0 = []\n",
    "        Tdur = []\n",
    "        depths = []\n",
    "\n",
    "    time_new = time[~intransit]\n",
    "    flux_new = flux[~intransit]\n",
    "    if len(time_new)>0:\n",
    "        start = tm.time()\n",
    "\n",
    "        durations = np.linspace(0.02, 0.5, 75)\n",
    "        model     = BoxLeastSquares(time_new, flux_new)\n",
    "        results   = model.autopower(durations, objective='snr', maximum_period=max_per)\n",
    "        \n",
    "        my_median = running_median(results.power )\n",
    "        \n",
    "        results['power_final'] = results.power - my_median\n",
    "        \n",
    "        index = np.argmax(results.power_final)\n",
    "        print('results ', results)\n",
    "        period    = results.period[index]\n",
    "        print('period', period, 'index ', index)\n",
    "        print('sizes', len(results.transit_time), len(results.period))\n",
    "#     print('params', periods, T0, Tdur, depths)\n",
    "        end = tm.time()\n",
    "        print('planet run: BLS time ', (end-start)/60, ' minutes')\n",
    "\n",
    "#         else:d\n",
    "        if round(results.transit_time[index], 4) in [round(x, 4) for x in T0]:\n",
    "        \n",
    "            intransit = np.logical_or(intransit, transit_mask(time, results.period, 2*results.duration+(2*0.04), results.transit_time))\n",
    "            print('mask', set(transit_mask(time, results.period, 2*results.duration+(2*0.04), results.transit_time)))\n",
    "            return using_BLS_to_find_periodic_signals(time, flux, u, intransit=intransit, verbose = verbose,  periods = periods, T0 = T0, Tdur = Tdur, depths = depths, first = False)\n",
    "        if verbose:\n",
    "            \n",
    "            print('duration picked: ', results.duration[index])\n",
    "            plt.figure(figsize = (10, 10))\n",
    "\n",
    "            ax = plt.gca()\n",
    "            ax.set_facecolor('None')\n",
    "            ax.axvline(period, alpha=1, lw=3.5,  color='#E4D7BA')\n",
    "            plt.xlim(np.min(results.period), np.max(results.period))\n",
    "            for n in range(2, 10):\n",
    "                ax.axvline(n*period, alpha=0.25, lw=2, linestyle=\"dashed\",  color='#E4D7BA')\n",
    "                ax.axvline(period / n, alpha=0.25, lw=2, linestyle=\"dashed\",  color='#E4D7BA')\n",
    "            for per in periods:\n",
    "                ax.axvline(per, alpha=0.6, lw=2, linestyle=\"dashed\",  color='#E4D7BA')\n",
    "\n",
    "#                         ax.axvline(results.period / n, alpha=0.4, lw=1, linestyle=\"dashed\",  color='#B06200')\n",
    "            plt.ylabel(r'SDE', fontsize = 40)\n",
    "            plt.xlabel('Period (days)', fontsize = 40)\n",
    "        \n",
    "        \n",
    "        \n",
    "#             chi2 = 1 / results.power\n",
    "#             SR = min(chi2) / chi2\n",
    "#             SDE = (1 - np.mean(SR)) / np.std(SR)\n",
    "#             SDE_power = SR - np.min(SR)      # shift down to touch 0\n",
    "#             scale = SDE / np.max(SDE_power)  # scale factor to touch max=SDE\n",
    "#             SDE_power = SDE_power * scale\n",
    "            \n",
    "            \n",
    "            \n",
    "            ax.plot(results.period, results.power, color = '#EB8300', lw=0.65)\n",
    "            ax.plot(results.period, results.power_final, color = 'k', lw=0.65)\n",
    "            ax.scatter(results.period, my_median, color = 'r')\n",
    "            \n",
    "#             plt.xlim(0, 100.);\n",
    "            ax.xaxis.label.set_color('#BC9B54')        #setting up X-axis label color to yellow\n",
    "            ax.yaxis.label.set_color('#BC9B54')          #setting up Y-axis label color to blue\n",
    "\n",
    "            ax.tick_params(axis='x', colors='#BC9B54', labelsize = 35, width=3, length = 8)    #setting up X-axis tick color to red\n",
    "            ax.tick_params(axis='y', colors='#BC9B54', labelsize = 35, width=3, length = 8)  #setting up Y-axis tick color to black\n",
    "\n",
    "            ax.spines['left'].set_color(None)        # setting up Y-axis tick color to red\n",
    "            ax.spines['bottom'].set_color(None)         #setting up above X-axis tick color to red\n",
    "            ax.spines['top'].set_color(None)        # setting up Y-axis tick color to red\n",
    "            ax.spines['right'].set_color(None)         #setting up above X-axis tick color to red\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            t0 = results.transit_time[index]\n",
    "            duration = results.duration[index]\n",
    "            \n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "            plt.figure(figsize = (10, 10))\n",
    "            ax2 = plt.gca()\n",
    "            ax2.xaxis.label.set_color('#BC9B54')        #setting up X-axis label color to yellow\n",
    "            ax2.yaxis.label.set_color('#BC9B54')          #setting up Y-axis label color to blue\n",
    "\n",
    "            ax2.tick_params(axis='x', colors='#BC9B54', labelsize = 35, width=3, length = 8)    #setting up X-axis tick color to red\n",
    "            ax2.tick_params(axis='y', colors='#BC9B54', labelsize = 35, width=3, length = 8)  #setting up Y-axis tick color to black\n",
    "            ax2.spines['top'].set_color(None)        # setting up Y-axis tick color to red\n",
    "            ax2.spines['right'].set_color(None)         #setting up above X-axis tick color to red\n",
    "\n",
    "            ax2.spines['left'].set_color(None)        # setting up Y-axis tick color to red\n",
    "            ax2.spines['bottom'].set_color(None)         #setting up above X-axis tick color to red\n",
    "\n",
    "            ax2.set_facecolor('None')\n",
    "\n",
    "            x = ((time - t0 + 0.5*period) % period) -( 0.5*period)\n",
    "            m = np.abs(x) < 0.5\n",
    "            ax2.scatter(\n",
    "                x[m],\n",
    "                flux[m],\n",
    "                color='#E4D7BA',\n",
    "                s=10,\n",
    "                alpha=0.8,\n",
    "                zorder=2)\n",
    "\n",
    "            x_new = np.linspace(-0.5, 0.5, 1000)\n",
    "            f = model.model(x_new + t0, period, duration, t0)\n",
    "\n",
    "            ax2.plot(x_new, f, color='#EB8300', lw = 6.5)\n",
    "#             ax2.set_xlim(-0.5, 0.5)\n",
    "            ax2.set_xlabel('Phase', color = '#BC9B54', fontsize = 40)\n",
    "            ax2.set_ylabel('Relative Flux', color = '#BC9B54', fontsize = 40);\n",
    "            plt.show()\n",
    "            print('T0: ', results.transit_time[index], 'duration: ', results.duration[index], 'npoints_dur: ', np.ceil(results.duration[index]/30.))\n",
    "        if not np.abs(np.diff(np.array(sorted(results.power_final))[[-1, -2]]))>2*np.nanstd(np.diff(results.power_final)) or len(time_new)==0 :\n",
    "\n",
    "            print('done with multis!')\n",
    "            print('per', periods)\n",
    "\n",
    "            return np.array(periods), np.array(T0), np.array(Tdur), np.array(depths)\n",
    "        else: \n",
    "            intransit = np.logical_or(intransit, transit_mask(time, results.period[index], 2*results.duration[index]+(2*0.04), results.transit_time[index]))\n",
    "            \n",
    "            depths.append(1-results.depth[index])\n",
    "            periods.append(results.period[index])\n",
    "            T0.append(results.transit_time[index])\n",
    "            Tdur.append(results.duration[index])\n",
    "\n",
    "            return using_BLS_to_find_periodic_signals(time, flux, u, intransit=intransit, verbose = verbose,  periods = periods, T0 = T0, Tdur = Tdur, depths = depths, first = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79f693b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catalog_info(ticid, df = False):\n",
    "    if type(df) == bool:\n",
    "        ctlfile = './Total_Mdwarf_files/final_mdwarf_params_new.csv'\n",
    "        mdwarfs = pd.read_csv(ctlfile, iterator =True, chunksize = 100000, index_col=None, header = 0)\n",
    "        df = pd.concat(\n",
    "            [chunk[chunk['TICID'].astype(int) == ticid] \n",
    "            for chunk in mdwarfs]\n",
    "        ).reset_index(drop=True)\n",
    "    else:\n",
    "        df = df[df['TICID']==ticid]\n",
    "    return df[['aLSM', 'bLSM']].values[0].astype(float), float(df['Mass']), float(df['eMass']), float(df['eMass']), float(df['Rad']), float(df['eRad']), float(df['eRad'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8e8f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f21d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def running_periodic_search(files, ):\n",
    "    total_time, total_flux = get_data(files)\n",
    "\n",
    "    time = total_time[np.argsort(total_time)]\n",
    "    flux = total_flux[np.argsort(total_time)]\n",
    "    flux_err = np.full(len(flux), np.std(flux))\n",
    "\n",
    "    \n",
    "    brk = np.append(np.append([0], find_breaks(total_sorted_times)), [len(total_sorted_times)])\n",
    "\n",
    "    indexes = breaking_up_data(new_time, brk)\n",
    "    split_times    = [time[indx]     for indx in indexes]\n",
    "    split_flux     = [flux[indx]     for indx in indexes]\n",
    "    split_flux_err = [flux_err[indx] for indx in indexes]\n",
    "    \n",
    "    intransit = np.full(len(total_sorted_times), False)\n",
    "\n",
    "    tf = []\n",
    "    for mmm in range(len(split_times)):\n",
    "        tf.append([split_times[mmm], split_fluxes[mmm]])\n",
    "#         print('is this working?', len(tf[mmm]), len(tf[mmm][0]), len(tf[mmm][1]))\n",
    "\n",
    "\n",
    "#     time, flux = new_binning_function_by_time(list(time), list(flux), 10.)\n",
    "    print(len(time), len(flux))\n",
    "\n",
    "    print('running periodic search')\n",
    "\n",
    "    periods_multis, T0_multis, Tdur_multis, depth_multis = using_BLS_to_find_periodic_signals(time, flux, u = ab, verbose = verbose)\n",
    "    \n",
    "    for iii in range(len(periods_multis)):\n",
    "        \n",
    "        intransit = np.logical_or(intransit, transit_mask(total_sorted_times, periods_multis[iii], (2*Tdur_multis[iii])+0.08, T0_multis[iii]))\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f86c9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48f277df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(data, window_size):\n",
    "    \"\"\"Returns the moving average of an array `data`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array of numbers\n",
    "        The running mean will be computed on this data.\n",
    "    window_size : int\n",
    "        Window length used to compute the running mean.\n",
    "    \"\"\"\n",
    "    cumsum = np.cumsum(np.insert(data, 0, 0))\n",
    "    return (cumsum[window_size:] - cumsum[:-window_size]) / float(window_size)\n",
    "\n",
    "\n",
    "def mask_outliers(time, flux, sigma = 4.5, sigma_lower=None, sigma_upper=None, **kwargs):\n",
    "    outlier_mask = sigma_clip(data=flux,\n",
    "                              sigma=sigma,\n",
    "                              sigma_lower=sigma_lower,\n",
    "                              sigma_upper=sigma_upper,\n",
    "                              **kwargs).mask\n",
    "    # Second, we return the masked light curve and optionally the mask itself\n",
    "    return outlier_mask\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def remove_outliers(time, flux, sigma = 4.5, sigma_lower=None, sigma_upper=None, **kwargs):\n",
    "    outlier_mask = sigma_clip(data=flux,\n",
    "                              sigma=sigma,\n",
    "                              sigma_lower=sigma_lower,\n",
    "                              sigma_upper=sigma_upper,\n",
    "                              **kwargs).mask\n",
    "    # Second, we return the masked light curve and optionally the mask itself\n",
    "    return time[~outlier_mask], flux[~outlier_mask]\n",
    "    \n",
    "def flatten_lc(time, flux):\n",
    "    flat_flux, flux_trend = flatten(\n",
    "    time,                 # Array of time values\n",
    "    flux,                 # Array of flux values\n",
    "    method='biweight',\n",
    "    window_length=0.9,    # The length of the filter window in units of ``time``\n",
    "#     edge_cutoff=0.1,      # length (in units of time) to be cut off each edge.\n",
    "#     break_tolerance=1,  # Split into segments at breaks longer than that\n",
    "    return_trend=True,    # Return trend and flattened light curve\n",
    "#     cval=5.0              # Tuning parameter for the robust estimators\n",
    "    )\n",
    "    return flat_flux, flux_trend\n",
    "\n",
    "def cleaning_up_data(time, flux):\n",
    "#     flux = flux/np.nanmedian(flux)\n",
    "#     try: \n",
    "#         flattened_flux = flatten_lc(time, flux)\n",
    "\n",
    "#     except Exception as error: \n",
    "#         flattened_flux = flux\n",
    "\n",
    "    cleaned_time, cleaned_flux = remove_outliers(time, flux)\n",
    "    return cleaned_time, cleaned_flux\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_data(fits_files_lst_for_target):\n",
    "    total_time = []\n",
    "    total_flux = []\n",
    "    total_flux_err = []\n",
    "\n",
    "\n",
    "    for i in fits_files_lst_for_target:\n",
    "#         sector = np.int64(i.split('/')[7].split('_')[4].split('-')[0][1:])\n",
    "#         print('sector', sector)\n",
    "#         if sector > 34:\n",
    "#             print(hdulist)\n",
    "\n",
    "        hdulist=apf.open(i) #fits time series\n",
    "\n",
    "        tbdata = hdulist[1].data\n",
    "#         print(tbdata)\n",
    "        qual         = tbdata.QUALITY == 0\n",
    "\n",
    "        time, flux = tbdata.TIME[qual], tbdata.SAP_FLUX[qual]\n",
    "        \n",
    "        print('init time', len(time))\n",
    "\n",
    "        flux = flux/np.nanmedian(flux)\n",
    "        flux, time = flux[~np.isnan(flux)], time[~np.isnan(flux)]\n",
    "\n",
    "        cleaned_time, cleaned_flux = cleaning_up_data(time, flux)\n",
    "\n",
    "        flat_flux, flat_trend = flatten_lc(cleaned_time, cleaned_flux)\n",
    "\n",
    "        flat_flux_err = np.full(len(flat_flux), np.std(flat_flux))\n",
    "        \n",
    "        total_time.extend(cleaned_time)\n",
    "        total_flux.extend(flat_flux)\n",
    "        total_flux_err.extend(flat_flux_err)\n",
    "\n",
    "#         plt.scatter(total_time, total_flux)\n",
    "#         plt.show()BaseException\n",
    "    print('total_time', len(total_time))\n",
    "    return np.array(total_time), np.array(total_flux), np.array(total_flux_err)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1fe1530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catalog_info(ticid, df = False):\n",
    "    if type(df) == bool:\n",
    "        ctlfile = './Total_Mdwarf_files/final_mdwarf_params_new.csv'\n",
    "        mdwarfs = pd.read_csv(ctlfile, iterator =True, chunksize = 100000, index_col=None, header = 0)\n",
    "        df = pd.concat(\n",
    "            [chunk[chunk['TICID'].astype(int) == ticid] \n",
    "            for chunk in mdwarfs]\n",
    "        ).reset_index(drop=True)\n",
    "    else:\n",
    "        df = df[df['TICID']==ticid]\n",
    "    return df[['aLSM', 'bLSM']].values[0].astype(float), float(df['Mass']), float(df['eMass']), float(df['eMass']), float(df['Rad']), float(df['eRad']), float(df['eRad'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e80ce3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctlfile = './Total_Mdwarf_files/final_mdwarf_params.csv'\n",
    "mdwarfs = pd.read_csv(ctlfile, iterator =True, chunksize = 100000, index_col=None)\n",
    "\n",
    "mdwarfs_known = pd.concat(\n",
    "    [chunk[chunk['TICID'].astype(int).isin(TICIDs)] \n",
    "    for chunk in mdwarfs]\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "572a05b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512ca77fa54f4678bee256ddd96da698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 targets | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mdwarfs_known =match_logg_and_teff_for_LDC(mdwarfs_known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46109af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TICID</th>\n",
       "      <th>RA</th>\n",
       "      <th>DEC</th>\n",
       "      <th>Vmag</th>\n",
       "      <th>Jmag</th>\n",
       "      <th>Tmag</th>\n",
       "      <th>Teff</th>\n",
       "      <th>eTeff_x</th>\n",
       "      <th>Rad</th>\n",
       "      <th>eRad</th>\n",
       "      <th>...</th>\n",
       "      <th>S54</th>\n",
       "      <th>S55</th>\n",
       "      <th>eTeff_y</th>\n",
       "      <th>logg</th>\n",
       "      <th>elogg</th>\n",
       "      <th>M/H</th>\n",
       "      <th>eM/H</th>\n",
       "      <th>GAIA</th>\n",
       "      <th>aLSM</th>\n",
       "      <th>bLSM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>261257684.0</td>\n",
       "      <td>89.372315</td>\n",
       "      <td>-83.130204</td>\n",
       "      <td>12.588</td>\n",
       "      <td>9.607</td>\n",
       "      <td>10.8460</td>\n",
       "      <td>3751.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.532439</td>\n",
       "      <td>0.015794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.70914</td>\n",
       "      <td>0.009127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.620844e+18</td>\n",
       "      <td>0.2581</td>\n",
       "      <td>0.3609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150428135.0</td>\n",
       "      <td>97.096787</td>\n",
       "      <td>-65.579312</td>\n",
       "      <td>13.151</td>\n",
       "      <td>9.469</td>\n",
       "      <td>10.9102</td>\n",
       "      <td>3494.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.419457</td>\n",
       "      <td>0.012573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.80892</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.284518e+18</td>\n",
       "      <td>0.1604</td>\n",
       "      <td>0.4325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>219195044.0</td>\n",
       "      <td>92.391740</td>\n",
       "      <td>-53.823484</td>\n",
       "      <td>13.311</td>\n",
       "      <td>10.241</td>\n",
       "      <td>11.5436</td>\n",
       "      <td>3731.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.473141</td>\n",
       "      <td>0.014147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.76101</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.500474e+18</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.4118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>259377017.0</td>\n",
       "      <td>68.415501</td>\n",
       "      <td>-51.956232</td>\n",
       "      <td>12.603</td>\n",
       "      <td>9.099</td>\n",
       "      <td>10.4981</td>\n",
       "      <td>3532.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.374358</td>\n",
       "      <td>0.011496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.85053</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.781196e+18</td>\n",
       "      <td>0.1604</td>\n",
       "      <td>0.4325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36724087.0</td>\n",
       "      <td>154.646405</td>\n",
       "      <td>-11.716734</td>\n",
       "      <td>13.140</td>\n",
       "      <td>9.007</td>\n",
       "      <td>10.5848</td>\n",
       "      <td>3331.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.374139</td>\n",
       "      <td>0.011184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.85074</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.767282e+18</td>\n",
       "      <td>0.1529</td>\n",
       "      <td>0.4604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>235678745.0</td>\n",
       "      <td>285.633044</td>\n",
       "      <td>75.418605</td>\n",
       "      <td>13.190</td>\n",
       "      <td>9.797</td>\n",
       "      <td>11.0788</td>\n",
       "      <td>3746.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.463205</td>\n",
       "      <td>0.013592</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.76979</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.268372e+18</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.4118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>441798995.0</td>\n",
       "      <td>264.147791</td>\n",
       "      <td>77.126122</td>\n",
       "      <td>13.476</td>\n",
       "      <td>10.765</td>\n",
       "      <td>11.9521</td>\n",
       "      <td>3872.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.548484</td>\n",
       "      <td>0.016161</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.69525</td>\n",
       "      <td>0.009462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.657159e+18</td>\n",
       "      <td>0.2946</td>\n",
       "      <td>0.3316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>284441182.0</td>\n",
       "      <td>10.088709</td>\n",
       "      <td>61.213626</td>\n",
       "      <td>13.459</td>\n",
       "      <td>10.154</td>\n",
       "      <td>11.4752</td>\n",
       "      <td>3624.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.490120</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.74607</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.272241e+17</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.3984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>467179528.0</td>\n",
       "      <td>197.998168</td>\n",
       "      <td>65.833807</td>\n",
       "      <td>12.941</td>\n",
       "      <td>9.706</td>\n",
       "      <td>11.0402</td>\n",
       "      <td>3618.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.435666</td>\n",
       "      <td>0.012939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.79432</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.678074e+18</td>\n",
       "      <td>0.1671</td>\n",
       "      <td>0.4201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TICID          RA        DEC    Vmag    Jmag     Tmag    Teff  \\\n",
       "0  261257684.0   89.372315 -83.130204  12.588   9.607  10.8460  3751.0   \n",
       "1  150428135.0   97.096787 -65.579312  13.151   9.469  10.9102  3494.0   \n",
       "2  219195044.0   92.391740 -53.823484  13.311  10.241  11.5436  3731.0   \n",
       "3  259377017.0   68.415501 -51.956232  12.603   9.099  10.4981  3532.0   \n",
       "4   36724087.0  154.646405 -11.716734  13.140   9.007  10.5848  3331.0   \n",
       "5  235678745.0  285.633044  75.418605  13.190   9.797  11.0788  3746.0   \n",
       "6  441798995.0  264.147791  77.126122  13.476  10.765  11.9521  3872.0   \n",
       "7  284441182.0   10.088709  61.213626  13.459  10.154  11.4752  3624.0   \n",
       "8  467179528.0  197.998168  65.833807  12.941   9.706  11.0402  3618.0   \n",
       "\n",
       "   eTeff_x       Rad      eRad  ...   S54   S55  eTeff_y     logg     elogg  \\\n",
       "0    157.0  0.532439  0.015794  ...   0.0   0.0    157.0  4.70914  0.009127   \n",
       "1    157.0  0.419457  0.012573  ...   0.0   0.0    157.0  4.80892  0.004651   \n",
       "2    157.0  0.473141  0.014147  ...   0.0   0.0    157.0  4.76101  0.007200   \n",
       "3    157.0  0.374358  0.011496  ...   0.0   0.0    157.0  4.85053  0.002090   \n",
       "4    157.0  0.374139  0.011184  ...   0.0   0.0    157.0  4.85074  0.001634   \n",
       "5    157.0  0.463205  0.013592  ...  10.0  10.0    157.0  4.76979  0.006479   \n",
       "6    157.0  0.548484  0.016161  ...  10.0  10.0    157.0  4.69525  0.009462   \n",
       "7    157.0  0.490120  0.014531  ...   0.0   0.0    157.0  4.74607  0.007723   \n",
       "8    157.0  0.435666  0.012939  ...   0.0   0.0    157.0  4.79432  0.005376   \n",
       "\n",
       "   M/H eM/H          GAIA    aLSM    bLSM  \n",
       "0  NaN  NaN  4.620844e+18  0.2581  0.3609  \n",
       "1  NaN  NaN  5.284518e+18  0.1604  0.4325  \n",
       "2  NaN  NaN  5.500474e+18  0.1737  0.4118  \n",
       "3  NaN  NaN  4.781196e+18  0.1604  0.4325  \n",
       "4  NaN  NaN  3.767282e+18  0.1529  0.4604  \n",
       "5  NaN  NaN  2.268372e+18  0.1737  0.4118  \n",
       "6  NaN  NaN  1.657159e+18  0.2946  0.3316  \n",
       "7  NaN  NaN  4.272241e+17  0.2125  0.3984  \n",
       "8  NaN  NaN  1.678074e+18  0.1671  0.4201  \n",
       "\n",
       "[9 rows x 80 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdwarfs_known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a7475476",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './model_TESS.pth'\n",
    "\n",
    "\n",
    "def make_LightKurveObject(time, flux, flux_err):\n",
    "    \"\"\" Convert this object to a lightkurve.lightcurve.TessLightCurve object to use for Deep Transit.\n",
    "\n",
    "    :return: Data in a lightkurve object\n",
    "    :rtype: `class` lightkurve.lightcurve.TessLightCurve\n",
    "    \"\"\"\n",
    "    lc = lk.TessLightCurve()\n",
    "    lc.time = time\n",
    "    lc.flux = flux\n",
    "    lc.flux_err = flux_err\n",
    "    return lc\n",
    "\n",
    "\n",
    "def DT_analysis(time, flux, flux_err, DT_Quite=True, is_flat = True):\n",
    "    \"\"\" \n",
    "    @author: D. Dragomir, P.Steimle\n",
    "\n",
    "\n",
    "    Function for the Deep Transit analysis (Cui et al. 2021) that returns only single transit events\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # create a new dataset for the while loop where transits can be masked out\n",
    "\n",
    "\n",
    "    if DT_Quite == True:\n",
    "        save_stdout = sys.stdout\n",
    "        save_stderr = sys.stderr\n",
    "        sys.stdout = open('.trash.txt', 'w')\n",
    "        sys.stderr = open('.trash.txt', 'w')\n",
    "\n",
    "        # do check for transits with DT\n",
    "        DT_model = dt.DeepTransit(make_LightKurveObject(time, flux, flux_err),  is_flat=is_flat)\n",
    "        bboxes = DT_model.transit_detection(model_path, confidence_threshold=0.6)\n",
    "\n",
    "        sys.stdout = save_stdout\n",
    "        sys.stderr = save_stderr\n",
    "\n",
    "    else:\n",
    "        # do check for transits with DT\n",
    "        DT_model = dt.DeepTransit(make_LightKurveObject(time, flux, flux_err), is_flat=is_flat)\n",
    "        bboxes = DT_model.transit_detection(model_path, confidence_threshold=0.6)\n",
    "\n",
    "        # if only 1 or 0 boxes were found, break the loop and continue\n",
    "\n",
    "    return bboxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b7f48e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_binning_function_by_time(time, flux, time_size_of_bins): \n",
    "    # Written by Mallory Harris\n",
    "\n",
    "    # Description: bins data in time, flux, and raw flux arrays as their mean value based on given time interval\n",
    "\n",
    "    # Arguments : time              = array of time, in days\n",
    "    #             flux              = array of flux \n",
    "    #             time_size_of_bins = bin size for time intervals, in minutes\n",
    "\n",
    "\n",
    "    # Return    : list of binned time, flux and \n",
    "    time = np.array(time).byteswap().newbyteorder()  #changes how the arrays are represented in memory\n",
    "    flux = np.array(flux).byteswap().newbyteorder() \n",
    "\n",
    "    interval = time_size_of_bins/60./24.#change units from minutes to days\n",
    "    df = pd.DataFrame({'time': time, 'flux':flux})\n",
    "    df = df.append(df)\n",
    "    #print(df)\n",
    "    numbins = np.array(list(range(int(np.ceil((max(time)-min(time))/interval))+1)))\n",
    "    #print(df)\n",
    "    bins = np.array([min(time)+x*interval for x in numbins])\n",
    "    #print(bins)\n",
    "    df['time_bins'] = pd.cut(df.time, bins)\n",
    "    new_time = [x for x in df.groupby('time_bins').mean()['time'] if not math.isnan(x)] #finds the mean value of binned time\n",
    "    new_flux = [x for x in df.groupby('time_bins').mean()['flux'] if not math.isnan(x)] #finds the mean value of binned flux\n",
    "    #print(len(new_time), len(new_flux), len(new_raw))\n",
    "    return np.array(new_time), np.array(new_flux)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f0515602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lc_with_bboxes(lc_object, bboxes, ax=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot light curve with bounding boxes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lc_object : `~lightkurve.LightCurve` instance\n",
    "\n",
    "    bboxes : list or np.ndarray\n",
    "                Bounding boxes in shape (N, 5)\n",
    "\n",
    "    ax : `~matplotlib.pyplot.axis` instance\n",
    "                Axis to plot to. If None, create a new one.\n",
    "    kwargs : dict\n",
    "                Additional arguments to be passed to `matplotlib.pyplot.plot`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ax : `~matplotlib.pyplot.axis` instance\n",
    "                The matplotlib axes object.\n",
    "    \"\"\"\n",
    "    with plt.style.context('grayscale'):\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(1, figsize=(12, 26), constrained_layout=False)\n",
    "            ax.plot(lc_object.time.value, lc_object.flux.value, color = '#996633', **kwargs)\n",
    "        else:\n",
    "            ax.plot(lc_object.time.value, lc_object.flux.value,color = '#996633', **kwargs)\n",
    "        from matplotlib.patches import Rectangle\n",
    "        from matplotlib.collections import PatchCollection\n",
    "        recs = []\n",
    "        for real_mask in bboxes:\n",
    "            rec = Rectangle((real_mask[1] - real_mask[3] / 2, real_mask[2] - real_mask[4] / 2),\n",
    "                            real_mask[3],\n",
    "                            real_mask[4], fill=False, color='#CC9966')\n",
    "            recs.append(rec)\n",
    "\n",
    "            ax.text(\n",
    "                real_mask[1] - real_mask[3] / 2,\n",
    "                real_mask[2] + real_mask[4] / 2,\n",
    "                s=f\"{real_mask[0]:.2f}\",\n",
    "                color='white',\n",
    "                verticalalignment=\"top\",\n",
    "                bbox=dict(alpha=0.75, color='#996633'),\n",
    "                clip_on=True\n",
    "            )\n",
    "\n",
    "        pc = PatchCollection(recs, facecolor='none', edgecolor='#CC9966', lw=1, zorder=3)\n",
    "        ax.add_collection(pc)\n",
    "        ax.set_xlabel('Time (day)', color = '#CCFFFF', fontsize = 25)\n",
    "        ax.set_ylabel('Normalized Flux', color = '#CCFFFF', fontsize = 25)\n",
    "    return ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20435e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epochs(T0, per, min_time, max_time):\n",
    "    epochs_big = np.array(list(range(-150, 150)))\n",
    "    new_epochs = T0+(np.array(list(range(-150, 150)))*per)\n",
    "    \n",
    "#     print('new epochs', new_epochs)\n",
    "    epochs = new_epochs[new_epochs>min_time]\n",
    "#     print('epochs', epochs)\n",
    "    epochs = epochs[epochs<max_time]\n",
    "    \n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19d875c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "toi_700_t0  = [1330.48, 1352.9912, 2303.16, 2349.04]\n",
    "toi_700_per = [37.4243, 27.8094, 16.0511, 9.97731]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1d8aa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TICID</th>\n",
       "      <th>RA</th>\n",
       "      <th>DEC</th>\n",
       "      <th>Vmag</th>\n",
       "      <th>Jmag</th>\n",
       "      <th>Tmag</th>\n",
       "      <th>Teff</th>\n",
       "      <th>eTeff_x</th>\n",
       "      <th>Rad</th>\n",
       "      <th>eRad</th>\n",
       "      <th>...</th>\n",
       "      <th>S54</th>\n",
       "      <th>S55</th>\n",
       "      <th>eTeff_y</th>\n",
       "      <th>logg</th>\n",
       "      <th>elogg</th>\n",
       "      <th>M/H</th>\n",
       "      <th>eM/H</th>\n",
       "      <th>GAIA</th>\n",
       "      <th>aLSM</th>\n",
       "      <th>bLSM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>261257684.0</td>\n",
       "      <td>89.372315</td>\n",
       "      <td>-83.130204</td>\n",
       "      <td>12.588</td>\n",
       "      <td>9.607</td>\n",
       "      <td>10.8460</td>\n",
       "      <td>3751.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.532439</td>\n",
       "      <td>0.015794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.70914</td>\n",
       "      <td>0.009127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.620844e+18</td>\n",
       "      <td>0.2581</td>\n",
       "      <td>0.3609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150428135.0</td>\n",
       "      <td>97.096787</td>\n",
       "      <td>-65.579312</td>\n",
       "      <td>13.151</td>\n",
       "      <td>9.469</td>\n",
       "      <td>10.9102</td>\n",
       "      <td>3494.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.419457</td>\n",
       "      <td>0.012573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.80892</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.284518e+18</td>\n",
       "      <td>0.1604</td>\n",
       "      <td>0.4325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>219195044.0</td>\n",
       "      <td>92.391740</td>\n",
       "      <td>-53.823484</td>\n",
       "      <td>13.311</td>\n",
       "      <td>10.241</td>\n",
       "      <td>11.5436</td>\n",
       "      <td>3731.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.473141</td>\n",
       "      <td>0.014147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.76101</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.500474e+18</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.4118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>259377017.0</td>\n",
       "      <td>68.415501</td>\n",
       "      <td>-51.956232</td>\n",
       "      <td>12.603</td>\n",
       "      <td>9.099</td>\n",
       "      <td>10.4981</td>\n",
       "      <td>3532.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.374358</td>\n",
       "      <td>0.011496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.85053</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.781196e+18</td>\n",
       "      <td>0.1604</td>\n",
       "      <td>0.4325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36724087.0</td>\n",
       "      <td>154.646405</td>\n",
       "      <td>-11.716734</td>\n",
       "      <td>13.140</td>\n",
       "      <td>9.007</td>\n",
       "      <td>10.5848</td>\n",
       "      <td>3331.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.374139</td>\n",
       "      <td>0.011184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.85074</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.767282e+18</td>\n",
       "      <td>0.1529</td>\n",
       "      <td>0.4604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>235678745.0</td>\n",
       "      <td>285.633044</td>\n",
       "      <td>75.418605</td>\n",
       "      <td>13.190</td>\n",
       "      <td>9.797</td>\n",
       "      <td>11.0788</td>\n",
       "      <td>3746.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.463205</td>\n",
       "      <td>0.013592</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.76979</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.268372e+18</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.4118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>441798995.0</td>\n",
       "      <td>264.147791</td>\n",
       "      <td>77.126122</td>\n",
       "      <td>13.476</td>\n",
       "      <td>10.765</td>\n",
       "      <td>11.9521</td>\n",
       "      <td>3872.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.548484</td>\n",
       "      <td>0.016161</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.69525</td>\n",
       "      <td>0.009462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.657159e+18</td>\n",
       "      <td>0.2946</td>\n",
       "      <td>0.3316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>284441182.0</td>\n",
       "      <td>10.088709</td>\n",
       "      <td>61.213626</td>\n",
       "      <td>13.459</td>\n",
       "      <td>10.154</td>\n",
       "      <td>11.4752</td>\n",
       "      <td>3624.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.490120</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.74607</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.272241e+17</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.3984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>467179528.0</td>\n",
       "      <td>197.998168</td>\n",
       "      <td>65.833807</td>\n",
       "      <td>12.941</td>\n",
       "      <td>9.706</td>\n",
       "      <td>11.0402</td>\n",
       "      <td>3618.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.435666</td>\n",
       "      <td>0.012939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.79432</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.678074e+18</td>\n",
       "      <td>0.1671</td>\n",
       "      <td>0.4201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TICID          RA        DEC    Vmag    Jmag     Tmag    Teff  \\\n",
       "0  261257684.0   89.372315 -83.130204  12.588   9.607  10.8460  3751.0   \n",
       "1  150428135.0   97.096787 -65.579312  13.151   9.469  10.9102  3494.0   \n",
       "2  219195044.0   92.391740 -53.823484  13.311  10.241  11.5436  3731.0   \n",
       "3  259377017.0   68.415501 -51.956232  12.603   9.099  10.4981  3532.0   \n",
       "4   36724087.0  154.646405 -11.716734  13.140   9.007  10.5848  3331.0   \n",
       "5  235678745.0  285.633044  75.418605  13.190   9.797  11.0788  3746.0   \n",
       "6  441798995.0  264.147791  77.126122  13.476  10.765  11.9521  3872.0   \n",
       "7  284441182.0   10.088709  61.213626  13.459  10.154  11.4752  3624.0   \n",
       "8  467179528.0  197.998168  65.833807  12.941   9.706  11.0402  3618.0   \n",
       "\n",
       "   eTeff_x       Rad      eRad  ...   S54   S55  eTeff_y     logg     elogg  \\\n",
       "0    157.0  0.532439  0.015794  ...   0.0   0.0    157.0  4.70914  0.009127   \n",
       "1    157.0  0.419457  0.012573  ...   0.0   0.0    157.0  4.80892  0.004651   \n",
       "2    157.0  0.473141  0.014147  ...   0.0   0.0    157.0  4.76101  0.007200   \n",
       "3    157.0  0.374358  0.011496  ...   0.0   0.0    157.0  4.85053  0.002090   \n",
       "4    157.0  0.374139  0.011184  ...   0.0   0.0    157.0  4.85074  0.001634   \n",
       "5    157.0  0.463205  0.013592  ...  10.0  10.0    157.0  4.76979  0.006479   \n",
       "6    157.0  0.548484  0.016161  ...  10.0  10.0    157.0  4.69525  0.009462   \n",
       "7    157.0  0.490120  0.014531  ...   0.0   0.0    157.0  4.74607  0.007723   \n",
       "8    157.0  0.435666  0.012939  ...   0.0   0.0    157.0  4.79432  0.005376   \n",
       "\n",
       "   M/H eM/H          GAIA    aLSM    bLSM  \n",
       "0  NaN  NaN  4.620844e+18  0.2581  0.3609  \n",
       "1  NaN  NaN  5.284518e+18  0.1604  0.4325  \n",
       "2  NaN  NaN  5.500474e+18  0.1737  0.4118  \n",
       "3  NaN  NaN  4.781196e+18  0.1604  0.4325  \n",
       "4  NaN  NaN  3.767282e+18  0.1529  0.4604  \n",
       "5  NaN  NaN  2.268372e+18  0.1737  0.4118  \n",
       "6  NaN  NaN  1.657159e+18  0.2946  0.3316  \n",
       "7  NaN  NaN  4.272241e+17  0.2125  0.3984  \n",
       "8  NaN  NaN  1.678074e+18  0.1671  0.4201  \n",
       "\n",
       "[9 rows x 80 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdwarfs_known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "639bf4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2018206045859-s0001-0000000150428135-0120-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2018263035959-s0003-0000000150428135-0123-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2018292075959-s0004-0000000150428135-0124-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2018319095959-s0005-0000000150428135-0125-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2018349182500-s0006-0000000150428135-0126-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2019006130736-s0007-0000000150428135-0131-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2019032160000-s0008-0000000150428135-0136-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2019058134432-s0009-0000000150428135-0139-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2019085135100-s0010-0000000150428135-0140-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2019112060037-s0011-0000000150428135-0143-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2019169103026-s0013-0000000150428135-0146-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2020186164531-s0027-0000000150428135-0189-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2020212050318-s0028-0000000150428135-0190-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2020266004630-s0030-0000000150428135-0195-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2020294194027-s0031-0000000150428135-0198-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2020351194500-s0033-0000000150428135-0203-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2021014023720-s0034-0000000150428135-0204-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2021039152502-s0035-0000000150428135-0205-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2021065132309-s0036-0000000150428135-0207-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2021091135823-s0037-0000000150428135-0208-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2021118034608-s0038-0000000150428135-0209-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2023018032328-s0061-0000000150428135-0250-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2023043185947-s0062-0000000150428135-0254-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2023069172124-s0063-0000000150428135-0255-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2023096110322-s0064-0000000150428135-0257-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2023124020739-s0065-0000000150428135-0259-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2023153011303-s0066-0000000150428135-0260-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2023209231226-s0068-0000000150428135-0262-s',\n",
       " './known_Mdwarfs_data/PS_data/tic_150428135/mastDownload/TESS/tess2023237165326-s0069-0000000150428135-0264-s']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fits_files = sorted(glob.glob('./known_Mdwarfs_data/PS_data/tic_'+str(150428135)+'/*/*/*'))\n",
    "fits_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3e4ce0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['TICID', 'planet_name', 'period', 'T0', 'Tdur', 'depth']\n",
    "\n",
    "# final_file = './search_mdwarf_planets.csv'\n",
    "new_planet_df = pd.DataFrame(columns=column_names)\n",
    "print(new_planet_df)\n",
    "\n",
    "\n",
    "for iii in TICIDs[:1]:\n",
    "    \n",
    "    print(iii)\n",
    "    fits_files = sorted(glob.glob('./known_Mdwarfs_data/FFI_data/all_target_data/tic_'+str(iii)+'_all/*/*/*/*.fits'))\n",
    "#     fits_files = fits_files\n",
    "#     print(len(fits_files))\n",
    "#     fits_files = sorted(glob.glob('./known_Mdwarfs_data/FFI_data/*/*/*/*'+str(iii)+'*/*.fits'))\n",
    "\n",
    "    count = 0\n",
    "#     if len(fits_files)>0:\n",
    "    for file in fits_files:\n",
    "        sector = np.int64(file.split('/')[7].split('_')[4].split('-')[0][1:])\n",
    "        print('sector new', sector)\n",
    "\n",
    "        file = [file]\n",
    "        count +=1\n",
    "    # print(tess_spoc_fits)\n",
    "        print('num files', len(file))\n",
    "    #     fits_files\n",
    "        ab, smass, smass_min, smass_max, sradius, sradius_min, sradius_max = get_catalog_info(iii, mdwarfs_known)\n",
    "        print('val', ab)\n",
    "        \n",
    "        total_time, total_flux, total_flux_err = get_data(file)\n",
    "\n",
    "        time = total_time[np.argsort(total_time)]\n",
    "        flux = total_flux[np.argsort(total_time)]\n",
    "        flux_err = total_flux_err[np.argsort(total_time)]\n",
    "        if np.median(np.diff(time) < 10/60/24):\n",
    "            print('binned')\n",
    "            binned_time, binned_flux = new_binning_function_by_time(time, flux, 10)\n",
    "#         flux_err = np.full(len(flux), np.std(flux))\n",
    "        \n",
    "#         indexes = breaking_up_data(new_time, brk)\n",
    "#         split_times    = [time[indx]     for indx in indexes]\n",
    "#         split_flux     = [flux[indx]     for indx in indexes]\n",
    "#         split_flux_err = [flux_err[indx] for indx in indexes]\n",
    "    \n",
    "        bboxes = DT_analysis(time, flux, flux_err)\n",
    "        detrended_lc = make_LightKurveObject(time, flux, flux_err)\n",
    "    #     print(detrended_lc)\n",
    "\n",
    "        fig = plt.figure(figsize = (4.7, 9.2))\n",
    "\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.patch.set_facecolor('#CCFFFF') # instead of fig.patch.set_facecolor\n",
    "        ax.patch.set_alpha(0.65)\n",
    "        fig.patch.set_facecolor('None') # instead of fig.patch.set_facecolor\n",
    "\n",
    "        for spine in ['top', 'right']:\n",
    "            ax.spines[spine].set_visible(False)\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor('#CCFFFF')\n",
    "        ax.tick_params(color='#CCFFFF', labelcolor='#CCFFFF', labelsize = 20)\n",
    "        \n",
    "        \n",
    "        plot_lc_with_bboxes(detrended_lc, bboxes, ms=5, marker='.', lw=0, ax = ax)\n",
    "        plt.subplots_adjust(left=0.35)\n",
    "        plt.savefig('./images/toi904/new_fig_'+str(iii)+'_s'+str(sector)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57de04c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1],\n",
       " [4, 5, 6, 7, 8, 9, 10, 11],\n",
       " [13],\n",
       " [27, 28],\n",
       " [30, 31],\n",
       " [31, 32, 33, 34, 35, 36, 37, 38]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sectors = [[1], list(range(4,12)), [13], [27,28], [30, 31], list(range(31, 39))]\n",
    "sectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6fb64a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 8, 1, 2, 2, 8]\n"
     ]
    }
   ],
   "source": [
    "print([len(x)for x in sectors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02f5c316",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_indexes = [[0], list(range(1, 1+8)), [9], [10, 11], [12, 13], list(range(14, 14+6))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31106c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0],\n",
       " [1, 2, 3, 4, 5, 6, 7, 8],\n",
       " [9],\n",
       " [10, 11],\n",
       " [12, 13],\n",
       " [14, 15, 16, 17, 18, 19]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05173a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fits_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fbfb669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_extend(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list.extend(row)\n",
    "    return flat_list\n",
    "\n",
    "flat_sectors = flatten_extend(sectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82fe0d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1],\n",
       " [4, 5, 6, 7, 8, 9, 10, 11],\n",
       " [13],\n",
       " [27, 28],\n",
       " [30, 31],\n",
       " [31, 32, 33, 34, 35, 36, 37, 38]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bbb3b33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T0_2 = 2458714.3512-2457000\n",
    "\n",
    "p2 = 83.9996 #period\n",
    "\n",
    "T0_1 = 2459366.628641-2457000\n",
    "\n",
    "p1 = 10.877 #period\n",
    "\n",
    "toi904_per = [p1, p2]\n",
    "toi904_T0  = [T0_1, T0_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d606e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['TICID', 'planet_name', 'period', 'T0', 'Tdur', 'depth']\n",
    "\n",
    "# final_file = './search_mdwarf_planets.csv'\n",
    "# new_planet_df = pd.DataFrame(columns=column_names)\n",
    "# print(new_planet_df)\n",
    "\n",
    "\n",
    "iii =     261257684\n",
    "print(iii)\n",
    "fits_files = sorted(glob.glob('./known_Mdwarfs_data/PS_data/tic_'+str(261257684)+'/*/*/*/*.fits'))\n",
    "#     fits_files = fits_files\n",
    "#     print(len(fits_files))\n",
    "#     fits_files = sorted(glob.glob('./known_Mdwarfs_data/FFI_data/*/*/*/*'+str(iii)+'*/*.fits'))\n",
    "\n",
    "#     if len(fits_files)>0:fi\n",
    "\n",
    "\n",
    "# fits_files = [file for file in fits_files if np.int64(file.split('/')[6].split('-')[1].split('-')[0][1:]) in flat_sectors]\n",
    "# count = \n",
    "print('num files', len(fits_files))\n",
    "\n",
    "for file in fits_files:\n",
    "\n",
    "    sector = np.int64(file.split('/')[6].split('-')[1].split('-')[0][1:])\n",
    "#     if sector!=27:\n",
    "#         continue\n",
    "    file = [file]\n",
    "\n",
    "# print(tess_spoc_fits)\n",
    "    print('num files', len(file))\n",
    "#     fits_files\n",
    "    ab, smass, smass_min, smass_max, sradius, sradius_min, sradius_max = get_catalog_info(iii, mdwarfs_known)\n",
    "    print('val', ab)\n",
    "\n",
    "    total_time, total_flux, total_flux_err = get_data(file)\n",
    "\n",
    "    time = np.array(total_time)[np.argsort(total_time)]\n",
    "    flux = np.array(total_flux)[np.argsort(total_time)]\n",
    "    flux_err = np.array(total_flux_err)[np.argsort(total_time)]\n",
    "\n",
    "    intransit = np.logical_or(transit_mask(time, toi_700_per[3],( 2*2.12423/24)+0.1, toi_700_t0[3]), transit_mask(time, toi_700_per[2], ( 2*1.39317/24)+0.1, toi_700_t0[2]))\n",
    "    \n",
    "    time = time[~intransit]\n",
    "    flux = flux[~intransit]\n",
    "    flux_err = flux_err[~intransit]\n",
    "\n",
    "#         if np.median(np.diff(time) < 10/60/24):\n",
    "#             print('binned')\n",
    "#             binned_time, binned_flux = new_binning_function_by_time(time, flux, 10)\n",
    "#         flux_err = np.full(len(flux), np.std(flux))\n",
    "\n",
    "#         indexes = breaking_up_data(new_time, brk)\n",
    "#         split_times    = [time[indx]     for indx in indexes]\n",
    "#         split_flux     = [flux[indx]     for indx in indexes]\n",
    "#         split_flux_err = [flux_err[indx] for indx in indexes]\n",
    "\n",
    "    bboxes = DT_analysis(time, flux, flux_err)\n",
    "    detrended_lc = make_LightKurveObject(time, flux, flux_err)\n",
    "#     print(detrended_lc)\n",
    "\n",
    "    fig = plt.figure(figsize = (4.7, 9.2))\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.patch.set_facecolor('#CCFFFF') # instead of fig.patch.set_facecolor\n",
    "    ax.patch.set_alpha(0.8)\n",
    "    fig.patch.set_facecolor('None') # instead of fig.patch.set_facecolor\n",
    "\n",
    "    for spine in ['top', 'right']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('#CCFFFF')\n",
    "\n",
    "    ax.tick_params(color='#CCFFFF', labelcolor='#CCFFFF', labelsize = 20)\n",
    "\n",
    "\n",
    "    plot_lc_with_bboxes(detrended_lc, bboxes, ms=4, marker='.', lw=0, ax = ax)\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "\n",
    "    for jjj in range(len(toi904_per)):\n",
    "        epochs = get_epochs(toi904_T0[jjj], toi904_per[jjj], min(time), max(time))\n",
    "#             print('len epochs', len(epochs))\n",
    "        ax.vlines(epochs, ymin, ymax, color = 'C'+str(jjj+10), zorder = -1)\n",
    "\n",
    "    plt.subplots_adjust(left=0.35)\n",
    "    plt.savefig('./images/toi904/PS/new_fig_s'+str(sector)+'.png')\n",
    "#     count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bbfbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "19b0de23",
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6887/847080069.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mtotal_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_flux\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_flux_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6887/2614310994.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(fits_files_lst_for_target)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m#             print(hdulist)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mhdulist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#fits time series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mtbdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhdulist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/astropy/io/fits/hdu/hdulist.py\u001b[0m in \u001b[0;36mfitsopen\u001b[0;34m(name, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     return HDUList.fromfile(name, mode, memmap, save_backup, cache,\n\u001b[0;32m--> 174\u001b[0;31m                             lazy_load_hdus, ignore_missing_simple, **kwargs)\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/astropy/io/fits/hdu/hdulist.py\u001b[0m in \u001b[0;36mfromfile\u001b[0;34m(cls, fileobj, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m                              \u001b[0msave_backup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_backup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                              \u001b[0mignore_missing_simple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_missing_simple\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m                              lazy_load_hdus=lazy_load_hdus, **kwargs)\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/astropy/io/fits/hdu/hdulist.py\u001b[0m in \u001b[0;36m_readfrom\u001b[0;34m(cls, fileobj, data, mode, memmap, cache, lazy_load_hdus, ignore_missing_simple, **kwargs)\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_File\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m                 \u001b[0;31m# instantiate a FITS file object (ffo)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m                 \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m             \u001b[0;31m# The Astropy mode is determined by the _File initializer if the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m             \u001b[0;31m# supplied mode was None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/astropy/utils/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m                     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarning_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/astropy/io/fits/file.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fileobj, mode, memmap, overwrite, cache)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_fileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_filelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/astropy/io/fits/file.py\u001b[0m in \u001b[0;36m_open_filename\u001b[0;34m(self, filename, mode, overwrite)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mfileobj_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m                 \u001b[0mmagic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/astropy/io/fits/util.py\u001b[0m in \u001b[0;36mfileobj_open\u001b[0;34m(filename, mode)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \"\"\"\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '.'"
     ]
    }
   ],
   "source": [
    "column_names = ['TICID', 'planet_name', 'period', 'T0', 'Tdur', 'depth']\n",
    "\n",
    "# final_file = './search_mdwarf_planets.csv'\n",
    "new_planet_df = pd.DataFrame(columns=column_names)\n",
    "print(new_planet_df)\n",
    "\n",
    "\n",
    "iii =     150428135\n",
    "print(iii)\n",
    "\n",
    "\n",
    "\n",
    "print(iii)\n",
    "fits_files = sorted(glob.glob('./known_Mdwarfs_data/PS_data/tic_'+str(150428135)+'/*/*/*/*.fits'))\n",
    "\n",
    "#     fits_files = fits_files\n",
    "#     print(len(fits_files))\n",
    "#     fits_files = sorted(glob.glob('./known_Mdwarfs_data/FFI_data/*/*/*/*'+str(iii)+'*/*.fits'))\n",
    "\n",
    "#     if len(fits_files)>0:\n",
    "\n",
    "# fits_files = [file for file in fits_files if np.int64(file.split('/')[6].split('-')[1].split('-')[0][1:]) in flat_sectors]\n",
    "\n",
    "# subset_files = [np.array(fits_files)[np.array(index)] for index in files_indexes]\n",
    "\n",
    "# fits_files = sorted(glob.glob('./known_Mdwarfs_data/PS_data/tic_'+str(150428135)+'/*/*/*/*.fits'))\n",
    "#     fits_files = fits_files\n",
    "#     print(len(fits_files))\n",
    "#     fits_files = sorted(glob.glob('./known_Mdwarfs_data/FFI_data/*/*/*/*'+str(iii)+'*/*.fits'))\n",
    "\n",
    "#     if len(fits_files)>0:\n",
    "\n",
    "\n",
    "# subset_files = [np.array(fits_files)[np.array(index)] for index in  files_indexes]\n",
    "count = 0\n",
    "\n",
    "for files in fits_files:\n",
    "\n",
    "# print(tess_spoc_fits)\n",
    "    print('num files', len(file))\n",
    "#     fits_files\n",
    "    ab, smass, smass_min, smass_max, sradius, sradius_min, sradius_max = get_catalog_info(iii, mdwarfs_known)\n",
    "    print('val', ab)\n",
    "\n",
    "    total_time, total_flux, total_flux_err = get_data(files)\n",
    "\n",
    "    time = np.array(total_time)[np.argsort(total_time)]\n",
    "    flux = np.array(total_flux)[np.argsort(total_time)]\n",
    "    flux_err = np.array(total_flux_err)[np.argsort(total_time)]\n",
    "    \n",
    "    intransit = np.logical_or(transit_mask(time, toi_700_per[3],( 2*2.12423/24)+0.1, toi_700_t0[3]), transit_mask(time, toi_700_per[2], ( 2*1.39317/24)+0.1, toi_700_t0[2]))\n",
    "\n",
    "\n",
    "    time = time[~intransit]\n",
    "    flux = flux[~intransit]\n",
    "    flux_err = flux_err[~intransit]\n",
    "    \n",
    "#         if np.median(np.diff(time) < 10/60/24):\n",
    "#             print('binned')\n",
    "#             binned_time, binned_flux = new_binning_function_by_time(time, flux, 10)\n",
    "#         flux_err = np.full(len(flux), np.std(flux))\n",
    "\n",
    "#         indexes = breaking_up_data(new_time, brk)\n",
    "#         split_times    = [time[indx]     for indx in indexes]\n",
    "#         split_flux     = [flux[indx]     for indx in indexes]\n",
    "#         split_flux_err = [flux_err[indx] for indx in indexes]\n",
    "\n",
    "    bboxes = DT_analysis(time, flux, flux_err)\n",
    "    detrended_lc = make_LightKurveObject(time, flux, flux_err)\n",
    "#     print(detrended_lc)\n",
    "\n",
    "    fig = plt.figure(figsize = (50, 10))\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.patch.set_facecolor('#CCFFFF') # instead of fig.patch.set_facecolor\n",
    "    ax.patch.set_alpha(0.65)\n",
    "    fig.patch.set_facecolor('None') # instead of fig.patch.set_facecolor\n",
    "\n",
    "    for spine in ['top', 'right']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('#CCFFFF')\n",
    "\n",
    "    ax.tick_params(color='#CCFFFF', labelcolor='#CCFFFF', labelsize = 20)\n",
    "\n",
    "\n",
    "    plot_lc_with_bboxes(detrended_lc, bboxes, ms=5, marker='.', lw=0, ax = ax)\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "\n",
    "    for jjj in range(1):\n",
    "        epochs = get_epochs(toi_700_t0[jjj], toi_700_per[jjj], min(time), max(time))\n",
    "#             print('len epochs', len(epochs))\n",
    "        ax.vlines(epochs, ymin, ymax, color = 'C'+str(jjj+3))\n",
    "\n",
    "    plt.subplots_adjust(left=0.35)\n",
    "    plt.savefig('./images/toi904/PS/new_fig_chunk'+str(count)+'.png')\n",
    "    count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e7ae1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_oot = np.array(pd.read_csv('toi700_oot.csv')['time'])\n",
    "flux_oot = np.array(pd.read_csv('toi700_oot.csv')['flux'])\n",
    "flux_err_oot = np.array(pd.read_csv('toi700_oot.csv')['flux_err'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5078bc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1325.65662662, 1325.67745988, 1325.71912641, ..., 2360.3717479 ,\n",
       "       2360.3786923 , 2360.38563669])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_oot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17e66c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 993,  994,  995, ..., 7923, 7924, 7925])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pd.read_csv(\"indexes\"+str(1)+\".csv\", header = None).astype(int))[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae823427",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_split = []\n",
    "\n",
    "for i in range(6):\n",
    "    ary = np.array(pd.read_csv(\"indexes\"+str(i)+\".csv\", header = None).astype(int))[:,0]\n",
    "    \n",
    "    indexes_split.append(ary)\n",
    "\n",
    "\n",
    "max_val = 0\n",
    "for lst in indexes_split:\n",
    "    max_lst = max(lst)\n",
    "    if max_lst>max_val:\n",
    "        max_val = max_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "864bbb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "[val[0] for val in indexes_split]\n",
    "\n",
    "np.argsort([val[0] for val in indexes_split])\n",
    "indexes_split = np.array(indexes_split)[np.argsort([val[0] for val in indexes_split])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d71a56e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38042"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "500eae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "toi_700_t0  = [1330.48, 1352.9912, 2303.16, 2349.04]\n",
    "toi_700_per = [37.4243, 27.8094, 16.0511, 9.97731]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a37d8546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0233430b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [TICID, planet_name, period, T0, Tdur, depth]\n",
      "Index: []\n",
      "150428135\n",
      "val [0.1604 0.4325]\n",
      "init time 993\n",
      "init time 701\n",
      "init time 1034\n",
      "init time 829\n",
      "init time 1029\n",
      "init time 673\n",
      "init time 1001\n",
      "init time 950\n",
      "init time 792\n",
      "init time 1120\n",
      "init time 3114\n",
      "init time 3019\n",
      "init time 2868\n",
      "init time 3047\n",
      "init time 3439\n",
      "init time 3113\n",
      "init time 2108\n",
      "init time 2493\n",
      "init time 2871\n",
      "init time 2927\n",
      "total_time 38043\n",
      "sector 1\n",
      "sector 4\n",
      "sector 5\n",
      "sector 6\n",
      "sector 7\n",
      "sector 8\n",
      "sector 9\n",
      "sector 10\n",
      "sector 11\n",
      "sector 13\n",
      "sector 27\n",
      "sector 28\n",
      "sector 30\n",
      "sector 31\n",
      "sector 33\n",
      "sector 34\n",
      "sector 35\n",
      "sector 36\n",
      "sector 37\n",
      "sector 38\n",
      "38043\n",
      "time 38043\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "column_names = ['TICID', 'planet_name', 'period', 'T0', 'Tdur', 'depth']\n",
    "\n",
    "# final_file = './search_mdwarf_planets.csv'\n",
    "new_planet_df = pd.DataFrame(columns=column_names)\n",
    "print(new_planet_df)\n",
    "\n",
    "\n",
    "for iii in TICIDs[:1]:\n",
    "    \n",
    "    print(iii)\n",
    "    fits_files = sorted(glob.glob('./known_Mdwarfs_data/FFI_data/all_target_data/tic_'+str(iii)+'_all/*/*/*/*.fits'))\n",
    "#     fits_files = fits_files\n",
    "#     print(len(fits_files))\n",
    "#     fits_files = sorted(glob.glob('./known_Mdwarfs_data/FFI_data/*/*/*/*'+str(iii)+'*/*.fits'))\n",
    "\n",
    "#     if len(fits_files)>0:\n",
    "    intransit_index = 0\n",
    "    ab, smass, smass_min, smass_max, sradius, sradius_min, sradius_max = get_catalog_info(iii, mdwarfs_known)\n",
    "    print('val', ab)\n",
    "    get_data(fits_files)\n",
    "    total_time = []\n",
    "    total_flux = []\n",
    "    total_flux_err = []\n",
    "    \n",
    "    for i in fits_files:\n",
    "        sector = np.int64(i.split('/')[7].split('_')[4].split('-')[0][1:])\n",
    "        print('sector', sector)\n",
    "#         if sector > 34:\n",
    "#             print(hdulist)\n",
    "\n",
    "        hdulist=apf.open(i) #fits time series\n",
    "\n",
    "        tbdata = hdulist[1].data\n",
    "#         print(tbdata)\n",
    "        qual         = tbdata.QUALITY == 0\n",
    "\n",
    "        time, flux, flux_raw, flux_err = tbdata.TIME[qual], tbdata.KSPSAP_FLUX[qual],  tbdata.SAP_FLUX[qual],tbdata.KSPSAP_FLUX_ERR[qual]\n",
    "\n",
    "        flux_err = flux_err/np.nanmedian(flux)\n",
    "        flux = flux/np.nanmedian(flux)\n",
    "        flux, flux_err, time = flux[~np.isnan(flux)], flux_err[~np.isnan(flux)],  time[~np.isnan(flux)]\n",
    "        \n",
    "        outliers_mask = mask_outliers(time, flux_raw)\n",
    "        \n",
    "        time = time[~outliers_mask]\n",
    "        flux = flux[~outliers_mask]\n",
    "        flux_err = flux_err[~outliers_mask]\n",
    "\n",
    "        total_time.extend(time)\n",
    "        total_flux.extend(flux)\n",
    "        total_flux_err.extend(flux_err)\n",
    "\n",
    "\n",
    "    total_time = np.array(total_time)\n",
    "    total_flux = np.array(total_flux)\n",
    "    total_flux_err = np.array(total_flux_err)\n",
    "    \n",
    "    time = total_time[np.argsort(total_time)]\n",
    "    flux = total_flux[np.argsort(total_time)]\n",
    "    flux_err = total_flux_err[np.argsort(total_time)]\n",
    "    \n",
    "    print(len(time))\n",
    "    \n",
    "    print('time', len(time))\n",
    "\n",
    "#         print('blah', sec_oot)\n",
    "#     if np.median(np.diff(time) < 30/60/24):\n",
    "#         print('binned')\n",
    "#         binned_time, binned_flux = new_binning_function_by_time(time, flux, 30)\n",
    "# #         flux_err = np.full(len(flux), np.std(flux))\n",
    "\n",
    "\n",
    "    for iii in range(len(indexes_split)):\n",
    "        \n",
    "        new_time = time[indexes_split[iii]]\n",
    "        new_flux = flux[indexes_split[iii]]\n",
    "        new_flux_err = flux_err[indexes_split[iii]]\n",
    "\n",
    "#         indexes = breaking_up_data(new_time, brk)\n",
    "#         split_times    = [time[indx]     for indx in indexes]\n",
    "#         split_flux     = [flux[indx]     for indx in indexes]\n",
    "#         split_flux_err = [flux_err[indx] for indx in indexes]\n",
    "\n",
    "        bboxes = DT_analysis(new_time, new_flux, new_flux_err, is_flat = False)\n",
    "        detrended_lc = make_LightKurveObject(new_time, new_flux, new_flux_err)\n",
    "    #         print(detrended_lc)\n",
    "\n",
    "        fig = plt.figure(figsize = (100, 10))\n",
    "\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.patch.set_facecolor('#CCFFFF') # instead of fig.patch.set_facecolor\n",
    "        ax.patch.set_alpha(0.65)\n",
    "        \n",
    "        \n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(25)) \n",
    "        for spine in ['top', 'right']:\n",
    "            ax.spines[spine].set_visible(False)\n",
    "#         for spine in ax.spines.values():\n",
    "#             spine.set_edgecolor('#CCFFFF')\n",
    "#         ax.tick_params(color='#CCFFFF', labelcolor='#CCFFFF')\n",
    "        ax.tick_params(color='k', labelcolor='k')\n",
    "\n",
    "        plot_lc_with_bboxes(detrended_lc, bboxes, ms=3, marker='.', lw=0, ax = ax)\n",
    "        \n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        \n",
    "#         print('times edges', min(new_time), max(new_time), abs(min(new_time)-max(new_time)))\n",
    "        for jjj in range(1):\n",
    "            epochs = get_epochs(toi_700_t0[jjj], toi_700_per[jjj], min(new_time), max(new_time))\n",
    "#             print('len epochs', len(epochs))\n",
    "            ax.vlines(epochs, ymin, ymax, color = 'C'+str(jjj+3))\n",
    "        \n",
    "        print('good')\n",
    "        plt.show()\n",
    "        plt.savefig('./images/toi700/raw/new_fig_chunk_'+str(iii)+'_oot_raw.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8991d4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = [[1], list(range(4,12/), [13], [27,28], [30, 31], list(range(31, 39))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be3f6fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1],\n",
       " [4, 5, 6, 7, 8, 9, 10, 11],\n",
       " [13],\n",
       " [27, 28],\n",
       " [30, 31],\n",
       " [31, 32, 33, 34, 35, 36, 37, 38]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "107fd400",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_indexes_split = [range(min(x), max(x)) for x in indexes_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "792cb02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 7.75192618968921,\n",
       " 1.009861206342858,\n",
       " 1.7660585175735324,\n",
       " 1.96030495662672,\n",
       " 5.775430183463783]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "axis_num = 0\n",
    "\n",
    "indexes_split\n",
    "\n",
    "split_times = [time[indx] for indx in indexes_split]\n",
    "split_flux = [flux[indx] for indx in indexes_split]\n",
    "\n",
    "sec_diff = [max(time_sec)-min(time_sec) for time_sec in split_times] \n",
    "\n",
    "ratios = [diff/min(sec_diff) for diff in sec_diff]\n",
    "\n",
    "ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8f7483bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_multi_sector_plot(time, flux, indexes_split):\n",
    "    plt.rcParams.update({\n",
    "    \"font.weight\": \"normal\",\n",
    "    \"xtick.major.size\": 20,\n",
    "    \"xtick.major.pad\": 0.01,\n",
    "    \"xtick.labelsize\": 35,\n",
    "    \"ytick.major.size\": 20,\n",
    "    \"ytick.major.pad\": 1,\n",
    "    \"ytick.labelcolor\": '#CCFFFF',\n",
    "    \"xtick.labelcolor\": '#CCFFFF',\n",
    "    \n",
    "    \"grid.color\": '#CCFFFF',\n",
    "    \"grid.linestyle\": \"-\",\n",
    "    \"grid.linewidth\": 15,\n",
    "    \"lines.linewidth\": 2,\n",
    "    \"lines.color\": '#CCFFFF'})\n",
    "    \n",
    "\n",
    "    split_times    = [time[indx] for indx in indexes_split]\n",
    "    split_flux     = [flux[indx] for indx in indexes_split]\n",
    "\n",
    "    sector_time_differences = [max(time_chunk)-min(time_chunk) for time_chunk in split_times]\n",
    "\n",
    "    diff_time_min = min(sector_time_differences)\n",
    "    \n",
    "    sector_ratios = [(diff_time_sector+3)/(diff_time_min+3) for diff_time_sector in sector_time_differences]\n",
    "\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(indexes_split), figsize = [75, 10], sharey=True, \n",
    "                             gridspec_kw={'width_ratios': sector_ratios})\n",
    "\n",
    "    fig.patch.set_facecolor('None') # instead of fig.patch.set_facecolor\n",
    "#     fig.patch.set_alpha(0.8)\n",
    "    \n",
    "    d = .03 # how big to make the diagonal lines in axes coordinates\n",
    "\n",
    "    for jjj in range(len(indexes_split)):\n",
    "        \n",
    "        sec_time = split_times[jjj]\n",
    "        sec_flux = split_flux[jjj]\n",
    "        axes[jjj].patch.set_facecolor('#0099CC') # instead of fig.patch.set_facecolor\n",
    "        axes[jjj].patch.set_alpha(0.4)\n",
    "        axes[jjj].tick_params(color = '#CCFFFF', which='both', width = 3)\n",
    "        axes[jjj].tick_params(which='major', length = 14)\n",
    "        axes[jjj].tick_params(which='minor', length = 8)\n",
    "\n",
    "#         axes[jjj].scatter(sec_time, sec_flux, color = 'lightgrey', s = 50)\n",
    "        axes[jjj].scatter(sec_time, sec_flux, color = '#CC9966', linewidth = 5)\n",
    "\n",
    "        axes[jjj].set_xlim(min(sec_time)-1.5, max(sec_time)+1.5)\n",
    "        axes[jjj].spines['bottom'].set_color('#CCFFFF')\n",
    "        axes[jjj].spines['top'].set_color('#CCFFFF')\n",
    "        \n",
    "        epochs = get_epochs(toi_700_t0[2], toi_700_per[2], min(sec_time)-1.5, 1.5+max(sec_time))\n",
    "#             print('len epochs', len(epochs))\n",
    "\n",
    "        axes[jjj].vlines(np.array(epochs), ymin, ymax, color = 'k')\n",
    "\n",
    "        axes[0].spines['left'].set_color('#CCFFFF')\n",
    "        \n",
    "        axes[5].spines['right'].set_color('#CCFFFF')\n",
    "\n",
    "        kwargs = dict(transform=axes[jjj].transAxes, color='#CCFFFF', clip_on=False)\n",
    "    \n",
    "\n",
    "        if jjj<max(range(len(indexes_split))):\n",
    "            axes[jjj].spines['right'].set_visible(False)\n",
    "            axes[jjj+1].spines['left'].set_visible(False)\n",
    "            \n",
    "\n",
    "            axes[jjj].plot((1-(d/sector_ratios[jjj]),1+(d/sector_ratios[jjj])),(-d,+d), **kwargs) # top-left diagonal\n",
    "            axes[jjj].plot((1-(d/sector_ratios[jjj]),1+(d/sector_ratios[jjj])),(1-d,1+d), **kwargs) # bottom-left diagonal\n",
    "\n",
    "\n",
    "        if jjj>0:\n",
    "            axes[jjj].yaxis.set_ticks_position('none')\n",
    "\n",
    "            axes[jjj].plot((-d/sector_ratios[jjj],d/sector_ratios[jjj]),(-d,+d), **kwargs) # top-right diagonal\n",
    "            axes[jjj].plot((-d/sector_ratios[jjj],d/sector_ratios[jjj]),(1-d,1+d), **kwargs) # bottom-right diagonalaxes[1].plot((1-d,1+d), (-d,+d), **kwargs)\n",
    "        \n",
    "#             kwargs.update(transform=axes[jjj].transAxes) # switch to the bottom axes\n",
    "#             axes[jjj].plot((-d/sector_ratios[jjj],d/sector_ratios[jjj]),(-d/sector_ratios[jjj],+d/sector_ratios[jjj]), **kwargs) # top-right diagonal\n",
    "#             axes[jjj].plot((-d/sector_ratios[jjj],d/sector_ratios[jjj]),(1-d/sector_ratios[jjj],1+d/sector_ratios[jjj]), **kwargs) # bottom-right diagonalaxes[1].plot((1-d,1+d), (-d,+d), **kwargs)\n",
    "\n",
    "\n",
    "    # plt.subplots_adjust(wspace=0, hspace=0.23)\n",
    "    # plt.xlabel('Time (BJD - 2457000)', fontsize = 45)\n",
    "    fig.text(0.441, 0.05, 'Time (BJD - 2457000)', va='center', fontsize = 45,  fontweight = 'normal', color ='#CCFFFF')\n",
    "\n",
    "    fig.text(0.085, 0.5, 'Relative Flux', va='center', fontsize = 45,  rotation='vertical', fontweight = 'normal', color = '#CCFFFF')\n",
    "    \n",
    "    plt.subplots_adjust(bottom=0.2)\n",
    "    \n",
    "    fig.savefig('evil_2.png', facecolor = fig.get_facecolor(), edgecolor = 'none')\n",
    "    \n",
    "creating_multi_sector_plot(time, flux, new_indexes_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d56055a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
