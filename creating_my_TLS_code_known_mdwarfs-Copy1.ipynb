{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28ba24ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "import astropy.io.fits as apf\n",
    "import batman\n",
    "import eleanor\n",
    "import emcee\n",
    "import getpass\n",
    "import glob\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import Process\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import time as tm \n",
    "from astroquery.mast import Catalogs\n",
    "import astropy.units as units\n",
    "from astropy.wcs import WCS\n",
    "import math\n",
    "import astropy.io.fits as apf\n",
    "from astropy.stats import sigma_clip\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from wotan import flatten\n",
    "import lightkurve as lk\n",
    "import corner\n",
    "import numpy as np\n",
    "import juliet\n",
    "import matplotlib.gridspec as gridspec\n",
    "import mpl_axes_aligner\n",
    "\n",
    "from astropy.timeseries import BoxLeastSquares\n",
    "from ldtk import LDPSetCreator, BoxcarFilter, TabulatedFilter, SVOFilter\n",
    "from ldtk.filters import tess, sdss_z\n",
    "from astroquery import svo_fps\n",
    "\n",
    "import mr_forecast as mr\n",
    "import numba\n",
    "from math import floor\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "from transitleastsquares import (\n",
    "    transitleastsquares,\n",
    "    cleaned_array,\n",
    "    catalog_info,\n",
    "    transit_mask\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea8ea463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0211cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TICIDs = [150428135, 259377017, 235678745, 467179528, 284441182, 36724087, 441798995, 219195044]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08998608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm going to go ahead and outline the steps to take:\\n1) Define output and input directories \\n2) Check to see if you have already started your search, and if so get the times in transit AND TICIDs/GAIAids\\n3) Detrend data with wotan\\n3) Get outliers for each target and create a histogram of frequent outline points. Mask them. \\n4) Save new flux+time data in fits file (if you can)\\n5) Before beginning SNR search: \\n    a) calculate CDPP\\n    b) create SNR grid, getting min rp and duration\\n    c) calc limb darkening (?)\\n6) begin SNR search\\n    a) using \""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"I'm going to go ahead and outline the steps to take:\n",
    "1) Define output and input directories \n",
    "2) Check to see if you have already started your search, and if so get the times in transit AND TICIDs/GAIAids\n",
    "3) Detrend data with wotan\n",
    "3) Get outliers for each target and create a histogram of frequent outline points. Mask them. \n",
    "4) Save new flux+time data in fits file (if you can)\n",
    "5) Before beginning SNR search: \n",
    "    a) calculate CDPP\n",
    "    b) create SNR grid, getting min rp and duration\n",
    "    c) calc limb darkening (?)\n",
    "6) begin SNR search\n",
    "    a) using \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39044af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RP_REFERENCE = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb9f9de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Let's start the following cells pretending that I have \n",
    "1) detrended data\n",
    "2) sliced the LC\n",
    "3) run the periodic search and masked out periodic transits\n",
    "4) gotten a df including M_star, R_star, Teff_star, aLDC, bLDC\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def interpolation_search(x, z):\n",
    "    n = len(x)\n",
    "#     print(n)\n",
    "    assert n > 1\n",
    "    if z < x[1] or n == 2:\n",
    "        return 0\n",
    "    elif z >= x[-2]:\n",
    "        return n - 2\n",
    "    imin = 0\n",
    "    imax = n - 1\n",
    "    while imax - imin > 1:\n",
    "        s = (z - x[imin]) / (x[imax] - x[imin])\n",
    "        j = int(imin + floor((imax - imin) * s))\n",
    "        if z >= x[j + 1]:\n",
    "            imin = j + 1\n",
    "        elif z < x[j]:\n",
    "            imax = j\n",
    "        else:\n",
    "            return j\n",
    "    return imin\n",
    "\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def lerp(y, theta):\n",
    "    return (1 - theta) * y[..., 0] + theta * y[..., 1]\n",
    "\n",
    "\n",
    "class interp1d(object):\n",
    "    \"\"\"\n",
    "    Adapted from:\n",
    "    Fast multithreaded linear interpolation, 1D and 2D - Ver. 3.4\n",
    "    This versione: 15/06/2018\n",
    "    @author: Marco Maffezzoli, Universita Bocconi\n",
    "    http://didattica.unibocconi.it/mypage/upload/49183_20180615_035144_INTERPOLATION.PY\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x_new, x):\n",
    "        (self._index, self._theta) = self._locate(x_new, x)\n",
    "        \n",
    "    @staticmethod\n",
    "    @numba.guvectorize(\"(i8[:],f8[:],f8[:],f8[:])\", \"(m),(m),(n)->(m)\")\n",
    "    def _linear(index, theta, y, y_new):\n",
    "        for (j, (i, t)) in enumerate(zip(index, theta)):\n",
    "            y_new[j] = lerp(y[i : i + 2], t)\n",
    "\n",
    "    def __call__(self, y):\n",
    "        return self._linear(self._index, self._theta, y)\n",
    "\n",
    "    @numba.guvectorize(\"(f8[:],f8[:],i8[:],f8[:])\", \"(),(n)->(),()\")\n",
    "    def _locate(x_new, x, index, theta =[]):\n",
    "        index[0] = i = interpolation_search(x, x_new[0])\n",
    "        theta[0] = (x_new[0] - x[i]) / (x[i + 1] - x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3556131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###DEFAULTS\n",
    "\n",
    "DURATIONS = np.array(range(2, 25))*30.\n",
    "MAXWIDTH_IN_SAMPLES = 24\n",
    "len(DURATIONS)\n",
    "RP_REFERENCE = 0.05\n",
    "T0_FIT_MARGIN = 0.01\n",
    "TRANSIT_DEPTH_MIN = 2.5 * 10 ** -6  # 10 ppm\n",
    "SIGNAL_DEPTH = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eb86987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fractional_transit(\n",
    "    duration,\n",
    "    maxwidth,\n",
    "    depth,\n",
    "    samples,\n",
    "    per,\n",
    "    rp,\n",
    "    a,\n",
    "    inc,\n",
    "    ecc,\n",
    "    w,\n",
    "    u,\n",
    "    limb_dark,\n",
    "    cached_reference_transit=None,\n",
    "):\n",
    "    \"\"\"Returns a scaled reference transit with fractional width and depth\"\"\"\n",
    "\n",
    "    if cached_reference_transit is None:\n",
    "#         print('a')\n",
    "        reference_flux = reference_transit(\n",
    "            samples=samples,\n",
    "            per=per,\n",
    "            rp=rp,\n",
    "            a=a,\n",
    "            inc=inc,\n",
    "            ecc=ecc,\n",
    "            w=w,\n",
    "            u=u,\n",
    "            limb_dark=limb_dark,\n",
    "        )\n",
    "    else:\n",
    "        reference_flux = cached_reference_transit\n",
    "\n",
    "    reference_time = np.linspace(-0.5, 0.5, samples)\n",
    "    occupied_samples = int((duration / maxwidth) * samples)\n",
    "    x_new = np.linspace(-0.5, 0.5, occupied_samples)\n",
    "    f = interp1d(x_new, reference_time)\n",
    "    y_new = f(reference_flux)\n",
    "\n",
    "    # Patch ends with ones (\"1\")\n",
    "    missing_samples = samples - occupied_samples\n",
    "    emtpy_segment = np.ones(int(missing_samples * 0.5))\n",
    "    result = np.append(emtpy_segment, y_new)\n",
    "    result = np.append(result, emtpy_segment)\n",
    "    if np.size(result) < samples:  # If odd number of samples\n",
    "        result = np.append(result, np.ones(1))\n",
    "\n",
    "    # Depth rescaling\n",
    "    result = 1 - ((1 - result) * depth)\n",
    "\n",
    "    return result\n",
    "\n",
    "###Creating cache of models\n",
    "def reference_transit(per, rp, a, inc, ecc, w, u, limb_dark, samples = 24):\n",
    "    \"\"\"Returns an Earth-like transit of width 1 and depth 1\"\"\"\n",
    "    ###Samples = maxwidth of samples = number of points in max duration val\n",
    "    ###NOTE: TLS requires that his number be EVEN\n",
    "    f = np.ones(1000)\n",
    "    duration = 1  # transit duration in days. Increase for exotic cases. ###I want the max trans dur to be 12 hrs\n",
    "    t = np.linspace(-duration * 0.5, duration * 0.5, 1000)\n",
    "    t_2_lin = np.linspace(0., duration, 1000)\n",
    "    \n",
    "    \n",
    "    print('u, ', u)\n",
    "    ###FOR ME: T=time in lc <- NOT TRUE. WHY: this is a model. I would like each transit \n",
    "    ###to start at 0 and then go to x duration BECAUSE ising t0 = 0 is EASY and then i\n",
    "    ###will SHIFT IT so the transit starts at 0 and t0 is size of shift \n",
    "    b_model           = batman.TransitParams()\n",
    "    b_model.t0        = 0  # time of inferior conjunction\n",
    "    b_model.per       = per  # orbital period, use Earth as a reference\n",
    "    b_model.rp        = rp  # planet radius (in units of stellar radii)\n",
    "    b_model.a         = a  # semi-major axis (in units of stellar radii)\n",
    "    b_model.inc       = inc  # orbital inclination (in degrees)\n",
    "    b_model.ecc       = ecc  # eccentricity\n",
    "    b_model.w         = w  # longitude of periastron (in degrees)\n",
    "    b_model.u         = u  # limb darkening coefficients\n",
    "    b_model.limb_dark = limb_dark  # limb darkening model\n",
    "    m = batman.TransitModel(b_model, t)  # initializes model\n",
    "    model_flux = m.light_curve(b_model)  # calculates light curve\n",
    "\n",
    "    # Determine start of transit (first value < 1)\n",
    "    idx_first = np.argmax(model_flux < 1)\n",
    "    intransit_model_flux = model_flux[idx_first : -idx_first + 1]\n",
    "    intransit_time = t[idx_first : -idx_first + 1] \n",
    "\n",
    "    # Downsample (bin) to target sample size\n",
    "    x_new = np.linspace(t[idx_first], t[-idx_first - 1], samples)\n",
    "\n",
    "    print(len(x_new))\n",
    "    f = interp1d(x_new, intransit_time)\n",
    "    downsampled_intransit_model_flux = f(intransit_model_flux)\n",
    "\n",
    "    # Rescale to height [0..1]\n",
    "    rescaled = (np.min(downsampled_intransit_model_flux) - downsampled_intransit_model_flux) / (\n",
    "        np.min(downsampled_intransit_model_flux) - 1\n",
    "    )\n",
    "    \n",
    "    return rescaled #, intransit_time\n",
    "\n",
    "\n",
    "def get_cache(durations, rp = 0.03, per=25., a =0.15*215., inc=89.5, ecc=0., w=180., u=[0.2, 0.1],\n",
    "              limb_dark='quadratic', verbose=False, maxwidth_in_samples = MAXWIDTH_IN_SAMPLES):\n",
    "    \"\"\"Fetches (size(durations)*size(depths)) light curves of length \n",
    "        maxwidth_in_samples and returns these LCs in a 2D array, together with \n",
    "        their metadata in a separate array.\"\"\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Creating model cache for\", str(len(durations)), \"durations\")\n",
    "    lc_arr = []\n",
    "    rows = np.size(durations)\n",
    "    lc_cache_overview = np.zeros(\n",
    "        rows,\n",
    "        dtype=[(\"duration\", \"float128\"), (\"width_in_samples\", \"int64\"), (\"overshoot\", \"float128\")],\n",
    "    )\n",
    "    cached_reference_transit = reference_transit(\n",
    "        per=per,\n",
    "        rp=rp,\n",
    "        a=a,\n",
    "        inc=inc,\n",
    "        ecc=ecc,\n",
    "        w=w,\n",
    "        u=u,\n",
    "        limb_dark=limb_dark,\n",
    "    )\n",
    "\n",
    "    row = 0\n",
    "    for duration in durations:\n",
    "        scaled_transit = fractional_transit(\n",
    "            duration=duration,\n",
    "            maxwidth=np.max(durations),\n",
    "            depth=SIGNAL_DEPTH,\n",
    "            samples=maxwidth_in_samples,\n",
    "            per=per,\n",
    "            rp=rp,\n",
    "            a=a,\n",
    "            inc=inc,\n",
    "            ecc=ecc,\n",
    "            w=w,\n",
    "            u=u,\n",
    "            limb_dark=limb_dark,\n",
    "            cached_reference_transit=cached_reference_transit,\n",
    "        )\n",
    "        lc_cache_overview[\"duration\"][row] = duration\n",
    "        used_samples = int((duration / np.max(durations)) * maxwidth_in_samples)\n",
    "        lc_cache_overview[\"width_in_samples\"][row] = used_samples\n",
    "        full_values = np.where(\n",
    "            scaled_transit < (1 - 0.01 * 10 ** -6 )\n",
    "        )\n",
    "        first_sample = np.min(full_values)\n",
    "        last_sample = np.max(full_values) + 1\n",
    "        signal = scaled_transit[first_sample:last_sample]\n",
    "        lc_arr.append(signal)\n",
    "\n",
    "        # Fraction of transit bottom and mean flux\n",
    "        overshoot = np.mean(signal) / np.min(signal)\n",
    "        # Later, we multiply the inverse fraction ==> convert to inverse percentage\n",
    "        lc_cache_overview[\"overshoot\"][row] = 1 / (2 - overshoot)\n",
    "#         print(overshoot, 1 / (2 - overshoot))\n",
    "        row += +1\n",
    "        \n",
    "\n",
    "    lc_arr = np.array(lc_arr, dtype=object)\n",
    "    return lc_cache_overview, lc_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dffa0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(nan,), (nan,), (nan,), (nan,), (nan,), (nan,), (nan,), (nan,),\n",
       "       (nan,), (nan,)], dtype=[('chi2', 'O')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_=np.zeros(10)\n",
    "residuals = np.full(len(list_), np.nan, dtype=[('chi2','object')])\n",
    "residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14b03210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowest_residuals_in_this_duration(\n",
    "    mean,\n",
    "    time,\n",
    "    transit_depth_min,\n",
    "    data_arr,\n",
    "    duration,\n",
    "    signal,\n",
    "    inverse_squared_dy_arr,\n",
    "    overshoot,\n",
    "    ootr,\n",
    "    chosen_transit_row,\n",
    "    datapoints,\n",
    "    T0_fit_margin, \n",
    "    threshold = 7.3, \n",
    "    verbose = False\n",
    "):\n",
    "    T0 = []\n",
    "    T0_st_indx = []\n",
    "    SNR = threshold\n",
    "    residuals_depths = np.full(len(time), np.nan, dtype = ([(\"residuals\", \"float128\"), (\"depths\", \"float128\")]))\n",
    "    # if nothing is fit, we fit a straight line: signal=1. Then, at dy=1,\n",
    "    # the squared sum of residuals equals the number of datapoints\n",
    "    summed_residual_in_rows = datapoints\n",
    "\n",
    "    xth_point = 1  # How many cadences the template shifts forward in each step\n",
    "    if T0_fit_margin > 0 and duration > T0_fit_margin:\n",
    "        T0_fit_margin = 1 / T0_fit_margin\n",
    "        xth_point = int(duration / T0_fit_margin)\n",
    "        if xth_point < 1:\n",
    "            xth_point = 1\n",
    "\n",
    "    for i in range(len(mean)):\n",
    "        if (mean[i] > transit_depth_min) and (i % xth_point == 0):\n",
    "            data = data_arr[i : i + duration]\n",
    "            flux_oot = np.delete(data_arr, range(i,i+duration))\n",
    "\n",
    "            dy = inverse_squared_dy_arr[i : i + duration]\n",
    "            target_depth = mean[i] * overshoot\n",
    "            scale = SIGNAL_DEPTH / target_depth\n",
    "            reverse_scale = 1 / scale  # speed: one division now, many mults later\n",
    "            snr = (mean[i] / (np.std(flux_oot)*np.sqrt(0.5))) * duration ** (0.5)\n",
    "            if snr>SNR:\n",
    "                SNR=snr\n",
    "            intransit_residual = 0\n",
    "            for j in range(len(signal)):\n",
    "                sigi = (1 - signal[j]) * reverse_scale\n",
    "                intransit_residual += ((data[j] - (1 - sigi)) ** 2) * dy[j]\n",
    "            current_stat = intransit_residual + ootr[i] #- summed_edge_effect_correction\n",
    "            \n",
    "            residuals_depths['residuals'][i] = current_stat\n",
    "            residuals_depths['depths'][i] = 1-target_depth\n",
    "            \n",
    "    residuals = residuals_depths['residuals'].astype('float128')\n",
    "\n",
    "    if np.nanmin(residuals)<=np.nanmedian(residuals)-5*np.nanstd(residuals) and SNR>threshold:\n",
    "        indexes = np.where(residuals<=np.nanmedian(residuals)-5*np.nanstd(residuals))[0]\n",
    "        for jjj in indexes:\n",
    "            if jjj and jjj+1 in indexes:\n",
    "                T0_st_indx.extend(np.where(residuals == min(residuals[[jjj, jjj+1]]))[0])\n",
    "        \n",
    "        if verbose:\n",
    "#             print(duration*30/60, 'planets Tdur: ', Toi270_Tdur)#' Tdur_p4:', Toi270_Tdur[3])\n",
    "            fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize=(20,5))\n",
    "            axes[0].plot(time, residuals, zorder = 10)\n",
    "\n",
    "            axes[1].scatter(time, data_arr, s = 1, zorder = 11, alpha = 1, color = 'black')\n",
    "            for j in range(1,7):\n",
    "                axes[0].hlines(np.nanmedian(residuals)-j*np.nanstd(residuals), np.min(time), np.max(time), alpha = 0.5, zorder = 3, color = 'violet')\n",
    "            plt.subplots_adjust(wspace=0.2, hspace=0)\n",
    "            plt.show()\n",
    "\n",
    "    \n",
    "        return SNR, np.array(list(residuals_depths['residuals'].astype('float128'))), np.array(list(residuals_depths['depths'].astype('float128'))), T0_st_indx\n",
    "    else:\n",
    "        return 0, [],[], []\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46fe8c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @numba.jit(fastmath=True, parallel=False, nopython=True)\n",
    "def out_of_transit_residuals(data, width_signal, inv_sq_dy):\n",
    "#     print(len(data), data)\n",
    "    chi2 = np.zeros(len(data) - width_signal + 1)\n",
    "    fullsum = np.sum(((1 - data) ** 2) * inv_sq_dy)\n",
    "    window = np.sum(((1 - data[:width_signal]) ** 2) * inv_sq_dy[:width_signal])\n",
    "    chi2[0] = fullsum - window\n",
    "    for i in range(1, len(data) - width_signal + 1):\n",
    "        becomes_visible = i - 1\n",
    "        becomes_invisible = i - 1 + width_signal\n",
    "        add_visible_left = (1 - data[becomes_visible]) ** 2 * inv_sq_dy[becomes_visible]\n",
    "        remove_invisible_right = (1 - data[becomes_invisible]) ** 2 * inv_sq_dy[\n",
    "            becomes_invisible\n",
    "        ]\n",
    "        chi2[i] = chi2[i - 1] + add_visible_left - remove_invisible_right\n",
    "    return chi2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f522961c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77def5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 6, 1, 4],\n",
       "       [0, 6, 4, 6, 2],\n",
       "       [2, 5, 1, 3, 6]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,3,6,1,4], [0, 6, 4, 6,2], [2,5,1,3,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b7a5d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 6, 1, 4],\n",
       "       [0, 6, 4, 6, 2],\n",
       "       [2, 5, 1, 3, 6]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,3,6,1,4], [0, 6, 4, 6,2], [2,5,1,3,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24ba75f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_set = ['#00E9F5',  '#22DAD2', '#44CBAF', \n",
    "         '#66BC8C', '#88AD69', '#AA9E46',  \n",
    "         '#CC8F23', '#EB8300', '#F19508',\n",
    "         '#F8A610','#FFB718']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b197a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "# pbs = []\n",
    "# for i in set(color):\n",
    "#     pb = Patch(facecolor=i, edgecolor='None')\n",
    "#     pbs.append(pb)\n",
    "\n",
    "# ax.legend(handles=pbs,\n",
    "#           labels=['', '', '', '', 'First', 'Second'],\n",
    "#           ncol=3, handletextpad=0.5, handlelength=1.0, columnspacing=-0.5,\n",
    "#           loc='center', fontsize=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3db111e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '', 'a']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['']*10+['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db385a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_best_fit_duration(\n",
    "#     duration,\n",
    "    t,\n",
    "    y,\n",
    "    dy,\n",
    "    transit_depth_min,\n",
    "    lc_arr,\n",
    "    lc_cache_overview,\n",
    "    T0_fit_margin,\n",
    "    verbose = True\n",
    "):\n",
    "    \"\"\"Core routine to search the flux data set 'injected' over all 'periods'\"\"\"\n",
    "    SNR_val = 0.\n",
    "\n",
    "    # duration (in samples) of widest transit in lc_cache (axis 0: rows; axis 1: columns)\n",
    "    npoints_in_duration = np.unique(lc_cache_overview[\"width_in_samples\"])\n",
    "    T0_vals = np.full(\n",
    "        100, np.nan, \n",
    "        dtype=[('T0_start', 'float128'), ('T0', 'float128'), ('residuals', 'float128'), ('best_dur', 'int64'), ('best_depth', 'float128')]\n",
    "    )\n",
    "\n",
    "    Residuals_all = []\n",
    "    inverse_squared_dy = 1 / dy ** 2\n",
    "    print('lengths', len(dy), len(y), len(t), len(inverse_squared_dy))\n",
    "\n",
    "    skipped_all = True\n",
    "    T0_starts = []\n",
    "    for i in range(len(npoints_in_duration)):\n",
    "        dur = npoints_in_duration[i]\n",
    "\n",
    "        chosen_transit_row = 0\n",
    "        while lc_cache_overview[\"width_in_samples\"][chosen_transit_row] != dur:\n",
    "            chosen_transit_row += 1\n",
    "        if len(t)<=dur:\n",
    "            continue\n",
    "        snr, residuals, depths, T0_start_indx = lowest_residuals_in_this_duration(\n",
    "            mean=1 - running_mean(y, dur),\n",
    "            time = t,\n",
    "            transit_depth_min=transit_depth_min,\n",
    "            data_arr=y,\n",
    "            duration=dur,\n",
    "            signal=lc_arr[chosen_transit_row],\n",
    "            inverse_squared_dy_arr=inverse_squared_dy,\n",
    "            overshoot=lc_cache_overview[\"overshoot\"][chosen_transit_row],\n",
    "            ootr=out_of_transit_residuals(\n",
    "                y, dur, inverse_squared_dy\n",
    "            ),\n",
    "            chosen_transit_row=chosen_transit_row,\n",
    "            datapoints=len(y),\n",
    "            T0_fit_margin=T0_fit_margin,\n",
    "        )\n",
    "\n",
    "       \n",
    "        SNR_val += snr\n",
    "        residuals = residuals/np.nanmedian(residuals)\n",
    "        T0_starts.extend(T0_start_indx)\n",
    "        T0_starts = list(set(T0_starts))\n",
    "        if len(residuals)>0:\n",
    "            Residuals_all.append(residuals)\n",
    "\n",
    "            for jjj in T0_starts:\n",
    "                indx = False\n",
    "                try: \n",
    "\n",
    "                    indx = np.where(T0_vals['T0_start']==jjj)[0][0]\n",
    "                    if float(T0_vals['residuals'][indx])<float(residuals[jjj]):\n",
    "                        indx = False\n",
    "\n",
    "                except:\n",
    "                    indx = min(np.where(T0_vals['best_dur']==-9223372036854775808)[0])\n",
    "\n",
    "\n",
    "                T0_vals['T0_start'][indx]   = jjj\n",
    "                T0_vals['T0'][indx]         = t[jjj]+chosen_transit_row/48\n",
    "                T0_vals['residuals'][indx]  = float(residuals[jjj])\n",
    "                T0_vals['best_dur'][indx]   = chosen_transit_row\n",
    "                T0_vals['best_depth'][indx] = float(depths[jjj])\n",
    "\n",
    "    if verbose:\n",
    "        color = ['#00E9F5', '#00E9F5', '#22DAD2','#22DAD2', '#44CBAF', '#44CBAF',\n",
    "                 '#66BC8C','#66BC8C','#88AD69', '#88AD69', '#AA9E46',  '#AA9E46', \n",
    "                 '#CC8F23', '#CC8F23', '#EB8300','#EB8300', '#F19508', '#F19508', \n",
    "                 '#F8A610','#F8A610', '#FFB718','#FFB718','#FFB718']\n",
    "        f, ax2 = plt.subplots(1, 1, sharey=False, figsize = (14, 20))\n",
    "        \n",
    "\n",
    "        resids = np.array(Residuals_all).transpose()\n",
    "        if len(Residuals_all)>0.:\n",
    "            for i in range(len(Residuals_all)):\n",
    "                ax2.plot(t, Residuals_all[i], color = color[i], lw = 2)\n",
    "                pbs = []\n",
    "            for i in color_set:\n",
    "                pb = Patch(facecolor=i, edgecolor='None')\n",
    "                pbs.append(pb)\n",
    "\n",
    "            label = ['']*int(len(color)-1)\n",
    "        \n",
    "            ax2.legend(handles=pbs,bbox_to_anchor=(0.2,1.037),\n",
    "                        labels=label+[''], framealpha=0.,\n",
    "                        ncol=len(set(color)), handletextpad=0., handlelength=1.05, columnspacing=-0.5, \n",
    "                        fontsize=30, labelcolor='#FFD475')\n",
    "\n",
    "\n",
    "#             print(len(t), np.shape(resids), len(Residuals_all))\n",
    "#             resids = [np.median(np.array(x)) for x in resids]\n",
    "            ax3 = ax2.twinx()\n",
    "            ax3.scatter(t, y, color = '#E4D7BA', zorder = 2, label = 'TESS Observations', s = 40, alpha =1.)\n",
    "#             ax.set_ylim(0.97, 1.02)\n",
    "#             ax3.plot(t, resids, color = '#EB8300', zorder = 10)\n",
    "            handles, labels = ax3.get_legend_handles_labels() # get existing handles and labels\n",
    "            empty_patch = Patch(color='None', label='Transit Durations Fit: 2-11.5 hours') # create a patch with no color\n",
    "\n",
    "            handles.append(empty_patch)  # add new patches and labels to list\n",
    "            labels.append('Transit Durations Fit: 2-11.5 hours')\n",
    "\n",
    "            ax3.legend(loc = 2, handles = handles, labels = labels, framealpha=0., handletextpad=0.5, \n",
    "                       bbox_to_anchor=(0.0,1.11), \n",
    "                       fontsize=40, labelcolor='#FFD475')\n",
    "        \n",
    "        \n",
    "            ax3.yaxis.tick_right()\n",
    "    #         align_yaxis(ax2, 1., ax3, 1.)\n",
    "            mpl_axes_aligner.align.yaxes(ax2, 1., ax3, 1., 0.7)\n",
    "            for ax in [ax2, ax3]:\n",
    "                ax.set_facecolor('None')\n",
    "\n",
    "                ax.xaxis.label.set_color('#FFD475')        #setting up X-axis label color to yellow\n",
    "                ax.yaxis.label.set_color('#FFD475')          #setting up Y-axis label color to blue\n",
    "\n",
    "                ax.tick_params(axis='x', colors='#FFD475', labelsize = 35, width=3, length = 10)    #setting up X-axis tick color to red\n",
    "                ax.tick_params(axis='y', colors='#FFD475', labelsize = 35, width=3, length = 10)  #setting up Y-axis tick color to black\n",
    "                ax.spines['top'].set_color(None)        # setting up Y-axis tick color to red\n",
    "                ax.spines['right'].set_color(None)         #setting up above X-axis tick color to red\n",
    "\n",
    "                ax.spines['left'].set_color(None)        # setting up Y-axis tick color to red\n",
    "                ax.spines['bottom'].set_color(None)         #setting up above X-axis tick color to red\n",
    "                ax.set_xlabel('Time (BJD)', color = '#FFD475', fontsize = 40)\n",
    "                ax.set_ylabel('Relative Flux', color = '#FFD475', fontsize = 40);\n",
    "\n",
    "            ax3.yaxis.set_label_position(\"right\")\n",
    "#             ax1.set_ylabel(r'$\\chi^2$ of Transit Fit', fontsize = 40)\n",
    "            ax3.set_ylabel(r'$\\chi^2$ of Transit Fit Values', fontsize = 40, rotation=270, labelpad=75)\n",
    "\n",
    "            plt.show()\n",
    "    return np.array(list(T0_vals['T0_start'])), np.array(list(T0_vals['T0'])), np.array(list(T0_vals['best_dur'])), np.array(list(T0_vals['best_depth'])), np.array(list(T0_vals['residuals']))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86d26b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctlfile = './Total_Mdwarf_files/final_mdwarf_params_new.csv'\n",
    "mdwarfs = pd.read_csv(ctlfile, iterator =True, chunksize = 100000, index_col=None)\n",
    "\n",
    "multi_mdwarfs = pd.concat(\n",
    "    [chunk[chunk['TICID'].astype(int).isin(TICIDs)] \n",
    "    for chunk in mdwarfs]\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48f9b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff28e077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TICID</th>\n",
       "      <th>RA</th>\n",
       "      <th>DEC</th>\n",
       "      <th>Vmag</th>\n",
       "      <th>Jmag</th>\n",
       "      <th>Tmag</th>\n",
       "      <th>Teff</th>\n",
       "      <th>eTeff_x</th>\n",
       "      <th>Rad</th>\n",
       "      <th>eRad</th>\n",
       "      <th>...</th>\n",
       "      <th>S54</th>\n",
       "      <th>S55</th>\n",
       "      <th>eTeff_y</th>\n",
       "      <th>logg</th>\n",
       "      <th>elogg</th>\n",
       "      <th>M/H</th>\n",
       "      <th>eM/H</th>\n",
       "      <th>GAIA</th>\n",
       "      <th>aLSM</th>\n",
       "      <th>bLSM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150428135.0</td>\n",
       "      <td>97.096787</td>\n",
       "      <td>-65.579312</td>\n",
       "      <td>13.151</td>\n",
       "      <td>9.469</td>\n",
       "      <td>10.9102</td>\n",
       "      <td>3494.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.419457</td>\n",
       "      <td>0.012573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.80892</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.284518e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>219195044.0</td>\n",
       "      <td>92.391740</td>\n",
       "      <td>-53.823484</td>\n",
       "      <td>13.311</td>\n",
       "      <td>10.241</td>\n",
       "      <td>11.5436</td>\n",
       "      <td>3731.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.473141</td>\n",
       "      <td>0.014147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.76101</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.500474e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>259377017.0</td>\n",
       "      <td>68.415501</td>\n",
       "      <td>-51.956232</td>\n",
       "      <td>12.603</td>\n",
       "      <td>9.099</td>\n",
       "      <td>10.4981</td>\n",
       "      <td>3532.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.374358</td>\n",
       "      <td>0.011496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.85053</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.781196e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36724087.0</td>\n",
       "      <td>154.646405</td>\n",
       "      <td>-11.716734</td>\n",
       "      <td>13.140</td>\n",
       "      <td>9.007</td>\n",
       "      <td>10.5848</td>\n",
       "      <td>3331.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.374139</td>\n",
       "      <td>0.011184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.85074</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.767282e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>235678745.0</td>\n",
       "      <td>285.633044</td>\n",
       "      <td>75.418605</td>\n",
       "      <td>13.190</td>\n",
       "      <td>9.797</td>\n",
       "      <td>11.0788</td>\n",
       "      <td>3746.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.463205</td>\n",
       "      <td>0.013592</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.76979</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.268372e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441798995.0</td>\n",
       "      <td>264.147791</td>\n",
       "      <td>77.126122</td>\n",
       "      <td>13.476</td>\n",
       "      <td>10.765</td>\n",
       "      <td>11.9521</td>\n",
       "      <td>3872.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.548484</td>\n",
       "      <td>0.016161</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.69525</td>\n",
       "      <td>0.009462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.657159e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>284441182.0</td>\n",
       "      <td>10.088709</td>\n",
       "      <td>61.213626</td>\n",
       "      <td>13.459</td>\n",
       "      <td>10.154</td>\n",
       "      <td>11.4752</td>\n",
       "      <td>3624.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.490120</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.74607</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.272241e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>467179528.0</td>\n",
       "      <td>197.998168</td>\n",
       "      <td>65.833807</td>\n",
       "      <td>12.941</td>\n",
       "      <td>9.706</td>\n",
       "      <td>11.0402</td>\n",
       "      <td>3618.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.435666</td>\n",
       "      <td>0.012939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.79432</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.678074e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TICID          RA        DEC    Vmag    Jmag     Tmag    Teff  \\\n",
       "0  150428135.0   97.096787 -65.579312  13.151   9.469  10.9102  3494.0   \n",
       "1  219195044.0   92.391740 -53.823484  13.311  10.241  11.5436  3731.0   \n",
       "2  259377017.0   68.415501 -51.956232  12.603   9.099  10.4981  3532.0   \n",
       "3   36724087.0  154.646405 -11.716734  13.140   9.007  10.5848  3331.0   \n",
       "4  235678745.0  285.633044  75.418605  13.190   9.797  11.0788  3746.0   \n",
       "5  441798995.0  264.147791  77.126122  13.476  10.765  11.9521  3872.0   \n",
       "6  284441182.0   10.088709  61.213626  13.459  10.154  11.4752  3624.0   \n",
       "7  467179528.0  197.998168  65.833807  12.941   9.706  11.0402  3618.0   \n",
       "\n",
       "   eTeff_x       Rad      eRad  ...   S54   S55  eTeff_y     logg     elogg  \\\n",
       "0    157.0  0.419457  0.012573  ...   0.0   0.0    157.0  4.80892  0.004651   \n",
       "1    157.0  0.473141  0.014147  ...   0.0   0.0    157.0  4.76101  0.007200   \n",
       "2    157.0  0.374358  0.011496  ...   0.0   0.0    157.0  4.85053  0.002090   \n",
       "3    157.0  0.374139  0.011184  ...   0.0   0.0    157.0  4.85074  0.001634   \n",
       "4    157.0  0.463205  0.013592  ...  10.0  10.0    157.0  4.76979  0.006479   \n",
       "5    157.0  0.548484  0.016161  ...  10.0  10.0    157.0  4.69525  0.009462   \n",
       "6    157.0  0.490120  0.014531  ...   0.0   0.0    157.0  4.74607  0.007723   \n",
       "7    157.0  0.435666  0.012939  ...   0.0   0.0    157.0  4.79432  0.005376   \n",
       "\n",
       "   M/H eM/H          GAIA  aLSM  bLSM  \n",
       "0  NaN  NaN  5.284518e+18   NaN   NaN  \n",
       "1  NaN  NaN  5.500474e+18   NaN   NaN  \n",
       "2  NaN  NaN  4.781196e+18   NaN   NaN  \n",
       "3  NaN  NaN  3.767282e+18   NaN   NaN  \n",
       "4  NaN  NaN  2.268372e+18   NaN   NaN  \n",
       "5  NaN  NaN  1.657159e+18   NaN   NaN  \n",
       "6  NaN  NaN  4.272241e+17   NaN   NaN  \n",
       "7  NaN  NaN  1.678074e+18   NaN   NaN  \n",
       "\n",
       "[8 rows x 80 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_mdwarfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7536e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "import ntpath\n",
    "\n",
    "\n",
    "LDC_for_quadratic = pd.read_csv('./LDC_files/table15.dat', \n",
    "                                header = None, \n",
    "                                sep=\"\\s+\", index_col=None,\n",
    "                               names = ['logg', 'Teff', 'z','L/HP', 'aLSM', 'bLSM',\n",
    "                                       'aFCM', 'bFCM', 'SQRT(CHI2)', 'qsr', 'PC'])\n",
    "\n",
    "mdwarf_LDC_for_quadratic = LDC_for_quadratic[LDC_for_quadratic['Teff']<4300]\n",
    "                  \n",
    "\n",
    "def match_logg_and_teff_for_LDC(df):\n",
    "    a = []\n",
    "    b = []\n",
    "#     print('a')\n",
    "    bar_format = \"{desc}{percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} targets | {elapsed}<{remaining}\"\n",
    "    pbar = tqdm(total=len(df), smoothing=0.3,  position=1, leave=True, bar_format=bar_format)\n",
    "    for i in range(len(df)):\n",
    "#         print(i)\n",
    "\n",
    "        Teff = np.float128(df['Teff'])[i]\n",
    "        logg =  np.float128(df['logg'])[i]\n",
    "        pbar.update(1)\n",
    "\n",
    "        try:\n",
    "            int(Teff)\n",
    "            mdwarf_Teff =mdwarf_LDC_for_quadratic[mdwarf_LDC_for_quadratic['Teff'] == np.median(mdwarf_LDC_for_quadratic.iloc[(mdwarf_LDC_for_quadratic['Teff'].astype('float128')-Teff+0.01).abs().argsort()[:8]].reset_index(drop=True)['Teff'])]\n",
    "            if i%100 == 0:\n",
    "    #                 print(Teff, set(mdwarf_Teff['Teff']))\n",
    "                if len(set(mdwarf_Teff['Teff']))>1:\n",
    "                       print(mdwarf_Teff)\n",
    "            if not abs(logg)>=0.:\n",
    "                logg = np.median(mdwarf_Teff['logg'])\n",
    "    #         print(mdwarf_Teff.iloc[(mdwarf_Teff['logg'].astype('float128')-logg-0.00000001).abs().argsort()].iloc[0][['aLSM', 'bLSM']])\n",
    "            aLSM, bLSM =  mdwarf_Teff.iloc[(mdwarf_Teff['logg'].astype('float128')-logg-0.00000001).abs().argsort()].iloc[0][['aLSM', 'bLSM']]\n",
    "#             print(aLSM, bLSM)\n",
    "            a.append(aLSM)\n",
    "            b.append(bLSM)  \n",
    "\n",
    "                    \n",
    "        except:\n",
    "            a.append(np.nan)\n",
    "            b.append(np.nan)\n",
    "    pbar.close()\n",
    "\n",
    "    df['aLSM'] = a\n",
    "    df['bLSM'] = b\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "207daf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d258d2468949a197826ed8c7b16e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 targets | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TICID</th>\n",
       "      <th>RA</th>\n",
       "      <th>DEC</th>\n",
       "      <th>Vmag</th>\n",
       "      <th>Jmag</th>\n",
       "      <th>Tmag</th>\n",
       "      <th>Teff</th>\n",
       "      <th>eTeff_x</th>\n",
       "      <th>Rad</th>\n",
       "      <th>eRad</th>\n",
       "      <th>...</th>\n",
       "      <th>S54</th>\n",
       "      <th>S55</th>\n",
       "      <th>eTeff_y</th>\n",
       "      <th>logg</th>\n",
       "      <th>elogg</th>\n",
       "      <th>M/H</th>\n",
       "      <th>eM/H</th>\n",
       "      <th>GAIA</th>\n",
       "      <th>aLSM</th>\n",
       "      <th>bLSM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150428135.0</td>\n",
       "      <td>97.096787</td>\n",
       "      <td>-65.579312</td>\n",
       "      <td>13.151</td>\n",
       "      <td>9.469</td>\n",
       "      <td>10.9102</td>\n",
       "      <td>3494.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.419457</td>\n",
       "      <td>0.012573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.80892</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.284518e+18</td>\n",
       "      <td>0.1604</td>\n",
       "      <td>0.4325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>219195044.0</td>\n",
       "      <td>92.391740</td>\n",
       "      <td>-53.823484</td>\n",
       "      <td>13.311</td>\n",
       "      <td>10.241</td>\n",
       "      <td>11.5436</td>\n",
       "      <td>3731.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.473141</td>\n",
       "      <td>0.014147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.76101</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.500474e+18</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.4118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>259377017.0</td>\n",
       "      <td>68.415501</td>\n",
       "      <td>-51.956232</td>\n",
       "      <td>12.603</td>\n",
       "      <td>9.099</td>\n",
       "      <td>10.4981</td>\n",
       "      <td>3532.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.374358</td>\n",
       "      <td>0.011496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.85053</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.781196e+18</td>\n",
       "      <td>0.1604</td>\n",
       "      <td>0.4325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36724087.0</td>\n",
       "      <td>154.646405</td>\n",
       "      <td>-11.716734</td>\n",
       "      <td>13.140</td>\n",
       "      <td>9.007</td>\n",
       "      <td>10.5848</td>\n",
       "      <td>3331.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.374139</td>\n",
       "      <td>0.011184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.85074</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.767282e+18</td>\n",
       "      <td>0.1529</td>\n",
       "      <td>0.4604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>235678745.0</td>\n",
       "      <td>285.633044</td>\n",
       "      <td>75.418605</td>\n",
       "      <td>13.190</td>\n",
       "      <td>9.797</td>\n",
       "      <td>11.0788</td>\n",
       "      <td>3746.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.463205</td>\n",
       "      <td>0.013592</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.76979</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.268372e+18</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.4118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441798995.0</td>\n",
       "      <td>264.147791</td>\n",
       "      <td>77.126122</td>\n",
       "      <td>13.476</td>\n",
       "      <td>10.765</td>\n",
       "      <td>11.9521</td>\n",
       "      <td>3872.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.548484</td>\n",
       "      <td>0.016161</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.69525</td>\n",
       "      <td>0.009462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.657159e+18</td>\n",
       "      <td>0.2946</td>\n",
       "      <td>0.3316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>284441182.0</td>\n",
       "      <td>10.088709</td>\n",
       "      <td>61.213626</td>\n",
       "      <td>13.459</td>\n",
       "      <td>10.154</td>\n",
       "      <td>11.4752</td>\n",
       "      <td>3624.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.490120</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.74607</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.272241e+17</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.3984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>467179528.0</td>\n",
       "      <td>197.998168</td>\n",
       "      <td>65.833807</td>\n",
       "      <td>12.941</td>\n",
       "      <td>9.706</td>\n",
       "      <td>11.0402</td>\n",
       "      <td>3618.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.435666</td>\n",
       "      <td>0.012939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.79432</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.678074e+18</td>\n",
       "      <td>0.1671</td>\n",
       "      <td>0.4201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TICID          RA        DEC    Vmag    Jmag     Tmag    Teff  \\\n",
       "0  150428135.0   97.096787 -65.579312  13.151   9.469  10.9102  3494.0   \n",
       "1  219195044.0   92.391740 -53.823484  13.311  10.241  11.5436  3731.0   \n",
       "2  259377017.0   68.415501 -51.956232  12.603   9.099  10.4981  3532.0   \n",
       "3   36724087.0  154.646405 -11.716734  13.140   9.007  10.5848  3331.0   \n",
       "4  235678745.0  285.633044  75.418605  13.190   9.797  11.0788  3746.0   \n",
       "5  441798995.0  264.147791  77.126122  13.476  10.765  11.9521  3872.0   \n",
       "6  284441182.0   10.088709  61.213626  13.459  10.154  11.4752  3624.0   \n",
       "7  467179528.0  197.998168  65.833807  12.941   9.706  11.0402  3618.0   \n",
       "\n",
       "   eTeff_x       Rad      eRad  ...   S54   S55  eTeff_y     logg     elogg  \\\n",
       "0    157.0  0.419457  0.012573  ...   0.0   0.0    157.0  4.80892  0.004651   \n",
       "1    157.0  0.473141  0.014147  ...   0.0   0.0    157.0  4.76101  0.007200   \n",
       "2    157.0  0.374358  0.011496  ...   0.0   0.0    157.0  4.85053  0.002090   \n",
       "3    157.0  0.374139  0.011184  ...   0.0   0.0    157.0  4.85074  0.001634   \n",
       "4    157.0  0.463205  0.013592  ...  10.0  10.0    157.0  4.76979  0.006479   \n",
       "5    157.0  0.548484  0.016161  ...  10.0  10.0    157.0  4.69525  0.009462   \n",
       "6    157.0  0.490120  0.014531  ...   0.0   0.0    157.0  4.74607  0.007723   \n",
       "7    157.0  0.435666  0.012939  ...   0.0   0.0    157.0  4.79432  0.005376   \n",
       "\n",
       "   M/H eM/H          GAIA    aLSM    bLSM  \n",
       "0  NaN  NaN  5.284518e+18  0.1604  0.4325  \n",
       "1  NaN  NaN  5.500474e+18  0.1737  0.4118  \n",
       "2  NaN  NaN  4.781196e+18  0.1604  0.4325  \n",
       "3  NaN  NaN  3.767282e+18  0.1529  0.4604  \n",
       "4  NaN  NaN  2.268372e+18  0.1737  0.4118  \n",
       "5  NaN  NaN  1.657159e+18  0.2946  0.3316  \n",
       "6  NaN  NaN  4.272241e+17  0.2125  0.3984  \n",
       "7  NaN  NaN  1.678074e+18  0.1671  0.4201  \n",
       "\n",
       "[8 rows x 80 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_logg_and_teff_for_LDC(multi_mdwarfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3b8d166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1604, 0.4325])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_mdwarfs[['aLSM', 'bLSM']].values[0].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d012bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_binning_function_by_time(time, flux, time_size_of_bins): \n",
    "    # Written by Mallory Harris\n",
    "\n",
    "    # Description: bins data in time, flux, and raw flux arrays as their mean value based on given time interval\n",
    "\n",
    "    # Arguments : time              = array of time, in days\n",
    "    #             flux              = array of flux \n",
    "    #             time_size_of_bins = bin size for time intervals, in minutes\n",
    "\n",
    "\n",
    "    # Return    : list of binned time, flux and \n",
    "    time = np.array(time).byteswap().newbyteorder()  #changes how the arrays are represented in memory\n",
    "    flux = np.array(flux).byteswap().newbyteorder() \n",
    "\n",
    "    interval = time_size_of_bins/60./24.#change units from minutes to days\n",
    "    df = pd.DataFrame({'time': time, 'flux':flux})\n",
    "    df = df.append(df)\n",
    "    #print(df)\n",
    "    numbins = np.array(list(range(int(np.ceil((max(time)-min(time))/interval))+1)))\n",
    "    #print(df)\n",
    "    print(numbins, min(time), interval)\n",
    "    bins = min(time) + interval*numbins\n",
    "    print(bins)\n",
    "    \n",
    "    #print(bins)\n",
    "    df['time_bins'] = pd.cut(df.time, bins)\n",
    "    new_time = [x for x in df.groupby('time_bins').median()['time'] if not math.isnan(x)] #finds the mean value of binned time\n",
    "    new_flux = [x for x in df.groupby('time_bins').median()['flux'] if not math.isnan(x)] #finds the mean value of binned flux\n",
    "    #print(len(new_time), len(new_flux), len(new_raw))\n",
    "    return np.array(new_time), np.array(new_flux)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c0287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0862e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(data, window_size):\n",
    "    \"\"\"Returns the moving average of an array `data`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array of numbers\n",
    "        The running mean will be computed on this data.\n",
    "    window_size : int\n",
    "        Window length used to compute the running mean.\n",
    "    \"\"\"\n",
    "    cumsum = np.cumsum(np.insert(data, 0, 0))\n",
    "    return (cumsum[window_size:] - cumsum[:-window_size]) / float(window_size)\n",
    "\n",
    "\n",
    "def remove_outliers(time, flux, sigma = 4.5, sigma_lower=None, sigma_upper=None, **kwargs):\n",
    "    outlier_mask = sigma_clip(data=flux,\n",
    "                              sigma=sigma,\n",
    "                              sigma_lower=sigma_lower,\n",
    "                              sigma_upper=sigma_upper,\n",
    "                              **kwargs).mask\n",
    "    # Second, we return the masked light curve and optionally the mask itself\n",
    "    return time[~outlier_mask], flux[~outlier_mask]\n",
    "    \n",
    "def flatten_lc(time, flux):\n",
    "    flat_flux, flux_trend = flatten(\n",
    "    time,                 # Array of time values\n",
    "    flux,                 # Array of flux values\n",
    "    method='biweight',\n",
    "    window_length=0.9,    # The length of the filter window in units of ``time``\n",
    "#     edge_cutoff=0.1,      # length (in units of time) to be cut off each edge.\n",
    "#     break_tolerance=1,  # Split into segments at breaks longer than that\n",
    "    return_trend=True,    # Return trend and flattened light curve\n",
    "#     cval=5.0              # Tuning parameter for the robust estimators\n",
    "    )\n",
    "    return flat_flux, flux_trend\n",
    "\n",
    "def cleaning_up_data(time, flux):\n",
    "#     flux = flux/np.nanmedian(flux)\n",
    "#     try: \n",
    "#         flattened_flux = flatten_lc(time, flux)\n",
    "\n",
    "#     except Exception as error: \n",
    "#         flattened_flux = flux\n",
    "\n",
    "    cleaned_time, cleaned_flux = remove_outliers(time, flux)\n",
    "    return cleaned_time, cleaned_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61701e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_if_doesnt_exist(outdir, str_new_dir_name):\n",
    "    # Written by Mallory Harris\n",
    "\n",
    "    # Description: creates new directory to save data to if it does not already exist\n",
    "\n",
    "    # Arguments : outdir             = existing directory in which new directory will be located\n",
    "    #             str_new_dir_name   = string of the new subdirectory of outdir's name\n",
    "\n",
    "\n",
    "    if os.path.exists(outdir+str_new_dir_name)==False:\n",
    "        new_outdir = os.path.join(outdir, str_new_dir_name)\n",
    "        os.mkdir(new_outdir)\n",
    "\n",
    "\n",
    "def fetch(ticid, sector_num, pipeline, exptime): \n",
    "    # Written by Mallory Harris\n",
    "\n",
    "    # Description: uses lightkurve to download TESS fits file based on sector number, source pipeline, exposure time and star id\n",
    "\n",
    "    # Arguments : ticid       = TESS Input Catalog identification number of star\n",
    "    #             sector_num  = sector from which to download data\n",
    "    #             pipeline    = source pipeline from which to get data (options are 'QLP', 'SPOC', 'TESS-SPOC')\n",
    "    #             exptime     = exposure length of observations (2 or 30 minutes, depending on pipeline) units of seconds\n",
    "    #                           'QLP', 'TESS-SPOC' = 30 minute (1800 s) exptime\n",
    "    #                           'SPOC'             = 2  minutte (120 s) exptime\n",
    "\n",
    "\n",
    "    good_authors = [pipeline]\n",
    "    if pipeline == 'SPOC':\n",
    "        Path = './known_Mdwarfs_data/mastDownload'\n",
    "        small_dir_path_lst = glob.glob(Path+\"/TESS/*\"+str(ticid).zfill(16)+\"*\")\n",
    "    else:\n",
    "        Path = './known_Mdwarfs_data/FFI_data/'\n",
    "        if sector_num != None:\n",
    "            Path = Path+'sector_'+str(sector_num)+'/mastDownload'\n",
    "        else:\n",
    "            Path = Path+'all_target_data/tic_'+str(ticid)+'_all'\n",
    "#         print(Path)\n",
    "        small_dir_path_lst = glob.glob(Path+\"/HLSP/*\"+str(ticid).zfill(16)+\"*\")\n",
    "\n",
    "        \n",
    "        if pipeline == 'QLP':\n",
    "            small_dir_path_lst = [i for i in small_dir_path_lst if 'ffi' in i]\n",
    "        elif pipeline == 'TESS-SPOC':\n",
    "            small_dir_path_lst = [i for i in small_dir_path_lst if 'tess-spoc' in i]\n",
    "            \n",
    "    for i in small_dir_path_lst:\n",
    "        file = glob.glob(i+'/*.fits')\n",
    "        print('there is something already in the folder:', len(file))\n",
    "        os.remove(file[0])\n",
    "        print('it was removed')\n",
    "        \n",
    "    search = lk.search_lightcurve('TIC '+str(ticid), mission='TESS', sector=sector_num, exptime =exptime)\n",
    "#     print(search)\n",
    "    try:\n",
    "        result = all(elem in list(search.author)  for elem in good_authors)\n",
    "    except:\n",
    "        print(search)\n",
    "        result = False\n",
    "\n",
    "    if result == True:\n",
    "        search = search[search.author == pipeline]\n",
    "        if sector_num!= None:\n",
    "            search.download(quality_bitmask='default', download_dir = './known_Mdwarfs_data/FFI_data/sector_'+str(sector_num))\n",
    "        else:\n",
    "            \n",
    "            search.download_all(quality_bitmask='default', download_dir = './known_Mdwarfs_data/FFI_data/all_target_data/tic_'+str(ticid)+'_all')\n",
    "\n",
    "        print('done downloading')\n",
    "    else:\n",
    "        print('No '+pipeline+' obervations')\n",
    "\n",
    "def get_lcf_files(df, pipeline, last_hung_ticid = 0, sector_num = False):\n",
    "    # Written by Mallory Harris\n",
    "\n",
    "    # Description: takes dataframe of TICIDs observed in a given sector (identified by a column in df, explained below)\n",
    "    #              to download light curves of that sector for each ticid from given pipeline \n",
    "            \n",
    "\n",
    "    # Arguments : df              = panda dataframe. Must include at least one column of \"TICID\" with TESS identification number\n",
    "    #                               and one column denoting whether or not observations were taken in the named sector.\n",
    "    #                               example: if targets are observed in sector 20, their value in the column \"S20\" will be >0\n",
    "    #             sector_num      = sector from which to download data\n",
    "    #             pipeline        = source pipeline from which to get data (options are 'QLP', 'SPOC', 'TESS-SPOC')\n",
    "    #             last_hung_ticid = if, for any reason, this function is stopped, one can enter that last downloaded TICID to avoid re-downloading data\n",
    "\n",
    "    if pipeline == 'SPOC':\n",
    "        exptime = 'short'\n",
    "    else:\n",
    "        exptime = 'long'\n",
    "    if sector_num!=False:\n",
    "        new_df = df[df['S'+str(sector_num)]>0.].reset_index(drop = True)\n",
    "        print('sector '+str(sector_num), 'num targets', len(new_df))\n",
    "\n",
    "    else:\n",
    "        new_df = df.copy()\n",
    "        sector_num = None\n",
    "    indx = 0\n",
    "\n",
    "    if last_hung_ticid != 0:\n",
    "        indx = new_df[new_df['TICID'] == last_hung_ticid].index[0]\n",
    "    print('starting index: ', indx)\n",
    "    r = indx\n",
    "    sector_PS_targets = new_df[indx:]\n",
    "    #start_time = time.time()\n",
    "    masteroutdir = './known_Mdwarfs_data/'\n",
    "    if pipeline == 'QLP' or pipeline == 'TESS-SPOC':\n",
    "        mkdir_if_doesnt_exist(masteroutdir, 'FFI_data/')\n",
    "        masteroutdir = masteroutdir + 'FFI_data/'\n",
    "    else:\n",
    "        mkdir_if_doesnt_exist(masteroutdir, 'tic_data/')\n",
    "\n",
    "        masteroutdir = masteroutdir + 'tic_data/'\n",
    "    mkdir_if_doesnt_exist(masteroutdir, 'sector_'+str(sector_num))\n",
    "\n",
    "\n",
    "    \n",
    "    for i in sector_PS_targets['TICID']:\n",
    "        print(r)\n",
    "        r +=1\n",
    "\n",
    "        ticid = int(i)\n",
    "        \n",
    "        print('TIC '+str(ticid))\n",
    "        #print(time.localtime())\n",
    "        while 1<2:\n",
    "            proc = Process(target=fetch, args=(ticid, sector_num, pipeline, exptime))\n",
    "            proc.start()\n",
    "            proc.join(timeout = 45)\n",
    "            proc.terminate()\n",
    "            if proc.exitcode is None:\n",
    "                print('timeout')\n",
    "                continue\n",
    "            else:\n",
    "                print('success!')\n",
    "                break\n",
    "    print('All done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9dbf051",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from math import gcd, log10, pow\n",
    "\n",
    "def cf(num1,num2):\n",
    "    n=[]\n",
    "    g=gcd(num1, num2)\n",
    "    for i in range(1, int(np.sqrt(g))+1):\n",
    "        if g%i==0:\n",
    "            n.append(i)\n",
    "            if g!=i*i:\n",
    "                n.append(int(g/i))\n",
    "    return n\n",
    "\n",
    "def float_scale(x):\n",
    "    max_digits = 3\n",
    "    int_part = int(abs(x))\n",
    "    magnitude = 1 if int_part == 0 else int(log10(int_part)) + 1\n",
    "    if magnitude >= max_digits:\n",
    "        return 0\n",
    "    frac_part = abs(x) - int_part\n",
    "    multiplier = 10 ** (max_digits - magnitude)\n",
    "    frac_digits = multiplier + int(multiplier * frac_part + 0.5)\n",
    "    while frac_digits % 10 == 0:\n",
    "        frac_digits /= 10\n",
    "    return int(log10(frac_digits))\n",
    "\n",
    "\n",
    "def float_gcd(a, b):\n",
    "    sc = float_scale(a)\n",
    "    sc_b = float_scale(b)\n",
    "    sc = sc_b if sc_b > sc else sc\n",
    "    fac = pow(10, sc)\n",
    "\n",
    "    a = int(round(a*fac))\n",
    "    b = int(round(b*fac))\n",
    "\n",
    "#     print(type(cf(a,b)))\n",
    "    return [round(x, sc) for x in np.array(cf(a, b))/fac]\n",
    "\n",
    "def find_common_denom_given_two_differences(a, b):\n",
    "    c = abs(a-b)\n",
    "    if (c == a) or (c == b) or (a==b):\n",
    "        return []\n",
    "    else:\n",
    "        A_cd = float_gcd(a, b)\n",
    "        B_cd = float_gcd(a, c)\n",
    "        C_cd = float_gcd(b, c)\n",
    "\n",
    "        return list(set.intersection(*map(set,[A_cd, B_cd, C_cd])))\n",
    "\n",
    "def check_if_singles_are_periodic(T0_lst):\n",
    "    new_rrr = []\n",
    "    T0_vals = []\n",
    "    for j in range(len(T0_lst)):\n",
    "        diff = np.array(T0_lst)-T0_lst[j]\n",
    "        for i in range(len(diff)):\n",
    "            for k in range(len(diff)):\n",
    "                if k == j or i == j:\n",
    "                    continue\n",
    "                else:\n",
    "                    rrr = np.array(find_common_denom_given_two_differences(diff[i], diff[k]))\n",
    "                    if len(rrr[rrr>12.])>0:\n",
    "                        new_rrr.append(list(rrr[rrr>12.]))\n",
    "                        T0_vals.extend([T0_lst[i], T0_lst[j], T0_lst[k]])\n",
    "\n",
    "\n",
    "    set_rrr = [ele for ind, ele in enumerate(new_rrr) if ele not in new_rrr[:ind]]    \n",
    "    T0_vals = list(set(T0_vals))\n",
    "    \n",
    "    T0_per_vals = []\n",
    "    for val in list(set_rrr):\n",
    "        pers = new_rrr[new_rrr == val]\n",
    "        T0_min = min(T0_vals)\n",
    "#         print(T0_vals)\n",
    "        per_max = max(pers)\n",
    "        T0_per_vals.append([T0_min, per_max, T0_vals])\n",
    "    return T0_per_vals\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "360e92a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def lnprob_MCMC_global(pars):\n",
    "    flux,unc,time,cad,tc, ld_params = PARAMS\n",
    "    u1, u2 = ld_params\n",
    "    t0 = pars[0]\n",
    "    P = pars[1]\n",
    "    rp_rs = pars[2]\n",
    "    cosi = pars[3]\n",
    "    a = pars[4]\n",
    "    norm = pars[5]\n",
    "    b = np.abs(a*cosi)\n",
    "    #make sure all pars are good\n",
    "\n",
    "    if np.abs(tc-t0)>0.25: return -np.inf\n",
    "    if np.max([u1,u2,cosi,rp_rs]) > 1.: return -np.inf\n",
    "    if np.min([u1,u2,cosi,rp_rs]) < 0.: return -np.inf\n",
    "    if a < 1: return -np.inf\n",
    "    if b > 1: return -np.inf\n",
    "\n",
    "    flux_theo = predict_lc(time,t0,P,rp_rs,cosi,a,u1,u2,cad)\n",
    "    flux=flux*norm\n",
    "    unc=unc*norm\n",
    "    result = 0.-0.5*np.sum(((flux_theo-flux)/unc)**2.)\n",
    "    if np.isfinite(result) != True:\n",
    "        #print('bad result')\n",
    "        return -np.inf\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def predict_lc(time_lc,t0,P,rp_rs,cosi,a,u1,u2,cad):\n",
    "    oversample = 4\n",
    "    e,omega = 0., np.pi/2.\n",
    "    inc = np.arccos(cosi)*180./np.pi\n",
    "\n",
    "    params = batman.TransitParams()\n",
    "    params.t0 = t0\n",
    "    params.per = P\n",
    "    params.rp = rp_rs\n",
    "    params.a = a\n",
    "    params.inc = inc\n",
    "    params.ecc = e\n",
    "    params.w = omega*180./np.pi\n",
    "    params.u = [u1,u2]\n",
    "    params.limb_dark = \"quadratic\"\n",
    "\n",
    "    m = batman.TransitModel(params, time_lc ,supersample_factor = oversample, exp_time = cad/24./60.)\n",
    "\n",
    "    flux_theo = m.light_curve(params)\n",
    "\n",
    "    return(flux_theo)\n",
    "\n",
    "\n",
    "def create_model_lc(time,t0,P,rp_rs,i,a,ld_params,cad):\n",
    "    oversample = 4\n",
    "    e,omega = 0., 90.\n",
    "\n",
    "    params = batman.TransitParams()\n",
    "    params.t0 = t0\n",
    "    params.per = P\n",
    "    params.rp = rp_rs\n",
    "    params.a = a\n",
    "    params.inc = i\n",
    "    params.ecc = e\n",
    "    params.w = omega\n",
    "    params.u = ld_params\n",
    "    params.limb_dark = \"quadratic\"\n",
    "\n",
    "    m = batman.TransitModel(params, time ,supersample_factor = oversample, exp_time = cad/24./60.)\n",
    "\n",
    "    flux_theo = m.light_curve(params)\n",
    "\n",
    "    return(flux_theo)\n",
    "\n",
    "\n",
    "\n",
    "def run_mcmc_code_for_tdur_and_depth(time, flux, T0, per, ld_params, cad = 30.,\n",
    "                           e = 0., inc = 90., b= 0., omega = 90., rp = 0.05, verbose =True):\n",
    "\n",
    "    nwalkers = 40\n",
    "    nchain = 1000\n",
    "    bchain = int(0.25*nchain)\n",
    "\n",
    "    ini_names = ['t0','per','rp/R*','cosi','a/R*','norm']\n",
    "    ini = np.array([T0,per,0.01,0.,per,1.0],dtype=float)\n",
    "\n",
    "    ndim = len(ini)\n",
    "    err = np.array([0.001,0.001, 0.001,0.01,0.1,0.01])\n",
    "    pos = [ini+5e-3*err*np.random.randn(ndim) for rrr in range(nwalkers)]\n",
    "    #print(ini)\n",
    "\n",
    "    ff=flux\n",
    "    uu=np.full(len(flux), np.std(flux))\n",
    "    tt=time\n",
    "    PP=per\n",
    "    cad=cad\n",
    "\n",
    "    global PARAMS\n",
    "    \n",
    "\n",
    "    PARAMS = [ff,uu,tt,cad,T0, ld_params]\n",
    "    #     print('globals 1 ',  len(globals()))\n",
    "\n",
    "    with Pool() as pool:\n",
    "        sampler = emcee.EnsembleSampler(nwalkers,ndim,lnprob_MCMC_global,pool=pool)\n",
    "\n",
    "    #         start = time.time()\n",
    "        sampler.run_mcmc(pos,nchain,progress=True)\n",
    "\n",
    "    del globals()['PARAMS']\n",
    "#     sampler = emcee.EnsembleSampler(nwalkers,ndim,lnprob,args=(ff,uu,tt,cad,T0, ld_params))\n",
    "#     sampler.run_mcmc(pos,nchain,progress=True)\n",
    "    samples = sampler.chain[:, bchain:, :].reshape((-1,ndim))\n",
    "\n",
    "    fig = corner.corner(samples, labels = ini_names)\n",
    "    plt.show()\n",
    "\n",
    "    report = list(map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]), zip(*np.percentile(samples, [16, 50, 84],axis=0))))\n",
    "    \n",
    "\n",
    "    t0 = report[0][0]\n",
    "    period = report[1][0]\n",
    "    rp_rs = report[2][0]\n",
    "    cosi = report[3][0]\n",
    "    v=np.percentile(np.arccos(samples[:,3])*180/np.pi, [50, 16, 84])\n",
    "    inc = v[1]\n",
    "    a = report[4][0]\n",
    "    b = np.abs(a*cosi)\n",
    "    depth = rp_rs**2.\n",
    "    T0 = (per*24.)/(a*np.pi)\n",
    "    tau = rp*T0/np.sqrt(1.-(b**2.))\n",
    "    dur = np.sqrt(1.-(b**2.))*T0+tau\n",
    "    if verbose:\n",
    "#         fig = corner.corner(samples, labels = ini_names)\n",
    "#         plt.show()\n",
    "        \n",
    "        flux_mcmc = create_model_lc(time,t0,period,rp_rs,inc,a,ld_params,cad)\n",
    "        plt.xlim(T0-dur*4, T0+dur*4)\n",
    "        plt.plot(time, flux_mcmc, color = 'r')\n",
    "        plt.scatter(time, flux, s=2, color = 'k')\n",
    "        plt.xlabel(\"Time from central transit\")\n",
    "        plt.ylabel(\"Relative flux\")\n",
    "        plt.show()\n",
    "    return dur, depth, t0, period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "522bc627",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_breaks(time, val = 0.5):\n",
    "    time = time[np.argsort(time)] \n",
    "    t   = np.diff(time)\n",
    "    inds = np.where( t>val)[0]\n",
    "    return inds + 1\n",
    "\n",
    "def sort_data_by_times(time, flux):\n",
    "    return time[np.argsort(time)], flux[np.argsort(time)]\n",
    "\n",
    "\n",
    "def breaking_up_data(time, flux, break_val = 0.5):\n",
    "    brk = np.append(np.append([0], find_breaks(time, break_val)), [len(time)])\n",
    "    new_time, new_flux = sort_data_by_times(time, flux)\n",
    "    times = []\n",
    "    fluxes = []\n",
    "    for i in range(len(brk)-1):\n",
    "    # np.arange(brk[0], brk[1], 1)\n",
    "        r = np.arange(brk[i],brk[i+1], 1)\n",
    "    #     print(brk[i], brk[i+1])\n",
    "    #     print(min(time[r]), max(time[r]), len(time[r]))\n",
    "        if len(new_time[r]>2):\n",
    "            times.append(new_time[r])\n",
    "            fluxes.append(new_flux[r])\n",
    "    return np.array(times), np.array(fluxes), np.array(new_time), np.array(new_flux)\n",
    "#     t1 = time[r1]; f1 = flux[r1]\n",
    "#     t2 = time[r2]; f2 = flux[r2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d613e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_yaxis(ax1, v1, ax2, v2):\n",
    "    \"\"\"adjust ax2 ylimit so that v2 in ax2 is aligned to v1 in ax1\"\"\"\n",
    "    _, y1 = ax1.transData.transform((0, v1))\n",
    "    _, y2 = ax2.transData.transform((0, v2))\n",
    "    inv = ax2.transData.inverted()\n",
    "    _, dy = inv.transform((0, 0)) - inv.transform((0, y1-y2))\n",
    "    miny, maxy = ax2.get_ylim()\n",
    "    ax2.set_ylim(miny+dy, maxy+dy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235b2a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a82f8779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catalog_info(ticid, df = False):\n",
    "    if type(df) == bool:\n",
    "        ctlfile = './Total_Mdwarf_files/final_mdwarf_params_new.csv'\n",
    "        mdwarfs = pd.read_csv(ctlfile, iterator =True, chunksize = 100000, index_col=None, header = 0)\n",
    "        df = pd.concat(\n",
    "            [chunk[chunk['TICID'].astype(int) == ticid] \n",
    "            for chunk in mdwarfs]\n",
    "        ).reset_index(drop=True)\n",
    "    else:\n",
    "        df = df[df['TICID']==ticid]\n",
    "    return df[['aLSM', 'bLSM']].values[0].astype(float), float(df['Mass']), float(df['eMass']), float(df['eMass']), float(df['Rad']), float(df['eRad']), float(df['eRad'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b634351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def using_TLS_to_find_periodic_signals(time, flux, u, verbose = True, show_progress_info = True, \n",
    "                                       intransit = [],\n",
    "                                       periods = [], T0 = [], Tdur = [], depths = [], first=True):\n",
    "    if first == True:\n",
    "        intransit = np.full(len(time), False)\n",
    "        periods = []\n",
    "        T0 = []\n",
    "        Tdur = []\n",
    "        depths = []\n",
    "\n",
    "    time_new = time[~intransit]\n",
    "    flux_new = flux[~intransit]\n",
    "    if len(time_new)>0:\n",
    "        model = transitleastsquares(time_new, flux_new)\n",
    "        try:\n",
    "            results = model.power(limb_dark='quadratic', u=ab, period_max=100., show_progress_info = show_progress_info)\n",
    "        except:\n",
    "            print('is the limb darkening good?', ab)\n",
    "            results = model.power(period_max=100.)\n",
    "#     print('params', periods, T0, Tdur, depths)\n",
    "\n",
    "        if not np.abs(np.diff(np.array(sorted(results.power))[[-1, -2]]))>2*np.std(np.diff(results.power)) or len(time_new)==0 :\n",
    "            print('done with multis!')\n",
    "\n",
    "            return np.array(periods), np.array(T0), np.array(Tdur), np.array(depths), intransit\n",
    "        else:\n",
    "            intransit = intransit+transit_mask(time, results.period, 2*results.duration+(2*0.04), results.T0)\n",
    "            if round(results.T0, 4) in [round(x, 4) for x in T0]:\n",
    "                return using_TLS_to_find_periodic_signals(time, flux, u, intransit=intransit, verbose = verbose,  periods = periods, T0 = T0, Tdur = Tdur, depths = depths, first = False)\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print('duration picked: ', results.duration)\n",
    "                    plt.figure(figsize = (10, 10))\n",
    "\n",
    "                    ax = plt.gca()\n",
    "                    ax.set_facecolor('None')\n",
    "                    ax.axvline(results.period, alpha=0.6, lw=3.5,  color='#E4D7BA')\n",
    "                    plt.xlim(np.min(results.periods), np.max(results.periods))\n",
    "                    for n in range(2, 10):\n",
    "                        ax.axvline(n*results.period, alpha=0.25, lw=2, linestyle=\"dashed\",  color='#E4D7BA')\n",
    "                        ax.axvline(results.period / n, alpha=0.25, lw=2, linestyle=\"dashed\",  color='#E4D7BA')\n",
    "                    for per in periods:\n",
    "                        ax.axvline(per, alpha=0.6, lw=2, linestyle=\"dashed\",  color='#E4D7BA')\n",
    "\n",
    "#                         ax.axvline(results.period / n, alpha=0.4, lw=1, linestyle=\"dashed\",  color='#B06200')\n",
    "                    plt.ylabel(r'SDE', fontsize = 40)\n",
    "                    plt.xlabel('Period (days)', fontsize = 40)\n",
    "                    plt.plot(results.periods, results.power, color = '#EB8300', lw=0.65)\n",
    "#                     plt.xlim(0, 100.);\n",
    "                    ax.xaxis.label.set_color('#BC9B54')        #setting up X-axis label color to yellow\n",
    "                    ax.yaxis.label.set_color('#BC9B54')          #setting up Y-axis label color to blue\n",
    "\n",
    "                    ax.tick_params(axis='x', colors='#BC9B54', labelsize = 35, width=3, length = 8)    #setting up X-axis tick color to red\n",
    "                    ax.tick_params(axis='y', colors='#BC9B54', labelsize = 35, width=3, length = 8)  #setting up Y-axis tick color to black\n",
    "\n",
    "                    ax.spines['left'].set_color(None)        # setting up Y-axis tick color to red\n",
    "                    ax.spines['bottom'].set_color(None)         #setting up above X-axis tick color to red\n",
    "                    ax.spines['top'].set_color(None)        # setting up Y-axis tick color to red\n",
    "                    ax.spines['right'].set_color(None)         #setting up above X-axis tick color to red\n",
    "\n",
    "                    plt.figure(figsize = (10, 10))\n",
    "                    ax = plt.gca()\n",
    "                    ax.xaxis.label.set_color('#BC9B54')        #setting up X-axis label color to yellow\n",
    "                    ax.yaxis.label.set_color('#BC9B54')          #setting up Y-axis label color to blue\n",
    "\n",
    "                    ax.tick_params(axis='x', colors='#BC9B54', labelsize = 35, width=3, length = 8)    #setting up X-axis tick color to red\n",
    "                    ax.tick_params(axis='y', colors='#BC9B54', labelsize = 35, width=3, length = 8)  #setting up Y-axis tick color to black\n",
    "                    ax.spines['top'].set_color(None)        # setting up Y-axis tick color to red\n",
    "                    ax.spines['right'].set_color(None)         #setting up above X-axis tick color to red\n",
    "\n",
    "                    ax.spines['left'].set_color(None)        # setting up Y-axis tick color to red\n",
    "                    ax.spines['bottom'].set_color(None)         #setting up above X-axis tick color to red\n",
    "\n",
    "                    ax.set_facecolor('None')\n",
    "\n",
    "                    ax.plot(\n",
    "                        results.model_folded_phase,\n",
    "                        results.model_folded_model,\n",
    "                        color='#EB8300', lw = 6.5)\n",
    "                    ax.scatter(\n",
    "                        results.folded_phase,\n",
    "                        results.folded_y,\n",
    "                        color='#E4D7BA',\n",
    "                        s=10,\n",
    "                        alpha=0.8,\n",
    "                        zorder=2)\n",
    "#                     ax.set_xlim(0.49, 0.51)\n",
    "    #                 plt.ylim(0.9985, 1.00025)\n",
    "                    ax.set_xlabel('Phase', color = '#BC9B54', fontsize = 40)\n",
    "                    ax.set_ylabel('Relative Flux', color = '#BC9B54', fontsize = 40);\n",
    "                    plt.show()\n",
    "                    print('T0: ', results.T0, 'duration: ', results.duration, 'npoints_dur: ', np.ceil(results.duration/30.))\n",
    "                depths.append(results.depth)\n",
    "                periods.append(results.period)\n",
    "                T0.append(results.T0)\n",
    "                Tdur.append(results.duration)\n",
    "                return using_TLS_to_find_periodic_signals(time, flux, u, intransit=intransit, verbose = verbose,  periods = periods, T0 = T0, Tdur = Tdur, depths = depths, first = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca611e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "905f1057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.04*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc64e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def using_TLS_to_find_periodic_signals(time, flux, u, verbose = False, show_progress_info = True, \n",
    "                                       intransit = [],\n",
    "                                       periods = [], T0 = [], Tdur = [], depths = [], first=True):\n",
    "    if first == True:\n",
    "        intransit = np.full(len(time), False)\n",
    "        periods = []\n",
    "        T0 = []\n",
    "        Tdur = []\n",
    "        depths = []\n",
    "\n",
    "    time_new = time[~intransit]\n",
    "    flux_new = flux[~intransit]\n",
    "    if len(time_new)>0:\n",
    "        model = transitleastsquares(time_new, flux_new)\n",
    "        try:\n",
    "            results = model.power(limb_dark='quadratic', u=ab, period_max=100., show_progress_info = show_progress_info)\n",
    "        except:\n",
    "            print('is the limb darkening good?', ab)\n",
    "            results = model.power(period_max=100.)\n",
    "#     print('params', periods, T0, Tdur, depths)\n",
    "\n",
    "#         else:\n",
    "        if round(results.T0, 4) in [round(x, 4) for x in T0]:\n",
    "            intransit = intransit+transit_mask(time, results.period, 2*results.duration+(2*0.04), results.T0)\n",
    "\n",
    "            return using_TLS_to_find_periodic_signals(time, flux, u, intransit=intransit, verbose = verbose,  periods = periods, T0 = T0, Tdur = Tdur, depths = depths, first = False)\n",
    "        if verbose:\n",
    "            print('duration picked: ', results.duration)\n",
    "            plt.figure(figsize = (10, 10))\n",
    "\n",
    "            ax = plt.gca()\n",
    "            ax.set_facecolor('None')\n",
    "            ax.axvline(results.period, alpha=0.6, lw=3.5,  color='#E4B7DA')\n",
    "            plt.xlim(np.min(results.periods), np.max(results.periods))\n",
    "            for n in range(2, 10):\n",
    "                ax.axvline(n*results.period, alpha=0.25, lw=2, linestyle=\"dashed\",  color='#E4B7DA')\n",
    "                ax.axvline(results.period / n, alpha=0.25, lw=2, linestyle=\"dashed\",  color='#E4B7DA')\n",
    "            for per in periods:\n",
    "                ax.axvline(per, alpha=0.6, lw=2, linestyle=\"dashed\",  color='#E4B7DA')\n",
    "\n",
    "#                         ax.axvline(results.period / n, alpha=0.4, lw=1, linestyle=\"dashed\",  color='#B06200')\n",
    "            plt.ylabel(r'SDE', fontsize = 40)\n",
    "            plt.xlabel('Period (days)', fontsize = 40)\n",
    "            plt.plot(results.periods, results.power, color = '#EB8300', lw=0.65)\n",
    "            plt.xlim(0, 100.);\n",
    "            ax.xaxis.label.set_color('#BC9B54')        #setting up X-axis label color to yellow\n",
    "            ax.yaxis.label.set_color('#BC9B54')          #setting up Y-axis label color to blue\n",
    "            ax.tick_params(axis='x', colors='#BC9B54', labelsize = 35, width=3, length = 8)    #setting up X-axis tick color to red\n",
    "            ax.tick_params(axis='y', colors='#BC9B54', labelsize = 35, width=3, length = 8)  #setting up Y-axis tick color to black\n",
    "\n",
    "            ax.spines['left'].set_color(None)        # setting up Y-axis tick color to red\n",
    "            ax.spines['bottom'].set_color(None)         #setting up above X-axis tick color to red\n",
    "            ax.spines['top'].set_color(None)        # setting up Y-axis tick color to red\n",
    "            ax.spines['right'].set_color(None)         #setting up above X-axis tick color to red\n",
    "\n",
    "            plt.figure(figsize = (10, 10))\n",
    "            ax = plt.gca()\n",
    "            ax.xaxis.label.set_color('#BC9B54')        #setting up X-axis label color to yellow\n",
    "            ax.yaxis.label.set_color('#BC9B54')          #setting up Y-axis label color to blue\n",
    "\n",
    "            ax.tick_params(axis='x', colors='#BC9B54', labelsize = 35, width=3, length = 8)    #setting up X-axis tick color to red\n",
    "            ax.tick_params(axis='y', colors='#BC9B54', labelsize = 35, width=3, length = 8)  #setting up Y-axis tick color to black\n",
    "            ax.xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "\n",
    "            ax.spines['top'].set_color(None)        # setting up Y-axis tick color to red\n",
    "            ax.spines['right'].set_color(None)         #setting up above X-axis tick color to red\n",
    "\n",
    "            ax.spines['left'].set_color(None)        # setting up Y-axis tick color to red\n",
    "            ax.spines['bottom'].set_color(None)         #setting up above X-axis tick color to red\n",
    "\n",
    "            ax.set_facecolor('None')\n",
    "\n",
    "            ax.plot(\n",
    "                results.model_folded_phase,\n",
    "                results.model_folded_model,\n",
    "                color='#EB8300', lw = 6.5)\n",
    "            ax.scatter(\n",
    "                results.folded_phase,\n",
    "                results.folded_y,\n",
    "                color='#E4B7DA',\n",
    "                s=10,\n",
    "                alpha=0.8,\n",
    "                zorder=2)\n",
    "            ax.set_xlim(0.49, 0.51)\n",
    "#                 plt.ylim(0.9985, 1.00025)\n",
    "            ax.set_xlabel('Phase', color = '#BC9B54', fontsize = 30)\n",
    "            ax.set_ylabel('Relative Flux', color = '#BC9B54', fontsize = 30);\n",
    "            plt.show()\n",
    "            print('T0: ', results.T0, 'duration: ', results.duration, 'npoints_dur: ', np.ceil(results.duration/30.))\n",
    "        if not np.abs(np.diff(np.array(sorted(results.power))[[-1, -2]]))>2*np.std(np.diff(results.power)) or len(time_new)==0 :\n",
    "\n",
    "            print('done with multis!')\n",
    "            print('per', periods)\n",
    "\n",
    "            return np.array(periods), np.array(T0), np.array(Tdur), np.array(depths), intransit\n",
    "        else: \n",
    "            intransit = intransit+transit_mask(time, results.period, 2*results.duration+(2*0.04), results.T0)\n",
    "\n",
    "            depths.append(results.depth)\n",
    "            periods.append(results.period)\n",
    "            T0.append(results.T0)\n",
    "            Tdur.append(results.duration)\n",
    "\n",
    "            return using_TLS_to_find_periodic_signals(time, flux, u, intransit=intransit, verbose = verbose,  periods = periods, T0 = T0, Tdur = Tdur, depths = depths, first = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57d1a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "\n",
    "model_colors = ['#FF930F', '#71F8FF']\n",
    "def using_BLS_to_find_periodic_signals(time, flux, u, verbose = False, show_progress_info = True, \n",
    "                                       intransit = [],\n",
    "                                       periods = [], T0 = [], Tdur = [], depths = [], first=True):\n",
    "    if first == True:\n",
    "        intransit = np.full(len(time), False)\n",
    "        periods = []\n",
    "        T0 = []\n",
    "        Tdur = []\n",
    "        depths = []\n",
    "\n",
    "    time_new = time[~intransit]\n",
    "    flux_new = flux[~intransit]\n",
    "    if len(time_new)>0:\n",
    "        start = tm.time()\n",
    "\n",
    "        durations = np.linspace(0.05, 0.5, 50)\n",
    "        model     = BoxLeastSquares(time_new, flux_new)\n",
    "        results   = model.autopower(durations, frequency_factor=10)\n",
    "        \n",
    "        print('results ', results)\n",
    "        period    = results.period[np.argmax(results.power)]\n",
    "#     print('params', periods, T0, Tdur, depths)\n",
    "        end = tm.time()\n",
    "        print('planet run: BLS time ', (end-start)/60, ' minutes')\n",
    "\n",
    "#         else:\n",
    "        if set([np.around(results.transit_time, 4)[x] in [round(x, 4) for x in T0] for x in range(len(results.transit_time))]) == set([True]):\n",
    "        \n",
    "            intransit = intransit+transit_mask(time, results.period, 2*results.duration+(2*0.04), results.transit_time)\n",
    "\n",
    "            return using_BLS_to_find_periodic_signals(time, flux, u, intransit=intransit, verbose = verbose,  periods = periods, T0 = T0, Tdur = Tdur, depths = depths, first = False)\n",
    "        if verbose:\n",
    "            print('duration picked: ', results.duration)\n",
    "            \n",
    "            if len(time_new) == len(time):\n",
    "                model_color = model_colors[0]\n",
    "            else:\n",
    "                model_color = model_colors[1]\n",
    "\n",
    "            fig = plt.figure(figsize = (10, 10))\n",
    "            ax = fig.add_subplot(111)\n",
    "            ax.set_facecolor('None')\n",
    "            ax.axvline(results.period, alpha=0.7, lw=3.5,  color='#71F8FF', zorder = 0)\n",
    "#             ax.xlim(np.min(results.period), np.max(results.period))\n",
    "            for n in range(2, 10):\n",
    "                ax.axvline(n*results.period, alpha=0.25, lw=2, linestyle=\"dashed\",  color='#71F8FF', zorder = 0)\n",
    "                ax.axvline(results.period / n, alpha=0.25, lw=2, linestyle=\"dashed\",  color='#71F8FF', zorder = 0)\n",
    "#             for per in periods:\n",
    "#                 ax.axvline(per, alpha=0.6, lw=2, linestyle=\"dashed\",  color='#E4B7DA')\n",
    "\n",
    "#                         ax.axvline(results.period / n, alpha=0.4, lw=1, linestyle=\"dashed\",  color='#B06200')\n",
    "            ax.set_ylabel(r'SDE BLS', fontsize = 40, labelpad = 70)\n",
    "            ax.set_xlabel('Period (days)', fontsize = 40)\n",
    "\n",
    "            ax.set_xlim(0, 100.);\n",
    "            ax.xaxis.label.set_color('#FFD475')        #setting up X-axis label color to yellow\n",
    "            ax.yaxis.label.set_color('#FFD475')          #setting up Y-axis label color to blue\n",
    "            ax.tick_params(axis='x', colors='#FFD475', labelsize = 30, width=3, length = 8)    #setting up X-axis tick color to red\n",
    "            ax.tick_params(axis='y', colors='#FFD475', labelsize = 30, width=3, length = 8)  #setting up Y-axis tick color to black\n",
    "\n",
    "            ax2 = ax.twinx()\n",
    "            \n",
    "            ax2.plot(results.periods, results.power, color = '#EB8300', lw=0.65, zorder = 15, alpha = 0.7, label = 'Transit Least Squares Fit')\n",
    "\n",
    "            ax.plot(results.period, results.power, color='#B06200', lw=0.65, zorder = 10, alpha = 1, label = 'Box Least Squares Fit')\n",
    "            \n",
    "            ax.yaxis.tick_right()\n",
    "            ax2.yaxis.tick_left()\n",
    "\n",
    "            ax2.set_xlim(0, 100.);\n",
    "            ax2.xaxis.label.set_color('#FFD475')        #setting up X-axis label color to yellow\n",
    "            ax2.yaxis.label.set_color('#FFD475')          #setting up Y-axis label color to blue\n",
    "            ax2.tick_params(axis='x', colors='#FFD475', labelsize = 35, width=3, length = 8)    #setting up X-axis tick color to red\n",
    "            ax2.tick_params(axis='y', colors='#FFD475', labelsize = 35, width=3, length = 8)  #setting up Y-axis tick color to black\n",
    "            ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0,0))            \n",
    "            ax.yaxis.get_offset_text().set_fontsize(24)\n",
    "\n",
    "            \n",
    "\n",
    "            ax.spines['left'].set_color(None)        # setting up Y-axis tick color to red\n",
    "            ax.spines['bottom'].set_color(None)         #setting up above X-axis tick color to red\n",
    "            ax.spines['top'].set_color(None)        # setting up Y-axis tick color to red\n",
    "            ax.spines['right'].set_color(None)         #setting up above X-axis tick color to red\n",
    "            ax2.spines['left'].set_color(None)        # setting up Y-axis tick color to red\n",
    "            ax2.spines['bottom'].set_color(None)         #setting up above X-axis tick color to red\n",
    "            ax2.spines['top'].set_color(None)        # setting up Y-axis tick color to red\n",
    "            ax2.spines['right'].set_color(None)         #setting up above X-axis tick color to red\n",
    "            \n",
    "            mpl_axes_aligner.align.yaxes(ax, 0., ax2, 0., 0.15)\n",
    "            ax2.set_ylabel(r'SDE BLS', fontsize = 35, rotation = 270, labelpad = 100)\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            handles2, labels2 = ax2.get_legend_handles_labels()\n",
    "\n",
    "            # copy the handles\n",
    "            \n",
    "            handles = [copy.copy(ha) for ha in handles ]+[copy.copy(ha) for ha in handles2]\n",
    "            # set the linewidths to the copies\n",
    "            [ha.set_linewidth(7) for ha in handles ]\n",
    "            labels = list(labels)+list(labels2)\n",
    "            fig.legend(handles=handles, labels=labels, loc = \"upper right\", labelcolor='#FFD475', bbox_to_anchor=(0.9,0.9),\n",
    "                       framealpha=0., prop={\"size\":20, 'weight':'normal'})._legend_box.align = \"left\"\n",
    "            # bulk-set the properties of all lines and texts\n",
    "\n",
    "\n",
    "            plt.figure(figsize = (10, 10))\n",
    "            \n",
    "            ax = plt.gca()\n",
    "            ax.xaxis.label.set_color('#FFD475')        #setting up X-axis label color to yellow\n",
    "            ax.yaxis.label.set_color('#FFD475')          #setting up Y-axis label color to blue\n",
    "\n",
    "            ax.tick_params(axis='x', colors='#FFD475', labelsize = 35, width=3, length = 8)    #setting up X-axis tick color to red\n",
    "            ax.tick_params(axis='y', colors='#FFD475', labelsize = 35, width=3, length = 8)  #setting up Y-axis tick color to black\n",
    "            ax.xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "\n",
    "            ax.spines['top'].set_color(None)        # setting up Y-axis tick color to red\n",
    "            ax.spines['right'].set_color(None)         #setting up above X-axis tick color to red\n",
    "\n",
    "            ax.spines['left'].set_color(None)        # setting up Y-axis tick color to red\n",
    "            ax.spines['bottom'].set_color(None)         #setting up above X-axis tick color to red\n",
    "\n",
    "            ax.set_facecolor('None')\n",
    "            if len(time_new) == len(time):\n",
    "                model_color = model_colors[0]\n",
    "            else:\n",
    "                model_color = model_colors[1]\n",
    "            ax.plot(\n",
    "                results.model_folded_phase,\n",
    "                results.model_folded_model,\n",
    "                color=model_color, lw = 6.5)\n",
    "            ax.scatter(\n",
    "                results.folded_phase,\n",
    "                results.folded_y,\n",
    "                color='#E4D7BA',\n",
    "                s=10,\n",
    "                alpha=1,\n",
    "                zorder=2)\n",
    "            ax.set_xlim(0.49, 0.51)\n",
    "#                 plt.ylim(0.9985, 1.00025)\n",
    "            ax.set_xlabel('Phase', color = '#FFD475', fontsize = 35)\n",
    "            ax.set_ylabel('Relative Flux', color = '#FFD475', fontsize = 35);\n",
    "            plt.show()\n",
    "            print('T0: ', results.T0, 'duration: ', results.duration, 'npoints_dur: ', np.ceil(results.duration/30.))\n",
    "        if not np.abs(np.diff(np.array(sorted(results.power))[[-1, -2]]))>2*np.std(np.diff(results.power)) or len(time_new)==0 :\n",
    "\n",
    "            print('done with multis!')\n",
    "            print('per', periods)\n",
    "\n",
    "            return np.array(periods), np.array(T0), np.array(Tdur), np.array(depths), intransit\n",
    "        else: \n",
    "            intransit = intransit+transit_mask(time, results.period, 2*results.duration+(2*0.04), results.T0)\n",
    "\n",
    "            depths.append(results.depth)\n",
    "            periods.append(results.period)\n",
    "            T0.append(results.transit_time)\n",
    "            Tdur.append(results.duration)\n",
    "\n",
    "            return using_BLS_to_find_periodic_signals(time, flux, u, intransit=intransit, verbose = verbose,  periods = periods, T0 = T0, Tdur = Tdur, depths = depths, first = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66240807",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_data(fits_files_lst_for_target):\n",
    "    total_time = []\n",
    "    total_flux = []\n",
    "\n",
    "\n",
    "    for i in fits_files:\n",
    "        sector = np.int64(i.split('/')[7].split('_')[4].split('-')[0][1:])\n",
    "        print('sector', sector)\n",
    "#         if sector > 34:\n",
    "#             print(hdulist)\n",
    "\n",
    "        hdulist=apf.open(i) #fits time series\n",
    "\n",
    "        tbdata = hdulist[1].data\n",
    "#         print(tbdata)\n",
    "        qual         = tbdata.QUALITY == 0\n",
    "\n",
    "        time, flux = tbdata.TIME[qual], tbdata.SAP_FLUX[qual]\n",
    "\n",
    "        flux = flux/np.nanmedian(flux)\n",
    "        flux, time = flux[~np.isnan(flux)], time[~np.isnan(flux)]\n",
    "\n",
    "        cleaned_time, cleaned_flux = cleaning_up_data(time, flux)\n",
    "\n",
    "        flat_flux, flat_trend = flatten_lc(cleaned_time, cleaned_flux)\n",
    "\n",
    "        total_time.extend(cleaned_time)\n",
    "        total_flux.extend(flat_flux)\n",
    "#         plt.scatter(total_time, total_flux)\n",
    "#         plt.show()\n",
    "\n",
    "    return np.array(total_time), np.array(total_flux)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0bcff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_unique_transits(\n",
    "    timesFluxes,\n",
    "    transit_depth_min,\n",
    "    lc_arr,\n",
    "    lc_cache_overview,\n",
    "    T0_fit_margin,\n",
    "    verbose = False\n",
    "):\n",
    "\n",
    "    times, fluxes = np.array(timesFluxes[0]), np.array(timesFluxes[1])\n",
    "\n",
    "\n",
    "    T0_start, T0, Tdur, depth, residuals = search_best_fit_duration(\n",
    "    t=times,\n",
    "    y=fluxes,\n",
    "    dy=np.full(len(fluxes), np.std(fluxes)),\n",
    "    transit_depth_min=TRANSIT_DEPTH_MIN,\n",
    "    lc_arr=lc_arr,\n",
    "    lc_cache_overview=lc_cache_overview,\n",
    "    T0_fit_margin=T0_FIT_MARGIN, \n",
    "    verbose = verbose\n",
    "    )\n",
    "\n",
    "    sort_indxs = np.argsort(T0_start[:min(np.where(np.isnan(T0_start))[0])])\n",
    "\n",
    "    break_sort_indxs = np.array(sorted(list(set(np.append([0], np.append(find_breaks(T0_start[sort_indxs], 2.), [len(T0_start[sort_indxs])-1]))))))\n",
    "    break_sort_indxs = break_sort_indxs[break_sort_indxs>=0]\n",
    "\n",
    "    best_resids = np.array([min(residuals[sort_indxs][break_sort_indxs[i]:break_sort_indxs[i+1]]) for i in range(len(break_sort_indxs)-1)])\n",
    "    best_indx   = np.in1d(residuals, best_resids).nonzero()[0]\n",
    "\n",
    "        \n",
    "    return list(T0[best_indx]), list(Tdur[best_indx]*0.5), list(depth[best_indx])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c10a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_previous_transits(time, flux, tuples_of_past_transit_durations): \n",
    "    \n",
    "    # Written by Mallory Harris\n",
    "\n",
    "    # Description: masks common outliers and previously found planet transits around the star for multi-planet systems\n",
    "\n",
    "    # Arguments : time, flux, raw                         = arrays of equal sizes with time, flux and raw flux observation values \n",
    "    #             pdumps                                  = times of momentum dumps\n",
    "    #             all_times_of_outliers                   = times of outliers in flux measurements \n",
    "    #             time_hist_freq_of_outlier_in_all_ticids = number of elements in histogram bins of outlier\n",
    "    #             time_hist_bins_of_time_of_outliers      = histogram bines of time values that correspond with flux outliers\n",
    "    #             time_hist_freq_stdv                     = stdv of the number of elements in each histogram bin\n",
    "    #             tuples_of_past_transit_durations        =  list of tuples with start and end times for each tranist in observing window\n",
    "\n",
    "    # Return    : mask_time, mask_flux, mask_raw = new arrays of equal sizes without masked elements\n",
    "\n",
    "    mask = np.zeros(len(time)) \n",
    "    mask_time = []\n",
    "    mask_flux = []\n",
    "    for ttt in range(len(time)):\n",
    "        if tuples_of_past_transit_durations != []: #masks previously found planet transits around star\n",
    "            for tdur_times in tuples_of_past_transit_durations:\n",
    "                if time[ttt]>= tdur_times[0]-0.25 and time[ttt]<tdur_times[1]+0.25:\n",
    "                    mask[ttt] = 1\n",
    "\n",
    "        if mask[ttt] == 0: #creates arrays of remaining data\n",
    "            mask_time = np.append(mask_time,time[ttt]) \n",
    "            mask_flux = np.append(mask_flux,flux[ttt])\n",
    "    return mask_time, mask_flux, mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_times_to_mask_previous_transits(time, t0, Tdur, period):\n",
    "    # Written by Mallory Harris\n",
    "\n",
    "    # Description: for multi-planet system - uses times of transits previously found to mask when searching for additional planets\n",
    "\n",
    "    # Arguments : time    = array of time values\n",
    "    #             t0      = mid-tranist time of previously found planets\n",
    "    #             Tdur    = transit duration of previously found planets\n",
    "    #             period  = period of previously found planets\n",
    "\n",
    "    # Return    : epoch_durations  = list of tuples with start and end times for each tranist in observing window\n",
    "\n",
    "    max_t = max(time)\n",
    "    min_t = min(time)\n",
    "    half_dur = Tdur/2/24\n",
    "    num_per_before = 0-int(np.floor(np.abs(t0-min_t)))\n",
    "    num_per_after = int(np.floor(np.abs(t0-max_t)))\n",
    "    epochs = t0+period*np.array(range(num_per_before-1, num_per_after+2))\n",
    "    epoch_durations =[[epoch-(3/2*half_dur), epoch+(3/2*half_dur)] for epoch in epochs]\n",
    "    return epoch_durations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9883c7d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def running_overall_TLS_code(files, ab, Mstar, Rstar, verbose=False):\n",
    "#     print(files)\n",
    "\n",
    "    total_time, total_flux = get_data(files)\n",
    "    \n",
    "    time = total_time[np.argsort(total_time)]\n",
    "    flux = total_flux[np.argsort(total_time)]\n",
    "    \n",
    "#     time, flux = new_binning_function_by_time(list(time), list(flux), 10.)\n",
    "    print(len(time), len(flux))\n",
    "    \n",
    "    print('running periodic search')\n",
    "    periods_multis, T0_multis, Tdur_multis, depth_multis, intransit = using_BLS_to_find_periodic_signals(time, flux, u = ab, verbose = verbose)\n",
    "    print('lengths', len(periods_multis), len(T0_multis))\n",
    "    new_time = time[~intransit]\n",
    "    new_flux = flux[~intransit]\n",
    "    split_times, split_fluxes, total_sorted_times, total_sorted_flux = breaking_up_data(new_time, new_flux, 1.)\n",
    "\n",
    "    tf = []\n",
    "    for mmm in range(len(split_times)):\n",
    "        tf.append([split_times[mmm], split_fluxes[mmm]])\n",
    "#         print('is this working?', len(tf[mmm]), len(tf[mmm][0]), len(tf[mmm][1]))\n",
    "\n",
    "\n",
    "\n",
    "#     periods_multis = []\n",
    "#     T0_multis    = []\n",
    "#     Tdur_multis  = []\n",
    "#     depth_multis = []\n",
    "\n",
    "    T0_singles    = []\n",
    "    Tdur_singles  = []\n",
    "    depth_singles = []\n",
    "    \n",
    "    print('running single transit search')\n",
    "\n",
    "\n",
    "\n",
    "#     try:\n",
    "    lc_cache_overview, lc_arr = get_cache(\n",
    "        durations=DURATIONS,\n",
    "        maxwidth_in_samples=MAXWIDTH_IN_SAMPLES,\n",
    "        rp=RP_REFERENCE,\n",
    "        u= ab\n",
    "    )\n",
    "\n",
    "        \n",
    "#     for tess_flux in tf:\n",
    "#         T0, Tdur, depth = getting_unique_transits(tess_flux,\n",
    "#                     transit_depth_min=TRANSIT_DEPTH_MIN,\n",
    "#                     lc_arr=lc_arr,\n",
    "#                     lc_cache_overview=lc_cache_overview,\n",
    "#                     T0_fit_margin=T0_FIT_MARGIN)\n",
    "#         T0_singles.extend(T0)\n",
    "#         Tdur_singles.extend(Tdur)\n",
    "#         depth_singles.extend(depth)\n",
    "\n",
    "    pool = multiprocessing.Pool(processes=12)\n",
    "    params = partial(\n",
    "            getting_unique_transits,\n",
    "            transit_depth_min=TRANSIT_DEPTH_MIN,\n",
    "            lc_arr=lc_arr,\n",
    "            lc_cache_overview=lc_cache_overview,\n",
    "            T0_fit_margin=T0_FIT_MARGIN\n",
    "        )\n",
    "\n",
    "\n",
    "    for data in pool.imap_unordered(params, tf):\n",
    "#         print(data)\n",
    "        T0_singles.extend(data[0])\n",
    "        Tdur_singles.extend(data[1])\n",
    "        depth_singles.extend(data[2])\n",
    "#         if verbose == True:\n",
    "#             pbar.update(1)\n",
    "    pool.close()\n",
    "#     except:\n",
    "#         print('singles didnt work')\n",
    "#         T0_singles    = []\n",
    "#         Tdur_singles  = []\n",
    "#         depth_singles = []\n",
    "\n",
    "\n",
    "\n",
    "    T0_singles = np.array(T0_singles)\n",
    "    # print(T0_singles)\n",
    "    \n",
    "    periodic_singles = check_if_singles_are_periodic(T0_singles)\n",
    "    print('periodic singles', len(periodic_singles))\n",
    "    new_T0_periodic = []\n",
    "    if len(periodic_singles)>0:\n",
    "        indxs =np.unique([round(x[1], 3) for x in periodic_singles], return_index=True)[1]\n",
    "        print(indxs)\n",
    "        periodic_singles = np.array(periodic_singles)[indxs]\n",
    "        print(periodic_singles)\n",
    "        for ppp in periodic_singles:\n",
    "            T0_min, per, T0_all = ppp\n",
    "            tdur_, depth_, T0_, period_ = run_mcmc_code_for_tdur_and_depth(time, flux, T0_min, per, ab)\n",
    "            T0_multis = np.concatenate((T0_multis, np.array([T0_])))\n",
    "            \n",
    "            Tdur_multis = np.concatenate((Tdur_multis, np.array([tdur_])))\n",
    "\n",
    "            depth_multis = np.concatenate((depth_multis, np.array([1-depth_])))\n",
    "            periods_multis = np.concatenate((periods_multis, np.array([period_])))\n",
    "            new_T0_periodic.extend(T0_all)\n",
    "\n",
    "            \n",
    "            \n",
    "    sort_index = np.intersect1d(np.argsort(T0_singles), np.array([i for i in range(len(T0_singles)) if T0_singles[i] not in new_T0_periodic]))\n",
    "\n",
    "    T0_singles = np.array(T0_singles)[sort_index]\n",
    "    depth_singles = np.array(depth_singles)[sort_index]\n",
    "    Tdur_singles = np.array(Tdur_singles)[sort_index]\n",
    "    periods_singles = np.full(len(Tdur_singles), np.nan)\n",
    "    \n",
    "    if verbose:\n",
    "        print('checking singles T0')\n",
    "        for iii in range(len(T0_singles)):\n",
    "            t0 = T0_singles[iii]\n",
    "            print('t0: ', t0, ', tdur: ', Tdur_singles[iii], ' hours')\n",
    "            fig, ax = plt.subplots(1, 1, sharey=False, figsize = (12, 12))\n",
    "            ax.scatter(time[time<t0+1][time>t0-1]-t0, flux[time<t0+1][time>t0-1], color = 'turquoise')\n",
    "    \n",
    "            \n",
    "    #     print(np.shape(T0_multis), np.shape(T0_singles) )\n",
    "    #     print(type(T0_multis), type(T0_singles))\n",
    "    T0_all = np.concatenate([T0_multis, T0_singles])\n",
    "    Tdur_all = np.concatenate([Tdur_multis, Tdur_singles])\n",
    "\n",
    "    depth_all = np.concatenate([depth_multis, depth_singles])\n",
    "    periods_all = np.concatenate([periods_multis, periods_singles])\n",
    "\n",
    "    return T0_all, Tdur_all, depth_all, periods_all\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d3f39ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tev_csv = pd.read_csv('../TOI_904_work/csv-file-toi-catalog_09112022.csv', skiprows = 4)\n",
    "\n",
    "ticids = list(set(list(tev_csv['TIC'])))\n",
    "type(ticids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f107297f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6076f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctlfile = './Total_Mdwarf_files/all_mdwarf_params.csv'\n",
    "# mdwarfs = pd.read_csv(ctlfile, nrows = 100000, index_col=None)\n",
    "# mdwarfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f29e8b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDC_for_quadratic = pd.read_csv('./LDC_files/table15.dat', \n",
    "                                header = None, \n",
    "                                sep=\"\\s+\", index_col=None,\n",
    "                               names = ['logg', 'Teff', 'z','L/HP', 'aLSM', 'bLSM',\n",
    "                                       'aFCM', 'bFCM', 'SQRT(CHI2)', 'qsr', 'PC'])\n",
    "\n",
    "mdwarf_LDC_for_quadratic = LDC_for_quadratic[LDC_for_quadratic['Teff']<4300]\n",
    "                  \n",
    "\n",
    "def match_logg_and_teff_for_LDC(df):\n",
    "    a = []\n",
    "    b = []\n",
    "#     print('a')\n",
    "#     bar_format = \"{desc}{percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} targets | {elapsed}<{remaining}\"\n",
    "#     pbar = tqdm(total=len(df), smoothing=0.3,  position=1, leave=True, bar_format=bar_format)\n",
    "    for i in range(len(df)):\n",
    "#         print(i)\n",
    "\n",
    "        Teff = np.float128(df['Teff'])[i]\n",
    "        logg =  np.float128(df['logg'])[i]\n",
    "#         pbar.update(1)\n",
    "\n",
    "        try:\n",
    "            int(Teff)\n",
    "            mdwarf_Teff =mdwarf_LDC_for_quadratic[mdwarf_LDC_for_quadratic['Teff'] == np.median(mdwarf_LDC_for_quadratic.iloc[(mdwarf_LDC_for_quadratic['Teff'].astype('float128')-Teff+0.01).abs().argsort()[:8]].reset_index(drop=True)['Teff'])]\n",
    "            if i%100 == 0:\n",
    "    #                 print(Teff, set(mdwarf_Teff['Teff']))\n",
    "                if len(set(mdwarf_Teff['Teff']))>1:\n",
    "                       print(mdwarf_Teff)\n",
    "            if not abs(logg)>=0.:\n",
    "                logg = np.median(mdwarf_Teff['logg'])\n",
    "    #         print(mdwarf_Teff.iloc[(mdwarf_Teff['logg'].astype('float128')-logg-0.00000001).abs().argsort()].iloc[0][['aLSM', 'bLSM']])\n",
    "            aLSM, bLSM =  mdwarf_Teff.iloc[(mdwarf_Teff['logg'].astype('float128')-logg-0.00000001).abs().argsort()].iloc[0][['aLSM', 'bLSM']]\n",
    "#             print(aLSM, bLSM)\n",
    "            a.append(aLSM)\n",
    "            b.append(bLSM)  \n",
    "\n",
    "                    \n",
    "        except:\n",
    "            a.append(np.nan)\n",
    "            b.append(np.nan)\n",
    "#     pbar.close()\n",
    "\n",
    "    df['aLSM'] = a\n",
    "    df['bLSM'] = b\n",
    "    print(df[['aLSM', 'bLSM']])\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6fefdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctlfile = './Total_Mdwarf_files/final_mdwarf_params.csv'\n",
    "mdwarfs = pd.read_csv(ctlfile, iterator =True, chunksize = 100000, index_col=None)\n",
    "\n",
    "mdwarfs_known = pd.concat(\n",
    "    [chunk[chunk['TICID'].astype(int).isin(TICIDs)] \n",
    "    for chunk in mdwarfs]\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0dfeb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_lcf_files(mdwarfs_known, 'QLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9eb5d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TICID</th>\n",
       "      <th>RA</th>\n",
       "      <th>DEC</th>\n",
       "      <th>Vmag</th>\n",
       "      <th>Jmag</th>\n",
       "      <th>Tmag</th>\n",
       "      <th>Teff</th>\n",
       "      <th>eTeff_x</th>\n",
       "      <th>Rad</th>\n",
       "      <th>eRad</th>\n",
       "      <th>...</th>\n",
       "      <th>S54</th>\n",
       "      <th>S55</th>\n",
       "      <th>eTeff_y</th>\n",
       "      <th>logg</th>\n",
       "      <th>elogg</th>\n",
       "      <th>M/H</th>\n",
       "      <th>eM/H</th>\n",
       "      <th>GAIA</th>\n",
       "      <th>aLSM</th>\n",
       "      <th>bLSM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150428135.0</td>\n",
       "      <td>97.096787</td>\n",
       "      <td>-65.579312</td>\n",
       "      <td>13.151</td>\n",
       "      <td>9.469</td>\n",
       "      <td>10.9102</td>\n",
       "      <td>3494.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.419457</td>\n",
       "      <td>0.012573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.80892</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.284518e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>219195044.0</td>\n",
       "      <td>92.391740</td>\n",
       "      <td>-53.823484</td>\n",
       "      <td>13.311</td>\n",
       "      <td>10.241</td>\n",
       "      <td>11.5436</td>\n",
       "      <td>3731.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.473141</td>\n",
       "      <td>0.014147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.76101</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.500474e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>259377017.0</td>\n",
       "      <td>68.415501</td>\n",
       "      <td>-51.956232</td>\n",
       "      <td>12.603</td>\n",
       "      <td>9.099</td>\n",
       "      <td>10.4981</td>\n",
       "      <td>3532.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.374358</td>\n",
       "      <td>0.011496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.85053</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.781196e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36724087.0</td>\n",
       "      <td>154.646405</td>\n",
       "      <td>-11.716734</td>\n",
       "      <td>13.140</td>\n",
       "      <td>9.007</td>\n",
       "      <td>10.5848</td>\n",
       "      <td>3331.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.374139</td>\n",
       "      <td>0.011184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.85074</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.767282e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>235678745.0</td>\n",
       "      <td>285.633044</td>\n",
       "      <td>75.418605</td>\n",
       "      <td>13.190</td>\n",
       "      <td>9.797</td>\n",
       "      <td>11.0788</td>\n",
       "      <td>3746.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.463205</td>\n",
       "      <td>0.013592</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.76979</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.268372e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441798995.0</td>\n",
       "      <td>264.147791</td>\n",
       "      <td>77.126122</td>\n",
       "      <td>13.476</td>\n",
       "      <td>10.765</td>\n",
       "      <td>11.9521</td>\n",
       "      <td>3872.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.548484</td>\n",
       "      <td>0.016161</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.69525</td>\n",
       "      <td>0.009462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.657159e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>284441182.0</td>\n",
       "      <td>10.088709</td>\n",
       "      <td>61.213626</td>\n",
       "      <td>13.459</td>\n",
       "      <td>10.154</td>\n",
       "      <td>11.4752</td>\n",
       "      <td>3624.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.490120</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.74607</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.272241e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>467179528.0</td>\n",
       "      <td>197.998168</td>\n",
       "      <td>65.833807</td>\n",
       "      <td>12.941</td>\n",
       "      <td>9.706</td>\n",
       "      <td>11.0402</td>\n",
       "      <td>3618.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.435666</td>\n",
       "      <td>0.012939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.79432</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.678074e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TICID          RA        DEC    Vmag    Jmag     Tmag    Teff  \\\n",
       "0  150428135.0   97.096787 -65.579312  13.151   9.469  10.9102  3494.0   \n",
       "1  219195044.0   92.391740 -53.823484  13.311  10.241  11.5436  3731.0   \n",
       "2  259377017.0   68.415501 -51.956232  12.603   9.099  10.4981  3532.0   \n",
       "3   36724087.0  154.646405 -11.716734  13.140   9.007  10.5848  3331.0   \n",
       "4  235678745.0  285.633044  75.418605  13.190   9.797  11.0788  3746.0   \n",
       "5  441798995.0  264.147791  77.126122  13.476  10.765  11.9521  3872.0   \n",
       "6  284441182.0   10.088709  61.213626  13.459  10.154  11.4752  3624.0   \n",
       "7  467179528.0  197.998168  65.833807  12.941   9.706  11.0402  3618.0   \n",
       "\n",
       "   eTeff_x       Rad      eRad  ...   S54   S55  eTeff_y     logg     elogg  \\\n",
       "0    157.0  0.419457  0.012573  ...   0.0   0.0    157.0  4.80892  0.004651   \n",
       "1    157.0  0.473141  0.014147  ...   0.0   0.0    157.0  4.76101  0.007200   \n",
       "2    157.0  0.374358  0.011496  ...   0.0   0.0    157.0  4.85053  0.002090   \n",
       "3    157.0  0.374139  0.011184  ...   0.0   0.0    157.0  4.85074  0.001634   \n",
       "4    157.0  0.463205  0.013592  ...  10.0  10.0    157.0  4.76979  0.006479   \n",
       "5    157.0  0.548484  0.016161  ...  10.0  10.0    157.0  4.69525  0.009462   \n",
       "6    157.0  0.490120  0.014531  ...   0.0   0.0    157.0  4.74607  0.007723   \n",
       "7    157.0  0.435666  0.012939  ...   0.0   0.0    157.0  4.79432  0.005376   \n",
       "\n",
       "   M/H eM/H          GAIA aLSM bLSM  \n",
       "0  NaN  NaN  5.284518e+18  NaN  NaN  \n",
       "1  NaN  NaN  5.500474e+18  NaN  NaN  \n",
       "2  NaN  NaN  4.781196e+18  NaN  NaN  \n",
       "3  NaN  NaN  3.767282e+18  NaN  NaN  \n",
       "4  NaN  NaN  2.268372e+18  NaN  NaN  \n",
       "5  NaN  NaN  1.657159e+18  NaN  NaN  \n",
       "6  NaN  NaN  4.272241e+17  NaN  NaN  \n",
       "7  NaN  NaN  1.678074e+18  NaN  NaN  \n",
       "\n",
       "[8 rows x 80 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdwarfs_known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e82f7019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TICID</th>\n",
       "      <th>RA</th>\n",
       "      <th>DEC</th>\n",
       "      <th>Vmag</th>\n",
       "      <th>Jmag</th>\n",
       "      <th>Tmag</th>\n",
       "      <th>Teff</th>\n",
       "      <th>eTeff_x</th>\n",
       "      <th>Rad</th>\n",
       "      <th>eRad</th>\n",
       "      <th>...</th>\n",
       "      <th>S54</th>\n",
       "      <th>S55</th>\n",
       "      <th>eTeff_y</th>\n",
       "      <th>logg</th>\n",
       "      <th>elogg</th>\n",
       "      <th>M/H</th>\n",
       "      <th>eM/H</th>\n",
       "      <th>GAIA</th>\n",
       "      <th>aLSM</th>\n",
       "      <th>bLSM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150428135.0</td>\n",
       "      <td>97.096787</td>\n",
       "      <td>-65.579312</td>\n",
       "      <td>13.151</td>\n",
       "      <td>9.469</td>\n",
       "      <td>10.9102</td>\n",
       "      <td>3494.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.419457</td>\n",
       "      <td>0.012573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.80892</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.284518e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>219195044.0</td>\n",
       "      <td>92.391740</td>\n",
       "      <td>-53.823484</td>\n",
       "      <td>13.311</td>\n",
       "      <td>10.241</td>\n",
       "      <td>11.5436</td>\n",
       "      <td>3731.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.473141</td>\n",
       "      <td>0.014147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.76101</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.500474e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>259377017.0</td>\n",
       "      <td>68.415501</td>\n",
       "      <td>-51.956232</td>\n",
       "      <td>12.603</td>\n",
       "      <td>9.099</td>\n",
       "      <td>10.4981</td>\n",
       "      <td>3532.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.374358</td>\n",
       "      <td>0.011496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.85053</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.781196e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36724087.0</td>\n",
       "      <td>154.646405</td>\n",
       "      <td>-11.716734</td>\n",
       "      <td>13.140</td>\n",
       "      <td>9.007</td>\n",
       "      <td>10.5848</td>\n",
       "      <td>3331.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.374139</td>\n",
       "      <td>0.011184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.85074</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.767282e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>235678745.0</td>\n",
       "      <td>285.633044</td>\n",
       "      <td>75.418605</td>\n",
       "      <td>13.190</td>\n",
       "      <td>9.797</td>\n",
       "      <td>11.0788</td>\n",
       "      <td>3746.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.463205</td>\n",
       "      <td>0.013592</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.76979</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.268372e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441798995.0</td>\n",
       "      <td>264.147791</td>\n",
       "      <td>77.126122</td>\n",
       "      <td>13.476</td>\n",
       "      <td>10.765</td>\n",
       "      <td>11.9521</td>\n",
       "      <td>3872.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.548484</td>\n",
       "      <td>0.016161</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.69525</td>\n",
       "      <td>0.009462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.657159e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>284441182.0</td>\n",
       "      <td>10.088709</td>\n",
       "      <td>61.213626</td>\n",
       "      <td>13.459</td>\n",
       "      <td>10.154</td>\n",
       "      <td>11.4752</td>\n",
       "      <td>3624.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.490120</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.74607</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.272241e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>467179528.0</td>\n",
       "      <td>197.998168</td>\n",
       "      <td>65.833807</td>\n",
       "      <td>12.941</td>\n",
       "      <td>9.706</td>\n",
       "      <td>11.0402</td>\n",
       "      <td>3618.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.435666</td>\n",
       "      <td>0.012939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.79432</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.678074e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TICID          RA        DEC    Vmag    Jmag     Tmag    Teff  \\\n",
       "0  150428135.0   97.096787 -65.579312  13.151   9.469  10.9102  3494.0   \n",
       "1  219195044.0   92.391740 -53.823484  13.311  10.241  11.5436  3731.0   \n",
       "2  259377017.0   68.415501 -51.956232  12.603   9.099  10.4981  3532.0   \n",
       "3   36724087.0  154.646405 -11.716734  13.140   9.007  10.5848  3331.0   \n",
       "4  235678745.0  285.633044  75.418605  13.190   9.797  11.0788  3746.0   \n",
       "5  441798995.0  264.147791  77.126122  13.476  10.765  11.9521  3872.0   \n",
       "6  284441182.0   10.088709  61.213626  13.459  10.154  11.4752  3624.0   \n",
       "7  467179528.0  197.998168  65.833807  12.941   9.706  11.0402  3618.0   \n",
       "\n",
       "   eTeff_x       Rad      eRad  ...   S54   S55  eTeff_y     logg     elogg  \\\n",
       "0    157.0  0.419457  0.012573  ...   0.0   0.0    157.0  4.80892  0.004651   \n",
       "1    157.0  0.473141  0.014147  ...   0.0   0.0    157.0  4.76101  0.007200   \n",
       "2    157.0  0.374358  0.011496  ...   0.0   0.0    157.0  4.85053  0.002090   \n",
       "3    157.0  0.374139  0.011184  ...   0.0   0.0    157.0  4.85074  0.001634   \n",
       "4    157.0  0.463205  0.013592  ...  10.0  10.0    157.0  4.76979  0.006479   \n",
       "5    157.0  0.548484  0.016161  ...  10.0  10.0    157.0  4.69525  0.009462   \n",
       "6    157.0  0.490120  0.014531  ...   0.0   0.0    157.0  4.74607  0.007723   \n",
       "7    157.0  0.435666  0.012939  ...   0.0   0.0    157.0  4.79432  0.005376   \n",
       "\n",
       "   M/H eM/H          GAIA aLSM bLSM  \n",
       "0  NaN  NaN  5.284518e+18  NaN  NaN  \n",
       "1  NaN  NaN  5.500474e+18  NaN  NaN  \n",
       "2  NaN  NaN  4.781196e+18  NaN  NaN  \n",
       "3  NaN  NaN  3.767282e+18  NaN  NaN  \n",
       "4  NaN  NaN  2.268372e+18  NaN  NaN  \n",
       "5  NaN  NaN  1.657159e+18  NaN  NaN  \n",
       "6  NaN  NaN  4.272241e+17  NaN  NaN  \n",
       "7  NaN  NaN  1.678074e+18  NaN  NaN  \n",
       "\n",
       "[8 rows x 80 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdwarfs_known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8678c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     aLSM    bLSM\n",
      "0  0.1604  0.4325\n",
      "1  0.1737  0.4118\n",
      "2  0.1604  0.4325\n",
      "3  0.1529  0.4604\n",
      "4  0.1737  0.4118\n",
      "5  0.2946  0.3316\n",
      "6  0.2125  0.3984\n",
      "7  0.1671  0.4201\n"
     ]
    }
   ],
   "source": [
    "mdwarfs_known =match_logg_and_teff_for_LDC(mdwarfs_known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25a781ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rad</th>\n",
       "      <th>eRad</th>\n",
       "      <th>Mass</th>\n",
       "      <th>eMass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.419457</td>\n",
       "      <td>0.012573</td>\n",
       "      <td>0.413261</td>\n",
       "      <td>0.020339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.473141</td>\n",
       "      <td>0.014147</td>\n",
       "      <td>0.470893</td>\n",
       "      <td>0.020349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.374358</td>\n",
       "      <td>0.011496</td>\n",
       "      <td>0.362274</td>\n",
       "      <td>0.020491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.374139</td>\n",
       "      <td>0.011184</td>\n",
       "      <td>0.362023</td>\n",
       "      <td>0.020268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.463205</td>\n",
       "      <td>0.013592</td>\n",
       "      <td>0.460544</td>\n",
       "      <td>0.020152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.548484</td>\n",
       "      <td>0.016161</td>\n",
       "      <td>0.543889</td>\n",
       "      <td>0.020201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.490120</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>0.488207</td>\n",
       "      <td>0.020264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.435666</td>\n",
       "      <td>0.012939</td>\n",
       "      <td>0.431082</td>\n",
       "      <td>0.020262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rad      eRad      Mass     eMass\n",
       "0  0.419457  0.012573  0.413261  0.020339\n",
       "1  0.473141  0.014147  0.470893  0.020349\n",
       "2  0.374358  0.011496  0.362274  0.020491\n",
       "3  0.374139  0.011184  0.362023  0.020268\n",
       "4  0.463205  0.013592  0.460544  0.020152\n",
       "5  0.548484  0.016161  0.543889  0.020201\n",
       "6  0.490120  0.014531  0.488207  0.020264\n",
       "7  0.435666  0.012939  0.431082  0.020262"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdwarfs_known[['Rad', 'eRad', 'Mass', 'eMass']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2676c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticids_mdwarfs = list(mdwarfs_known['TICID'].astype(int))\n",
    "len(set(ticids_mdwarfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90c5eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1, 27):\n",
    "#     get_lcf_files(mdwarfs_known, i, 'TESS-SPOC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc0f1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [TICID, planet_name, period, T0, Tdur, depth]\n",
      "Index: []\n",
      "150428135\n",
      "num files 20\n",
      "[0.1604 0.4325]\n",
      "sector 1\n",
      "sector 4\n",
      "sector 5\n",
      "sector 6\n",
      "sector 7\n",
      "sector 8\n",
      "sector 9\n",
      "sector 10\n",
      "sector 11\n",
      "sector 13\n",
      "sector 27\n",
      "sector 28\n",
      "sector 30\n",
      "sector 31\n",
      "sector 33\n",
      "sector 34\n",
      "sector 35\n",
      "sector 36\n",
      "sector 37\n",
      "sector 38\n",
      "38084 38084\n",
      "running periodic search\n",
      "number of frequencies:  2137190\n",
      "return autoperiod [  1.           1.00000047   1.00000093 ... 517.0731016  517.19799099\n",
      " 517.32294071]\n"
     ]
    }
   ],
   "source": [
    "column_names = ['TICID', 'planet_name', 'period', 'T0', 'Tdur', 'depth']\n",
    "\n",
    "# final_file = './search_mdwarf_planets.csv'\n",
    "new_planet_df = pd.DataFrame(columns=column_names)\n",
    "print(new_planet_df)\n",
    "\n",
    "\n",
    "for iii in ticids_mdwarfs[:1]:\n",
    "    \n",
    "    print(iii)\n",
    "    fits_files = sorted(glob.glob('./known_Mdwarfs_data/FFI_data/all_target_data/tic_'+str(iii)+'_all/*/*/*/*.fits'))\n",
    "#     print(len(fits_files))\n",
    "#     fits_files = sorted(glob.glob('./known_Mdwarfs_data/FFI_data/*/*/*/*'+str(iii)+'*/*.fits'))\n",
    "\n",
    "    if len(fits_files)>0:\n",
    "    # print(tess_spoc_fits)\n",
    "        print('num files', len(fits_files))\n",
    "    #     fits_files\n",
    "        ab, smass, smass_min, smass_max, sradius, sradius_min, sradius_max = get_catalog_info(iii, mdwarfs_known)\n",
    "        print(ab)\n",
    "        T0_all, Tdur_all, depth_all, periods_all = running_overall_TLS_code(fits_files, ab, smass, sradius, verbose = True)\n",
    "        nnn = 0\n",
    "        for jjj in range(len(T0_all)):\n",
    "            nnn+=1\n",
    "            planet_name = str(float(iii)+nnn/100)\n",
    "            new_planet_df.loc[len(new_planet_df.index)] = [int(iii), planet_name, periods_all[jjj], T0_all[jjj], Tdur_all[jjj],depth_all[jjj]]\n",
    "#             new_planet_df.to_csv(final_file, index = False, header = False, mode=\"a\",)\n",
    "        T0_all, Tdur_all, depth_all, periods_all = [], [], [], []\n",
    "        print('done ', iii, new_planet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef108771",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_planet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9468d82c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
